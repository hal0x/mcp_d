#!/usr/bin/env python3
"""
–ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Telegram –¥–∞–º–ø–∞–º–∏
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏: –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é, —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—é –∏ –ø–æ–∏—Å–∫
"""

import argparse
import asyncio
import hashlib
import json
import logging
import os
import signal
import subprocess
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ PYTHONPATH
sys.path.insert(0, str(Path(__file__).parent))

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ PYTHONPATH –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥—É–ª–∏
try:
    from memory_mcp.memory.embeddings import build_embedding_service_from_env

    EMBEDDING_CLIENT_AVAILABLE = True
except ImportError:
    EMBEDDING_CLIENT_AVAILABLE = False
    print("‚ö†Ô∏è LangChain embedding service –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

try:
    from memory_mcp.analysis.instruction_manager import InstructionManager

    INSTRUCTION_MANAGER_AVAILABLE = True
except ImportError:
    INSTRUCTION_MANAGER_AVAILABLE = False
    print("‚ö†Ô∏è InstructionManager –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º MCP —Å–µ—Ä–≤–µ—Ä –∏–∑ scripts
try:
    from mcp_server import TelegramDumpMCP

    MCP_AVAILABLE = True
except ImportError:
    MCP_AVAILABLE = False
    print("‚ö†Ô∏è TelegramDumpMCP –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º MessageExtractor –∏–∑ –æ–±—â–µ–≥–æ –º–æ–¥—É–ª—è
from memory_mcp.utils.message_extractor import MessageExtractor


class MessageDeduplicator:
    """–ö–ª–∞—Å—Å –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ –ø–æ–ª—é 'id'."""

    def __init__(self, chats_dir: str = "chats"):
        self.chats_dir = Path(chats_dir)
        self.stats = {
            "total_chats": 0,
            "processed_chats": 0,
            "total_messages": 0,
            "duplicates_removed": 0,
            "unique_messages": 0,
            "errors": 0,
        }

    def deduplicate_chat(self, chat_dir: Path) -> Dict[str, int]:
        """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –æ–¥–Ω–æ–º —á–∞—Ç–µ."""
        chat_stats = {
            "messages_before": 0,
            "messages_after": 0,
            "duplicates_removed": 0,
            "errors": 0,
        }

        # –ò—â–µ–º JSON —Ñ–∞–π–ª—ã –≤ —á–∞—Ç–µ (unknown.json –∏–ª–∏ result.json)
        json_files = []
        for pattern in ["unknown.json", "result.json"]:
            json_file = chat_dir / pattern
            if json_file.exists():
                json_files.append(json_file)

        if not json_files:
            logger.warning(f"–ù–µ—Ç JSON —Ñ–∞–π–ª–æ–≤ –≤ —á–∞—Ç–µ: {chat_dir}")
            return chat_stats

        for json_file in json_files:
            try:
                # –ß–∏—Ç–∞–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                messages = []
                with open(json_file, encoding="utf-8") as f:
                    for line_num, line in enumerate(f, 1):
                        line = line.strip()
                        if not line:
                            continue

                        try:
                            message = json.loads(line)
                            messages.append(message)
                            chat_stats["messages_before"] += 1
                        except json.JSONDecodeError as e:
                            logger.warning(f"–û—à–∏–±–∫–∞ JSON –≤ {json_file}:{line_num}: {e}")
                            chat_stats["errors"] += 1

                # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ ID
                seen_ids = set()
                unique_messages = []
                duplicates_count = 0

                for message in messages:
                    message_id = str(message.get("id", ""))
                    if message_id and message_id not in seen_ids:
                        seen_ids.add(message_id)
                        unique_messages.append(message)
                    else:
                        duplicates_count += 1

                chat_stats["duplicates_removed"] += duplicates_count
                chat_stats["messages_after"] += len(unique_messages)

                # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∞–π–ª –±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
                if duplicates_count > 0:
                    with open(json_file, "w", encoding="utf-8") as f:
                        for message in unique_messages:
                            json.dump(message, f, ensure_ascii=False)
                            f.write("\n")

                    logger.info(
                        f"–£–¥–∞–ª–µ–Ω–æ {duplicates_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ {json_file.name}"
                    )

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {json_file}: {e}")
                chat_stats["errors"] += 1

        return chat_stats

    def deduplicate_all_chats(self) -> Dict[str, int]:
        """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –≤–æ –≤—Å–µ—Ö —á–∞—Ç–∞—Ö."""
        if not self.chats_dir.exists():
            logger.error(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {self.chats_dir} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            return self.stats

        chat_dirs = [d for d in self.chats_dir.iterdir() if d.is_dir()]
        self.stats["total_chats"] = len(chat_dirs)

        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(chat_dirs)} —á–∞—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")

        for chat_dir in chat_dirs:
            try:
                chat_stats = self.deduplicate_chat(chat_dir)

                # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                self.stats["processed_chats"] += 1
                self.stats["total_messages"] += chat_stats["messages_before"]
                self.stats["duplicates_removed"] += chat_stats["duplicates_removed"]
                self.stats["unique_messages"] += chat_stats["messages_after"]
                self.stats["errors"] += chat_stats["errors"]

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞—Ç–∞ {chat_dir}: {e}")
                self.stats["errors"] += 1

        return self.stats

    def print_stats(self):
        """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏."""
        print("\n" + "=" * 70)
        print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –£–î–ê–õ–ï–ù–ò–Ø –î–£–ë–õ–ò–ö–ê–¢–û–í")
        print("=" * 70)
        print(
            f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —á–∞—Ç–æ–≤: {self.stats['processed_chats']}/{self.stats['total_chats']}"
        )
        print(f"–í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {self.stats['total_messages']}")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π: {self.stats['unique_messages']}")
        print(f"–£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {self.stats['duplicates_removed']}")
        print(f"–û—à–∏–±–æ–∫: {self.stats['errors']}")

        if self.stats["total_messages"] > 0:
            duplicate_percent = (
                self.stats["duplicates_removed"] / self.stats["total_messages"]
            ) * 100
            print(f"–ü—Ä–æ—Ü–µ–Ω—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicate_percent:.2f}%")

        print("=" * 70)


class ProcessManager:
    """–ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏."""

    @staticmethod
    def kill_processes_by_name(pattern: str) -> int:
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å—ã –ø–æ –∏–º–µ–Ω–∏"""
        try:
            result = subprocess.run(["ps", "aux"], capture_output=True, text=True)

            lines = result.stdout.split("\n")
            killed_count = 0

            for line in lines:
                if pattern in line and "grep" not in line:
                    parts = line.split()
                    if len(parts) >= 2:
                        pid = parts[1]
                        try:
                            os.kill(int(pid), signal.SIGTERM)
                            print(f"‚úÖ –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø—Ä–æ—Ü–µ—Å—Å {pid}: {line[:80]}...")
                            killed_count += 1
                        except (OSError, ValueError) as e:
                            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å {pid}: {e}")

            return killed_count

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤: {e}")
            return 0

    @staticmethod
    def stop_ollama():
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Ollama —Å–µ—Ä–≤–µ—Ä"""
        print("\nüõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama —Å–µ—Ä–≤–µ—Ä–∞...")

        # –ü–æ–ø—Ä–æ–±—É–µ–º –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —á–µ—Ä–µ–∑ ollama stop
        try:
            result = subprocess.run(
                ["ollama", "stop"], capture_output=True, text=True, timeout=10
            )
            if result.returncode == 0:
                print("‚úÖ Ollama —Å–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —á–µ—Ä–µ–∑ ollama stop")
            else:
                print(f"‚ö†Ô∏è  ollama stop –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –∫–æ–¥–æ–º {result.returncode}")
        except subprocess.TimeoutExpired:
            print("‚ö†Ô∏è  ollama stop –ø—Ä–µ–≤—ã—Å–∏–ª –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è")
        except FileNotFoundError:
            print("‚ö†Ô∏è  –ö–æ–º–∞–Ω–¥–∞ ollama –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ Ollama: {e}")

        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Å—Ç–∞–Ω–æ–≤–∏–º –ø—Ä–æ—Ü–µ—Å—Å—ã ollama
        ollama_count = ProcessManager.kill_processes_by_name("ollama")
        if ollama_count > 0:
            print(f"‚úÖ –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ {ollama_count} –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ Ollama")
        else:
            print("‚ÑπÔ∏è  –ü—Ä–æ—Ü–µ—Å—Å—ã Ollama –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

    @staticmethod
    def stop_indexing_processes():
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Å–µ –ø—Ä–æ—Ü–µ—Å—Å—ã –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
        print("\nüõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏...")

        patterns = [
            "python.*index",
            "python.*memory_mcp",
            "python.*process_and_index",
            "python.*summarize",
            "python.*markdown",
        ]

        total_killed = 0
        for pattern in patterns:
            count = ProcessManager.kill_processes_by_name(pattern)
            total_killed += count

        if total_killed > 0:
            print(f"‚úÖ –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ {total_killed} –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
        else:
            print("‚ÑπÔ∏è  –ü—Ä–æ—Ü–µ—Å—Å—ã –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

    @staticmethod
    def check_remaining_processes():
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –ø—Ä–æ—Ü–µ—Å—Å—ã"""
        print("\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤...")

        try:
            result = subprocess.run(["ps", "aux"], capture_output=True, text=True)

            lines = result.stdout.split("\n")
            remaining = []

            for line in lines:
                if (
                    any(
                        keyword in line.lower()
                        for keyword in ["index", "memory_mcp", "ollama", "summarize"]
                    )
                    and "grep" not in line
                ):
                    remaining.append(line)

            if remaining:
                print("‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω—ã –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –ø—Ä–æ—Ü–µ—Å—Å—ã:")
                for line in remaining:
                    print(f"   {line[:100]}...")
            else:
                print("‚úÖ –í—Å–µ –ø—Ä–æ—Ü–µ—Å—Å—ã –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤: {e}")

    @staticmethod
    def stop_all_indexing():
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Å–µ –ø—Ä–æ—Ü–µ—Å—Å—ã –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
        print("üõë –û–°–¢–ê–ù–û–í–ö–ê –í–°–ï–• –ü–†–û–¶–ï–°–°–û–í –ò–ù–î–ï–ö–°–ê–¶–ò–ò")
        print("=" * 50)

        # –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å—ã –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        ProcessManager.stop_indexing_processes()

        # –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Ollama
        ProcessManager.stop_ollama()

        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        ProcessManager.check_remaining_processes()

        print("\n" + "=" * 50)
        print("‚úÖ –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print("\nüí° –î–ª—è –ø–æ–ª–Ω–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ Ollama —Ç–∞–∫–∂–µ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:")
        print("   pkill -f ollama")
        print("\nüí° –î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞:")
        print("   ps aux | grep -E '(index|memory_mcp|ollama)' | grep -v grep")


class TelegramDumpManager:
    """–ì–ª–∞–≤–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Telegram –¥–∞–º–ø–∞–º–∏"""

    def __init__(self):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        if MCP_AVAILABLE:
            self.mcp = TelegramDumpMCP()
        else:
            self.mcp = None

        if EMBEDDING_CLIENT_AVAILABLE:
            self.embedding_client = build_embedding_service_from_env()
        else:
            self.embedding_client = None

        if INSTRUCTION_MANAGER_AVAILABLE:
            self.instruction_manager = InstructionManager()
        else:
            self.instruction_manager = None

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.message_extractor = MessageExtractor()
        self.message_deduplicator = MessageDeduplicator()

    async def __aenter__(self):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä - –≤—Ö–æ–¥"""
        # LangChain –∞–¥–∞–ø—Ç–µ—Ä—ã –Ω–µ —Ç—Ä–µ–±—É—é—Ç async context manager
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä - –≤—ã—Ö–æ–¥"""
        # LangChain –∞–¥–∞–ø—Ç–µ—Ä—ã –Ω–µ —Ç—Ä–µ–±—É—é—Ç async context manager
        if self.embedding_client:
            self.embedding_client.close()

    async def check_system(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º—ã"""
        print("üîß –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º—ã...")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º embedding service
        if self.embedding_client:
            if not self.embedding_client.available():
                print("‚ùå Embedding service –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
                print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ embedding service –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∏ –¥–æ—Å—Ç—É–ø–µ–Ω")
                return False
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
            dimension = self.embedding_client.dimension
            if dimension:
                print(f"‚úÖ Embedding service –¥–æ—Å—Ç—É–ø–µ–Ω (—Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {dimension})")
            else:
                print("‚úÖ Embedding service –¥–æ—Å—Ç—É–ø–µ–Ω")
        else:
            print("‚ö†Ô∏è LangChain embedding service –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º ChromaDB
        if self.mcp:
            try:
                self.mcp.collection = self.mcp.chroma_client.get_collection(
                    "telegram_messages"
                )
                count = self.mcp.collection.count()
                print(f"‚úÖ ChromaDB –¥–æ—Å—Ç—É–ø–µ–Ω (—Å–æ–æ–±—â–µ–Ω–∏–π: {count})")
            except:
                print("‚ö†Ô∏è ChromaDB –∫–æ–ª–ª–µ–∫—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        else:
            print("‚ö†Ô∏è MCP —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

        return True

    def set_summarization_instruction(
        self,
        *,
        chat: Optional[str] = None,
        mode: Optional[str] = None,
        instruction: Optional[str] = None,
        clear: bool = False,
    ) -> None:
        """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è MCP –∏ CLI."""
        if not self.instruction_manager:
            print("‚ö†Ô∏è InstructionManager –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return

        target_count = sum(1 for value in (chat, mode) if value)
        if target_count != 1:
            raise ValueError("–ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å —Ä–æ–≤–Ω–æ –æ–¥–∏–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä: chat –∏–ª–∏ mode")

        if clear:
            if chat:
                self.instruction_manager.clear_chat_instruction(chat)
            else:
                self.instruction_manager.clear_mode_instruction(mode)
            return

        if instruction is None or not instruction.strip():
            raise ValueError("–ù–µ –ø–µ—Ä–µ–¥–∞–Ω —Ç–µ–∫—Å—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏")

        if chat:
            self.instruction_manager.set_chat_instruction(chat, instruction)
        else:
            self.instruction_manager.set_mode_instruction(mode, instruction)

    async def get_stats(self) -> None:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        print("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã...")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–æ–æ–±—â–µ–Ω–∏—è–º
        if self.mcp:
            try:
                self.mcp.collection = self.mcp.chroma_client.get_collection(
                    "telegram_messages"
                )
                message_count = self.mcp.collection.count()
                print(f"üìö –°–æ–æ–±—â–µ–Ω–∏–π –≤ –∏–Ω–¥–µ–∫—Å–µ: {message_count}")
            except:
                print("üìö –°–æ–æ–±—â–µ–Ω–∏–π –≤ –∏–Ω–¥–µ–∫—Å–µ: 0")
        else:
            print("üìö MCP —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ñ–∞–π–ª–∞–º
        chats_path = Path("chats")
        if chats_path.exists():
            json_files = list(chats_path.glob("**/*.json"))
            print(f"üìÅ JSON —Ñ–∞–π–ª–æ–≤: {len(json_files)}")
        else:
            print("üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è chats –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

        md_files = (
            list(Path("summaries").glob("*.md")) if Path("summaries").exists() else []
        )
        print(f"üìÑ MD —Ñ–∞–π–ª–æ–≤: {len(md_files)}")

    async def extract_messages(
        self,
        dry_run: bool = False,
        filter_by_date: bool = True,
        chat_filter: Optional[str] = None,
        input_dir: str = "input",
        chats_dir: str = "chats",
    ) -> None:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ input –≤ chats"""
        print("üì• –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π...")

        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—É—Ç–∏ –≤ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–µ
        self.message_extractor.input_dir = Path(input_dir)
        self.message_extractor.chats_dir = Path(chats_dir)

        # –í—ã–ø–æ–ª–Ω—è–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ
        self.message_extractor.extract_all_messages(
            dry_run=dry_run, filter_by_date=filter_by_date, chat_filter=chat_filter
        )

        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.message_extractor.print_stats()

    async def deduplicate_messages(self, chats_dir: str = "chats") -> None:
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏–π"""
        print("üßπ –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏–π...")

        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—É—Ç—å –≤ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ç–æ—Ä–µ
        self.message_deduplicator.chats_dir = Path(chats_dir)

        # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é
        self.message_deduplicator.deduplicate_all_chats()

        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.message_deduplicator.print_stats()

    async def stop_indexing(self) -> None:
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
        print("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏...")
        ProcessManager.stop_all_indexing()


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description="Telegram Dump Manager")
    parser.add_argument(
        "command",
        choices=[
            "check",
            "stats",
            "extract-messages",
            "deduplicate",
            "stop-indexing",
        ],
        help="–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è",
    )
    parser.add_argument("--query", "-q", help="–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")
    parser.add_argument("--limit", "-l", type=int, default=10, help="–õ–∏–º–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    parser.add_argument(
        "--max-files", type=int, help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"
    )
    parser.add_argument(
        "--batch-size", type=int, default=100, help="–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"
    )
    parser.add_argument(
        "--dry-run", action="store_true", help="–†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π"
    )
    parser.add_argument(
        "--no-date-filter", action="store_true", help="–û—Ç–∫–ª—é—á–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ –¥–∞—Ç–µ"
    )
    parser.add_argument("--chat", help="–û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ —É–∫–∞–∑–∞–Ω–Ω—ã–π —á–∞—Ç")
    parser.add_argument("--input-dir", default="input", help="–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ input")
    parser.add_argument("--chats-dir", default="chats", help="–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ chats")

    args = parser.parse_args()

    async with TelegramDumpManager() as manager:
        if args.command == "check":
            await manager.check_system()

        elif args.command == "stats":
            await manager.get_stats()

        elif args.command == "extract-messages":
            await manager.extract_messages(
                dry_run=args.dry_run,
                filter_by_date=not args.no_date_filter,
                chat_filter=args.chat,
                input_dir=args.input_dir,
                chats_dir=args.chats_dir,
            )

        elif args.command == "deduplicate":
            await manager.deduplicate_messages(args.chats_dir)

        elif args.command == "stop-indexing":
            await manager.stop_indexing()


if __name__ == "__main__":
    asyncio.run(main())
