#!/usr/bin/env python3
"""
–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π Ollama
–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –ø—Ä–æ–µ–∫—Ç–∞ tg_dump
"""

import asyncio
import time
import json
import sys
import os
import aiohttp
import logging
from pathlib import Path
from typing import Dict, List, Any, Tuple
from dataclasses import dataclass, asdict
import statistics
from tqdm import tqdm

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.memory_mcp.core.ollama_client import OllamaEmbeddingClient


@dataclass
class BenchmarkResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –±–µ–Ω—á–º–∞—Ä–∫–∞ –¥–ª—è –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    model_name: str
    test_name: str
    duration: float
    success: bool
    error_message: str = ""
    tokens_per_second: float = 0.0
    quality_score: float = 0.0
    memory_usage_mb: float = 0.0
    additional_metrics: Dict[str, Any] = None


@dataclass
class ModelBenchmark:
    """–ü–æ–ª–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –º–æ–¥–µ–ª–∏"""
    model_name: str
    model_size_gb: float
    total_tests: int
    successful_tests: int
    average_duration: float
    median_duration: float
    min_duration: float
    max_duration: float
    average_tokens_per_second: float
    average_quality_score: float
    results: List[BenchmarkResult]


class ModelBenchmarker:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self):
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self._setup_logging()
        
        self.models = {
            "hf.co/lmstudio-community/Magistral-Small-2509-GGUF:Q4_K_M": 15.0,
            "dengcao/Qwen3-Embedding-4B:Q5_K_M": 2.9,
            "gemma3n:e4b-it-q8_0": 9.5,
            "gpt-oss-20b:latest": 12.0
        }
        self.ollama_base_url = "http://localhost:11434"
        self.max_context_tokens = 7000  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–æ 7–∫ —Ç–æ–∫–µ–Ω–æ–≤
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
        self.test_scenarios = {
            "short_text": "–ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ –∫–æ—Ä–æ—Ç–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.",
            "medium_text": """
            –í —á–∞—Ç–µ –æ–±—Å—É–∂–¥–∞–µ—Ç—Å—è –ø—Ä–æ–µ–∫—Ç –ø–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –º–æ–±–∏–ª—å–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è. 
            –£—á–∞—Å—Ç–Ω–∏–∫–∏ –æ–±—Å—É–∂–¥–∞—é—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã: –¥–∏–∑–∞–π–Ω –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞, —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å, 
            —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, —Å—Ä–æ–∫–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏. –ï—Å—Ç—å —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏—è –ø–æ –ø–æ–≤–æ–¥—É 
            –≤—ã–±–æ—Ä–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Å—Ç–µ–∫–∞. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç React Native, 
            –¥—Ä—É–≥–∏–µ - Flutter. –¢–∞–∫–∂–µ –æ–±—Å—É–∂–¥–∞–µ—Ç—Å—è –≤–æ–ø—Ä–æ—Å —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –∏ —Å–µ—Ä–≤–µ—Ä–Ω–æ–π —á–∞—Å—Ç—å—é.
            –ù—É–∂–Ω–æ –ø—Ä–∏–Ω—è—Ç—å —Ä–µ—à–µ–Ω–∏–µ –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∑–∞–¥–∞—á–∏ –º–µ–∂–¥—É —É—á–∞—Å—Ç–Ω–∏–∫–∞–º–∏.
            """,
            "long_text": """
            –≠—Ç–æ –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –º–æ–¥–µ–ª–µ–π.
            –í –Ω–µ–º —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –º–Ω–æ–∂–µ—Å—Ç–≤–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∞—Å–ø–µ–∫—Ç–∞—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è.
            
            –û–±—Å—É–∂–¥–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å–∏—Å—Ç–µ–º—ã:
            - –ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ vs –º–æ–Ω–æ–ª–∏—Ç–Ω–∞—è
            - –í—ã–±–æ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (PostgreSQL, MongoDB, Redis)
            - –°–∏—Å—Ç–µ–º–∞ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            - –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            - –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å –∏ –Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            
            –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏:
            - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Docker –¥–ª—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏–∏
            - CI/CD –ø–∞–π–ø–ª–∞–π–Ω—ã —Å GitHub Actions
            - –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é ELK Stack
            - API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é Swagger/OpenAPI
            - –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: unit, integration, e2e —Ç–µ—Å—Ç—ã
            
            –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞:
            - Agile –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è —Å –¥–≤—É—Ö–Ω–µ–¥–µ–ª—å–Ω—ã–º–∏ —Å–ø—Ä–∏–Ω—Ç–∞–º–∏
            - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∞–º–∏ –≤ Jira
            - Code review –ø—Ä–æ—Ü–µ—Å—Å
            - –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞ –≤ Confluence
            - –ö–æ–º–∞–Ω–¥–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –∏ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è –≤ Slack
            
            –†–∏—Å–∫–∏ –∏ –º–∏—Ç–∏–≥–∞—Ü–∏—è:
            - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏ –∏ —Å–ø–æ—Å–æ–±—ã –∏—Ö –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏
            - –í—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∏ –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á
            - –†–µ—Å—É—Ä—Å—ã –∫–æ–º–∞–Ω–¥—ã –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–æ–ª–µ–π
            - –ö–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
            - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∏ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ –ø–æ—Å–ª–µ —Ä–µ–ª–∏–∑–∞
            """ * 3,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç
            
            "russian_text": """
            –û–±—Å—É–∂–¥–µ–Ω–∏–µ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç –∏ –±–ª–æ–∫—á–µ–π–Ω —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –≤ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω–æ–º —Å–æ–æ–±—â–µ—Å—Ç–≤–µ.
            –£—á–∞—Å—Ç–Ω–∏–∫–∏ –¥–µ–ª—è—Ç—Å—è –º–Ω–µ–Ω–∏—è–º–∏ –æ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–∞—Ö, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—Ç —Ä—ã–Ω–æ–∫,
            –æ–±—Å—É–∂–¥–∞—é—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏.
            
            –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã:
            - –ê–Ω–∞–ª–∏–∑ –∫—É—Ä—Å–æ–≤ Bitcoin, Ethereum –∏ –¥—Ä—É–≥–∏—Ö –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç
            - –ù–æ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã –≤ —Å—Ñ–µ—Ä–µ DeFi –∏ NFT
            - –†–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç –≤ —Ä–∞–∑–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∞—Ö
            - –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ —Ç–æ—Ä–≥–æ–≤–ª–∏ —Ü–∏—Ñ—Ä–æ–≤—ã–º–∏ –∞–∫—Ç–∏–≤–∞–º–∏
            - –ú–∞–π–Ω–∏–Ω–≥ –∏ —Å—Ç–µ–π–∫–∏–Ω–≥ –∫–∞–∫ —Å–ø–æ—Å–æ–±—ã –∑–∞—Ä–∞–±–æ—Ç–∫–∞
            
            –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã:
            - –°–º–∞—Ä—Ç-–∫–æ–Ω—Ç—Ä–∞–∫—Ç—ã –∏ –∏—Ö –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ
            - –°–ª–æ–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è (Layer 2 —Ä–µ—à–µ–Ω–∏—è)
            - –ú–µ–∂–±–ª–æ—á–Ω—ã–µ –º–æ—Å—Ç—ã –∏ –∞—Ç–æ–º–∞—Ä–Ω—ã–µ —Å–≤–æ–ø—ã
            - –ö–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å –∏ –∞–Ω–æ–Ω–∏–º–Ω–æ—Å—Ç—å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
            - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –±–ª–æ–∫—á–µ–π–Ω–∞ —Å —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏
            """,
            
            "code_discussion": """
            –û–±—Å—É–∂–¥–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏:
            
            ```python
            def process_telegram_messages(messages):
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π Telegram
                processed = []
                for msg in messages:
                    if msg.get('text'):
                        processed.append({
                            'id': msg['id'],
                            'text': msg['text'],
                            'timestamp': msg['date']
                        })
                return processed
            ```
            
            –ù—É–∂–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–æ—Ç –∫–æ–¥ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–æ–ª—å—à–∏–º–∏ –æ–±—ä–µ–º–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö.
            –†–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç—Å—è –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è asyncio, multiprocessing,
            –∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.
            """,
            
            "multilingual_text": """
            International discussion about technology trends:
            - Artificial Intelligence and Machine Learning developments
            - Cloud computing and serverless architectures
            - Mobile app development with React Native and Flutter
            - Web development with modern frameworks like Next.js
            
            –û–±—Å—É–∂–¥–µ–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:
            - –†–∞–∑–≤–∏—Ç–∏–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
            - –û–±–ª–∞—á–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏ –±–µ—Å—Å–µ—Ä–≤–µ—Ä–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
            - –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π
            - –í–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞–º–∏
            """
        }
        
        # –û–±—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –¥–æ 7–∫ —Ç–æ–∫–µ–Ω–æ–≤ (–ø—Ä–∏–º–µ—Ä–Ω–æ 28–∫ —Å–∏–º–≤–æ–ª–æ–≤)
        self._truncate_test_scenarios()
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        self.embedding_queries = [
            "–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã –∏ –±–ª–æ–∫—á–µ–π–Ω",
            "—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π", 
            "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç",
            "–æ–±–ª–∞—á–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
            "–≤–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞",
            "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ",
            "–±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö",
            "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"
        ]

    def _setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        log_file = log_dir / f"benchmark_{timestamp}.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–∞ –º–æ–¥–µ–ª–µ–π Ollama")
        self.logger.info(f"üìù –õ–æ–≥–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤: {log_file.absolute()}")

    def _truncate_test_scenarios(self):
        """–û–±—Ä–µ–∑–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –¥–æ 7–∫ —Ç–æ–∫–µ–Ω–æ–≤ (–ø—Ä–∏–º–µ—Ä–Ω–æ 28–∫ —Å–∏–º–≤–æ–ª–æ–≤)"""
        max_chars = self.max_context_tokens * 4  # –ü—Ä–∏–º–µ—Ä–Ω–æ 4 —Å–∏–º–≤–æ–ª–∞ –Ω–∞ —Ç–æ–∫–µ–Ω
        
        for key, text in self.test_scenarios.items():
            if len(text) > max_chars:
                self.test_scenarios[key] = text[:max_chars] + "\n\n[–¢–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞]"

    async def unload_current_model(self):
        """–í—ã–≥—Ä—É–∂–∞–µ—Ç —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å –∏–∑ –ø–∞–º—è—Ç–∏ Ollama"""
        try:
            self.logger.info("üîÑ –í—ã–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å –∏–∑ –ø–∞–º—è—Ç–∏...")
            async with aiohttp.ClientSession() as session:
                async with session.post(f"{self.ollama_base_url}/api/generate", 
                                      json={"model": "", "prompt": "", "stream": False}) as response:
                    if response.status == 200:
                        print("  üîÑ –ú–æ–¥–µ–ª—å –≤—ã–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ –ø–∞–º—è—Ç–∏")
                        self.logger.info("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –≤—ã–≥—Ä—É–∂–µ–Ω–∞")
                    else:
                        print(f"  ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {response.status}")
                        self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {response.status}")
        except Exception as e:
            print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")

    async def load_model(self, model_name: str) -> bool:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –≤ –ø–∞–º—è—Ç—å Ollama"""
        try:
            print(f"  üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å: {model_name}")
            self.logger.info(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å: {model_name}")
            
            async with aiohttp.ClientSession() as session:
                # –°–Ω–∞—á–∞–ª–∞ –≤—ã–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å
                await self.unload_current_model()
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å –ø—Ä–æ—Å—Ç—ã–º –∑–∞–ø—Ä–æ—Å–æ–º
                self.logger.info(f"üîÑ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {model_name}")
                async with session.post(f"{self.ollama_base_url}/api/generate", 
                                      json={
                                          "model": model_name, 
                                          "prompt": "test", 
                                          "stream": False,
                                          "options": {"num_ctx": self.max_context_tokens}
                                      }) as response:
                    if response.status == 200:
                        print(f"  ‚úÖ –ú–æ–¥–µ–ª—å {model_name} –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                        self.logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                        return True
                    else:
                        print(f"  ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {response.status}")
                        self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {model_name}: {response.status}")
                        return False
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏ {model_name}: {e}")
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏ {model_name}: {e}")
            return False

    async def test_model_availability(self, model_name: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        try:
            async with OllamaEmbeddingClient() as client:
                result = await client.test_connection()
                return result.get("model_available", False)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ–¥–µ–ª–∏ {model_name}: {e}")
            return False

    async def benchmark_text_generation(self, model_name: str, text: str, test_name: str) -> BenchmarkResult:
        """–ë–µ–Ω—á–º–∞—Ä–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞/—Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏"""
        start_time = time.time()
        self.logger.info(f"üî§ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ {test_name} –¥–ª—è –º–æ–¥–µ–ª–∏ {model_name}")
        
        try:
            # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            async with OllamaEmbeddingClient(model_name=model_name) as client:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—é
                self.logger.debug(f"üìù –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—é –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –¥–ª–∏–Ω–æ–π {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
                summary = await client.generate_summary(text)
                duration = time.time() - start_time
                
                # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ (–ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞)
                quality_score = self._evaluate_summary_quality(text, summary)
                
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã –≤ —Å–µ–∫—É–Ω–¥—É (–ø—Ä–∏–º–µ—Ä–Ω–æ)
                estimated_tokens = len(text.split()) + len(summary.split())
                tokens_per_second = estimated_tokens / duration if duration > 0 else 0
                
                self.logger.info(f"‚úÖ –¢–µ—Å—Ç {test_name} –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {duration:.2f}—Å, –∫–∞—á–µ—Å—Ç–≤–æ: {quality_score:.3f}")
                
                return BenchmarkResult(
                    model_name=model_name,
                    test_name=test_name,
                    duration=duration,
                    success=True,
                    tokens_per_second=tokens_per_second,
                    quality_score=quality_score,
                    additional_metrics={
                        "input_length": len(text),
                        "output_length": len(summary),
                        "summary": summary[:200] + "..." if len(summary) > 200 else summary
                    }
                )
                
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–µ {test_name}: {e}")
            return BenchmarkResult(
                model_name=model_name,
                test_name=test_name,
                duration=time.time() - start_time,
                success=False,
                error_message=str(e)
            )

    async def benchmark_embeddings(self, model_name: str, texts: List[str], test_name: str) -> BenchmarkResult:
        """–ë–µ–Ω—á–º–∞—Ä–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        start_time = time.time()
        
        try:
            # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
            async with OllamaEmbeddingClient(model_name=model_name) as client:
                embeddings = await client.generate_embeddings(texts)
                duration = time.time() - start_time
                
                # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (—Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –ø–æ—Ö–æ–∂–∏–º–∏ —Ç–µ–∫—Å—Ç–∞–º–∏)
                quality_score = self._evaluate_embedding_quality(embeddings, texts)
                
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã –≤ —Å–µ–∫—É–Ω–¥—É
                total_tokens = sum(len(text.split()) for text in texts)
                tokens_per_second = total_tokens / duration if duration > 0 else 0
                
                return BenchmarkResult(
                    model_name=model_name,
                    test_name=test_name,
                    duration=duration,
                    success=True,
                    tokens_per_second=tokens_per_second,
                    quality_score=quality_score,
                    additional_metrics={
                        "embedding_dimension": len(embeddings[0]) if embeddings else 0,
                        "num_embeddings": len(embeddings),
                        "total_input_length": sum(len(text) for text in texts)
                    }
                )
                
        except Exception as e:
            return BenchmarkResult(
                model_name=model_name,
                test_name=test_name,
                duration=time.time() - start_time,
                success=False,
                error_message=str(e)
            )

    def _evaluate_summary_quality(self, original_text: str, summary: str) -> float:
        """–ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏"""
        if not summary:
            return 0.0
            
        # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        compression_ratio = len(summary) / len(original_text) if len(original_text) > 0 else 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
        original_words = set(original_text.lower().split())
        summary_words = set(summary.lower().split())
        keyword_overlap = len(original_words.intersection(summary_words)) / len(original_words) if original_words else 0
        
        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ (0-1)
        quality_score = min(1.0, keyword_overlap * 0.7 + (1 - compression_ratio) * 0.3)
        return quality_score

    def _evaluate_embedding_quality(self, embeddings: List[List[float]], texts: List[str]) -> float:
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ –∞–Ω–∞–ª–∏–∑ —Å—Ö–æ–¥—Å—Ç–≤–∞"""
        if len(embeddings) < 2:
            return 0.0
            
        try:
            import numpy as np
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏
            similarities = []
            for i in range(len(embeddings)):
                for j in range(i + 1, len(embeddings)):
                    emb1 = np.array(embeddings[i])
                    emb2 = np.array(embeddings[j])
                    
                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ–∫—Ç–æ—Ä—ã
                    norm1 = np.linalg.norm(emb1)
                    norm2 = np.linalg.norm(emb2)
                    
                    if norm1 > 0 and norm2 > 0:
                        similarity = np.dot(emb1, emb2) / (norm1 * norm2)
                        similarities.append(similarity)
            
            if similarities:
                # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–±—Ä–æ—Å–∞ —Å—Ö–æ–¥—Å—Ç–≤
                mean_similarity = np.mean(similarities)
                std_similarity = np.std(similarities)
                
                # –•–æ—Ä–æ—à–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å —Ä–∞–∑—É–º–Ω—ã–π —Ä–∞–∑–±—Ä–æ—Å —Å—Ö–æ–¥—Å—Ç–≤
                quality_score = min(1.0, max(0.0, 1 - std_similarity))
                return quality_score
            
        except ImportError:
            # –ï—Å–ª–∏ numpy –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é –æ—Ü–µ–Ω–∫—É
            return 0.5
            
        return 0.0

    async def run_comprehensive_benchmark(self) -> Dict[str, ModelBenchmark]:
        """–ó–∞–ø—É—Å–∫ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –±–µ–Ω—á–º–∞—Ä–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        print("üöÄ –ó–∞–ø—É—Å–∫ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –±–µ–Ω—á–º–∞—Ä–∫–∞ –º–æ–¥–µ–ª–µ–π Ollama")
        print(f"üìè –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {self.max_context_tokens} —Ç–æ–∫–µ–Ω–æ–≤")
        print("=" * 60)
        
        self.logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π")
        self.logger.info(f"üìè –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {self.max_context_tokens} —Ç–æ–∫–µ–Ω–æ–≤")
        
        results = {}
        total_models = len(self.models)
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è –º–æ–¥–µ–ª–µ–π
        model_progress = tqdm(self.models.items(), 
                            desc="ü§ñ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π", 
                            unit="–º–æ–¥–µ–ª—å",
                            total=total_models)
        
        for model_name, model_size in model_progress:
            model_progress.set_description(f"ü§ñ –¢–µ—Å—Ç–∏—Ä—É–µ–º {model_name.split('/')[-1]}")
            
            print(f"\nüìä –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_name}")
            print(f"üì¶ –†–∞–∑–º–µ—Ä: {model_size} GB")
            print("-" * 50)
            
            self.logger.info(f"üìä –ù–∞—á–∏–Ω–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_name} ({model_size} GB)")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            if not await self.load_model(model_name):
                print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å {model_name}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                self.logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å {model_name}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue
            
            model_results = []
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ø–∏—Å–æ–∫ —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            tests = [
                ("short_text_summarization", "üî§ –¢–µ—Å—Ç 1: –°–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞", "short_text"),
                ("medium_text_summarization", "üìù –¢–µ—Å—Ç 2: –°–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Å—Ä–µ–¥–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞", "medium_text"),
                ("long_text_summarization", "üìÑ –¢–µ—Å—Ç 3: –°–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞", "long_text"),
                ("russian_text_summarization", "üá∑üá∫ –¢–µ—Å—Ç 4: –°–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞", "russian_text"),
                ("code_discussion_summarization", "üíª –¢–µ—Å—Ç 5: –°–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞", "code_discussion"),
                ("short_embeddings", "üî¢ –¢–µ—Å—Ç 6: –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤", "embedding_short"),
                ("all_embeddings", "üî¢ –¢–µ—Å—Ç 7: –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤", "embedding_all"),
                ("parallel_processing", "‚ö° –¢–µ—Å—Ç 8: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞", "parallel")
            ]
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è —Ç–µ—Å—Ç–æ–≤
            test_progress = tqdm(tests, desc="üß™ –¢–µ—Å—Ç—ã", unit="—Ç–µ—Å—Ç", leave=False)
            
            for test_id, test_description, test_type in test_progress:
                test_progress.set_description(test_description)
                print(f"{test_description}...")
                
                if test_type == "embedding_short":
                    result = await self.benchmark_embeddings(
                        model_name, 
                        self.embedding_queries[:4], 
                        test_id
                    )
                elif test_type == "embedding_all":
                    result = await self.benchmark_embeddings(
                        model_name, 
                        self.embedding_queries, 
                        test_id
                    )
                elif test_type == "parallel":
                    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
                    parallel_start = time.time()
                    tasks = []
                    for i, scenario_name in enumerate(["short_text", "medium_text", "russian_text"]):
                        task = self.benchmark_text_generation(
                            model_name, 
                            self.test_scenarios[scenario_name], 
                            f"parallel_test_{i}"
                        )
                        tasks.append(task)
                    
                    parallel_results = await asyncio.gather(*tasks, return_exceptions=True)
                    parallel_duration = time.time() - parallel_start
                    
                    # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞
                    successful_parallel = sum(1 for r in parallel_results if isinstance(r, BenchmarkResult) and r.success)
                    result = BenchmarkResult(
                        model_name=model_name,
                        test_name=test_id,
                        duration=parallel_duration,
                        success=successful_parallel > 0,
                        tokens_per_second=sum(r.tokens_per_second for r in parallel_results if isinstance(r, BenchmarkResult)) / len(parallel_results),
                        quality_score=sum(r.quality_score for r in parallel_results if isinstance(r, BenchmarkResult)) / len(parallel_results),
                        additional_metrics={
                            "successful_tasks": successful_parallel,
                            "total_tasks": len(tasks)
                        }
                    )
                else:
                    # –û–±—ã—á–Ω—ã–µ —Ç–µ—Å—Ç—ã —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
                    result = await self.benchmark_text_generation(
                        model_name, 
                        self.test_scenarios[test_type], 
                        test_id
                    )
                
                model_results.append(result)
                self._print_test_result(result)
            
            
            # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–∫—É –ø–æ –º–æ–¥–µ–ª–∏
            successful_results = [r for r in model_results if r.success]
            durations = [r.duration for r in successful_results]
            tokens_per_sec = [r.tokens_per_second for r in successful_results]
            quality_scores = [r.quality_score for r in successful_results]
            
            model_benchmark = ModelBenchmark(
                model_name=model_name,
                model_size_gb=model_size,
                total_tests=len(model_results),
                successful_tests=len(successful_results),
                average_duration=statistics.mean(durations) if durations else 0,
                median_duration=statistics.median(durations) if durations else 0,
                min_duration=min(durations) if durations else 0,
                max_duration=max(durations) if durations else 0,
                average_tokens_per_second=statistics.mean(tokens_per_sec) if tokens_per_sec else 0,
                average_quality_score=statistics.mean(quality_scores) if quality_scores else 0,
                results=model_results
            )
            
            results[model_name] = model_benchmark
            
            print(f"\n‚úÖ –ú–æ–¥–µ–ª—å {model_name} –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∞")
            print(f"üìä –£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {model_benchmark.successful_tests}/{model_benchmark.total_tests}")
            print(f"‚è±Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {model_benchmark.average_duration:.2f}—Å")
            print(f"üéØ –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {model_benchmark.average_quality_score:.3f}")
            
            self.logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∞")
            self.logger.info(f"üìä –£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {model_benchmark.successful_tests}/{model_benchmark.total_tests}")
            self.logger.info(f"‚è±Ô∏è –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {model_benchmark.average_duration:.2f}—Å")
            self.logger.info(f"üéØ –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {model_benchmark.average_quality_score:.3f}")
            
            # –í—ã–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ø–æ—Å–ª–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            await self.unload_current_model()
        
        return results

    def _print_test_result(self, result: BenchmarkResult):
        """–í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ç–µ—Å—Ç–∞"""
        if result.success:
            print(f"  ‚úÖ {result.test_name}: {result.duration:.2f}—Å, "
                  f"{result.tokens_per_second:.1f} —Ç–æ–∫/—Å, –∫–∞—á–µ—Å—Ç–≤–æ: {result.quality_score:.3f}")
        else:
            print(f"  ‚ùå {result.test_name}: –û–®–ò–ë–ö–ê - {result.error_message}")

    def generate_report(self, results: Dict[str, ModelBenchmark]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –±–µ–Ω—á–º–∞—Ä–∫–∞"""
        report = []
        report.append("# üìä –û—Ç—á–µ—Ç –ø–æ –±–µ–Ω—á–º–∞—Ä–∫—É –º–æ–¥–µ–ª–µ–π Ollama")
        report.append("=" * 60)
        report.append("")
        
        # –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
        report.append("## üìã –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        report.append("")
        report.append("| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä (GB) | –¢–µ—Å—Ç—ã | –£—Å–ø–µ—Ö | –°—Ä. –≤—Ä–µ–º—è (—Å) | –°—Ä. —Ç–æ–∫/—Å | –ö–∞—á–µ—Å—Ç–≤–æ |")
        report.append("|--------|-------------|-------|-------|---------------|-----------|----------|")
        
        for model_name, benchmark in results.items():
            report.append(f"| {model_name.split('/')[-1]} | {benchmark.model_size_gb} | "
                         f"{benchmark.total_tests} | {benchmark.successful_tests} | "
                         f"{benchmark.average_duration:.2f} | {benchmark.average_tokens_per_second:.1f} | "
                         f"{benchmark.average_quality_score:.3f} |")
        
        report.append("")
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
        for model_name, benchmark in results.items():
            report.append(f"## ü§ñ {model_name}")
            report.append("")
            report.append(f"**–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏:** {benchmark.model_size_gb} GB")
            report.append(f"**–£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤:** {benchmark.successful_tests}/{benchmark.total_tests}")
            report.append(f"**–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:** {benchmark.average_duration:.2f} —Å–µ–∫—É–Ω–¥")
            report.append(f"**–ú–µ–¥–∏–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è:** {benchmark.median_duration:.2f} —Å–µ–∫—É–Ω–¥")
            report.append(f"**–î–∏–∞–ø–∞–∑–æ–Ω –≤—Ä–µ–º–µ–Ω–∏:** {benchmark.min_duration:.2f} - {benchmark.max_duration:.2f} —Å–µ–∫—É–Ω–¥")
            report.append(f"**–°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å:** {benchmark.average_tokens_per_second:.1f} —Ç–æ–∫–µ–Ω–æ–≤/—Å–µ–∫—É–Ω–¥–∞")
            report.append(f"**–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞:** {benchmark.average_quality_score:.3f}")
            report.append("")
            
            # –î–µ—Ç–∞–ª–∏ –ø–æ –∫–∞–∂–¥–æ–º—É —Ç–µ—Å—Ç—É
            report.append("### üìù –î–µ—Ç–∞–ª–∏ —Ç–µ—Å—Ç–æ–≤:")
            report.append("")
            for result in benchmark.results:
                status = "‚úÖ" if result.success else "‚ùå"
                report.append(f"- {status} **{result.test_name}**: {result.duration:.2f}—Å")
                if result.success:
                    report.append(f"  - –°–∫–æ—Ä–æ—Å—Ç—å: {result.tokens_per_second:.1f} —Ç–æ–∫/—Å")
                    report.append(f"  - –ö–∞—á–µ—Å—Ç–≤–æ: {result.quality_score:.3f}")
                    if result.additional_metrics:
                        for key, value in result.additional_metrics.items():
                            report.append(f"  - {key}: {value}")
                else:
                    report.append(f"  - –û—à–∏–±–∫–∞: {result.error_message}")
            report.append("")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        report.append("## üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
        report.append("")
        
        # –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ —Å–∫–æ—Ä–æ—Å—Ç–∏
        fastest_model = min(results.values(), key=lambda x: x.average_duration)
        report.append(f"**‚ö° –°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å:** {fastest_model.model_name}")
        report.append(f"   - –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {fastest_model.average_duration:.2f} —Å–µ–∫—É–Ω–¥")
        report.append("")
        
        # –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
        best_quality_model = max(results.values(), key=lambda x: x.average_quality_score)
        report.append(f"**üèÜ –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ:** {best_quality_model.model_name}")
        report.append(f"   - –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {best_quality_model.average_quality_score:.3f}")
        report.append("")
        
        # –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—é —Å–∫–æ—Ä–æ—Å—Ç—å/–∫–∞—á–µ—Å—Ç–≤–æ
        balanced_scores = []
        for model_name, benchmark in results.items():
            if benchmark.average_quality_score > 0 and benchmark.average_tokens_per_second > 0:
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∏ –≤—ã—á–∏—Å–ª—è–µ–º –±–∞–ª–∞–Ω—Å
                speed_score = benchmark.average_tokens_per_second / max(b.average_tokens_per_second for b in results.values())
                quality_score = benchmark.average_quality_score / max(b.average_quality_score for b in results.values())
                balance_score = (speed_score + quality_score) / 2
                balanced_scores.append((model_name, balance_score))
        
        if balanced_scores:
            best_balanced = max(balanced_scores, key=lambda x: x[1])
            report.append(f"**‚öñÔ∏è –õ—É—á—à–∏–π –±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç—å/–∫–∞—á–µ—Å—Ç–≤–æ:** {best_balanced[0]}")
            report.append(f"   - –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: {best_balanced[1]:.3f}")
            report.append("")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
        report.append("### üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é:")
        report.append("")
        report.append("- **–î–ª—è –±—ã—Å—Ç—Ä–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏:** –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–∞–º—É—é –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å")
        report.append("- **–î–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:** –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º")
        report.append("- **–î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞:** —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º –±–∞–ª–∞–Ω—Å–æ–º")
        report.append("- **–î–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤:** –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á")
        report.append("")
        
        return "\n".join(report)

    async def save_results(self, results: Dict[str, ModelBenchmark], filename: str = None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON —Ñ–∞–π–ª"""
        if filename is None:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"benchmark_results_{timestamp}.json"
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
        serializable_results = {}
        for model_name, benchmark in results.items():
            serializable_results[model_name] = {
                "model_name": benchmark.model_name,
                "model_size_gb": benchmark.model_size_gb,
                "total_tests": benchmark.total_tests,
                "successful_tests": benchmark.successful_tests,
                "average_duration": benchmark.average_duration,
                "median_duration": benchmark.median_duration,
                "min_duration": benchmark.min_duration,
                "max_duration": benchmark.max_duration,
                "average_tokens_per_second": benchmark.average_tokens_per_second,
                "average_quality_score": benchmark.average_quality_score,
                "results": [asdict(result) for result in benchmark.results]
            }
        
        filepath = Path(filename)
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, ensure_ascii=False, indent=2)
        
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {filepath.absolute()}")


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫–∞"""
    benchmarker = ModelBenchmarker()
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫
        benchmarker.logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –±–µ–Ω—á–º–∞—Ä–∫–∞")
        results = await benchmarker.run_comprehensive_benchmark()
        
        if not results:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏")
            benchmarker.logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏")
            return
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        benchmarker.logger.info("üìä –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º")
        report = benchmarker.generate_report(results)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        await benchmarker.save_results(results)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        report_filename = f"benchmark_report_{timestamp}.md"
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"\nüìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {report_filename}")
        benchmarker.logger.info(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {report_filename}")
        
        # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É
        print("\n" + "="*60)
        print("üéâ –ë–ï–ù–ß–ú–ê–†–ö –ó–ê–í–ï–†–®–ï–ù!")
        print("="*60)
        benchmarker.logger.info("üéâ –ë–µ–Ω—á–º–∞—Ä–∫ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        
        for model_name, benchmark in results.items():
            print(f"\nü§ñ {model_name.split('/')[-1]}:")
            print(f"   ‚è±Ô∏è  –í—Ä–µ–º—è: {benchmark.average_duration:.2f}—Å")
            print(f"   üéØ –ö–∞—á–µ—Å—Ç–≤–æ: {benchmark.average_quality_score:.3f}")
            print(f"   ‚ö° –°–∫–æ—Ä–æ—Å—Ç—å: {benchmark.average_tokens_per_second:.1f} —Ç–æ–∫/—Å")
            print(f"   ‚úÖ –£—Å–ø–µ—Ö: {benchmark.successful_tests}/{benchmark.total_tests}")
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  –ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        benchmarker.logger.warning("‚èπÔ∏è –ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –±–µ–Ω—á–º–∞—Ä–∫–∞: {e}")
        benchmarker.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –±–µ–Ω—á–º–∞—Ä–∫–∞: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
