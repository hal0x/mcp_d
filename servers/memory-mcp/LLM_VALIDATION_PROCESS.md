# Детальное описание процесса LLM валидации сущностей

## Обзор процесса

LLM валидация происходит в момент, когда сущность достигает порога частоты (например, 5 раз для имен) и должна быть добавлена в словарь. Вместо автоматического добавления, система отправляет запрос к LLM для проверки, является ли это действительно валидной сущностью.

## Пошаговый процесс

### Шаг 1: Триггер валидации

Валидация запускается в методе `track_entity()` класса `EntityDictionary`:

```python
def track_entity(self, entity_type: str, value: str, chat_name: str) -> bool:
    # ... нормализация и подсчет частоты ...
    
    if total_count >= threshold and normalized_value not in self.learned_dictionaries[entity_type]:
        # Валидация через LLM перед добавлением в словарь
        if self.enable_llm_validation:
            is_valid = self._validate_entity_with_llm(entity_type, normalized_value, value)
            if not is_valid:
                return False  # Сущность отклонена
        
        # Добавляем в словарь только если валидна
        self.learned_dictionaries[entity_type].add(normalized_value)
        return True
```

### Шаг 2: Формирование промпта

Система формирует промпт на основе типа сущности и значения:

```python
entity_type_names = {
    "persons": "имя человека",
    "organizations": "название организации",
    "locations": "название места/локации",
    "crypto_tokens": "криптовалютный токен",
    "telegram_channels": "Telegram канал",
    "telegram_bots": "Telegram бот",
    "crypto_addresses": "криптовалютный адрес",
    "domains": "доменное имя",
}

type_name = entity_type_names.get(entity_type, entity_type)

prompt = f"""Ты эксперт по анализу текста. Определи, является ли данное слово/фраза действительно {type_name}.

Слово/фраза для проверки: "{original_value}" (нормализованное: "{normalized_value}")

Правила:
1. Для типа "{entity_type}": это должно быть действительно {type_name}, а не обычное слово, глагол, прилагательное или другое слово общего назначения.
2. Исключи мат, грубые слова, времена года, дни недели, обычные глаголы и прилагательные.
3. Если это сокращение или опечатка - отклони.
4. Если это имя собственное (начинается с заглавной буквы) и соответствует типу - прими.

Ответь ТОЛЬКО одним словом: "ДА" если это валидная {type_name}, или "НЕТ" если это не валидная {type_name}.
Не добавляй никаких объяснений, только "ДА" или "НЕТ"."""
```

### Шаг 3: Выбор LLM клиента

Система автоматически выбирает доступный LLM:

1. **Проверка LM Studio** (приоритет 1):
   ```python
   if settings.lmstudio_llm_model:
       llm_client = LMStudioEmbeddingClient(
           model_name=settings.lmstudio_model,
           llm_model_name=settings.lmstudio_llm_model,  # Для генерации текста
           base_url=f"http://{settings.lmstudio_host}:{settings.lmstudio_port}"
       )
   ```

2. **Fallback на Ollama** (приоритет 2):
   ```python
   else:
       qa_settings = get_quality_analysis_settings()
       llm_client = OllamaEmbeddingClient(
           llm_model_name=qa_settings.ollama_model,
           base_url=qa_settings.ollama_base_url
       )
   ```

### Шаг 4: Отправка запроса к LLM

Запрос отправляется через метод `generate_summary()`:

```python
async with llm_client:
    response = await llm_client.generate_summary(
        prompt=prompt,
        temperature=0.1,      # Низкая температура для детерминированных ответов
        max_tokens=10,        # Нужен только "ДА" или "НЕТ"
        top_p=0.9,
        presence_penalty=0.0,
    )
```

**Для LM Studio** это POST запрос к `/v1/chat/completions`:
```json
{
  "model": "gpt-oss-20b",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful AI assistant..."
    },
    {
      "role": "user",
      "content": "Ты эксперт по анализу текста. Определи, является ли данное слово/фраза действительно имя человека.\n\nСлово/фраза для проверки: \"походила\" (нормализованное: \"походила\")\n\n..."
    }
  ],
  "temperature": 0.1,
  "max_tokens": 10,
  "top_p": 0.9,
  "presence_penalty": 0.0,
  "stream": false
}
```

**Для Ollama** это POST запрос к `/api/generate`:
```json
{
  "model": "gpt-oss-20b:latest",
  "prompt": "Ты эксперт по анализу текста...",
  "temperature": 0.1,
  "num_predict": 10,
  "top_p": 0.9
}
```

### Шаг 5: Обработка ответа

Ответ парсится для извлечения решения:

```python
response_clean = response.strip().upper()

if "ДА" in response_clean or "YES" in response_clean:
    return True   # Сущность валидна, добавляем в словарь
elif "НЕТ" in response_clean or "NO" in response_clean:
    return False  # Сущность не валидна, отклоняем
else:
    # Неоднозначный ответ - разрешаем (консервативный подход)
    logger.debug(f"Неоднозначный ответ LLM: '{response}'. Разрешаем добавление.")
    return True
```

## Примеры валидации

### Пример 1: Глагол "походила"

**Входные данные:**
- `entity_type`: "persons"
- `original_value`: "походила"
- `normalized_value`: "походила"
- `total_count`: 5 (достиг порога)

**Промпт:**
```
Ты эксперт по анализу текста. Определи, является ли данное слово/фраза действительно имя человека.

Слово/фраза для проверки: "походила" (нормализованное: "походила")

Правила:
1. Для типа "persons": это должно быть действительно имя человека, а не обычное слово, глагол, прилагательное или другое слово общего назначения.
2. Исключи мат, грубые слова, времена года, дни недели, обычные глаголы и прилагательные.
3. Если это сокращение или опечатка - отклони.
4. Если это имя собственное (начинается с заглавной буквы) и соответствует типу - прими.

Ответь ТОЛЬКО одним словом: "ДА" если это валидная имя человека, или "НЕТ" если это не валидная имя человека.
Не добавляй никаких объяснений, только "ДА" или "НЕТ".
```

**Ответ LLM:** "НЕТ"

**Результат:** Сущность отклонена, не добавляется в словарь ✅

---

### Пример 2: Правильное имя "Иван"

**Входные данные:**
- `entity_type`: "persons"
- `original_value`: "Иван"
- `normalized_value`: "иван"
- `total_count`: 5 (достиг порога)

**Промпт:**
```
Ты эксперт по анализу текста. Определи, является ли данное слово/фраза действительно имя человека.

Слово/фраза для проверки: "Иван" (нормализованное: "иван")

Правила:
1. Для типа "persons": это должно быть действительно имя человека, а не обычное слово, глагол, прилагательное или другое слово общего назначения.
2. Исключи мат, грубые слова, времена года, дни недели, обычные глаголы и прилагательные.
3. Если это сокращение или опечатка - отклони.
4. Если это имя собственное (начинается с заглавной буквы) и соответствует типу - прими.

Ответь ТОЛЬКО одним словом: "ДА" если это валидная имя человека, или "НЕТ" если это не валидная имя человека.
Не добавляй никаких объяснений, только "ДА" или "НЕТ".
```

**Ответ LLM:** "ДА"

**Результат:** Сущность валидна, добавляется в словарь ✅

---

### Пример 3: Организация "Сбербанк"

**Входные данные:**
- `entity_type`: "organizations"
- `original_value`: "Сбербанк"
- `normalized_value`: "сбербанк"
- `total_count`: 4 (достиг порога)

**Промпт:**
```
Ты эксперт по анализу текста. Определи, является ли данное слово/фраза действительно название организации.

Слово/фраза для проверки: "Сбербанк" (нормализованное: "сбербанк")

Правила:
1. Для типа "organizations": это должно быть действительно название организации, а не обычное слово, глагол, прилагательное или другое слово общего назначения.
2. Исключи мат, грубые слова, времена года, дни недели, обычные глаголы и прилагательные.
3. Если это сокращение или опечатка - отклони.
4. Если это имя собственное (начинается с заглавной буквы) и соответствует типу - прими.

Ответь ТОЛЬКО одним словом: "ДА" если это валидная название организации, или "НЕТ" если это не валидная название организации.
Не добавляй никаких объяснений, только "ДА" или "НЕТ".
```

**Ответ LLM:** "ДА"

**Результат:** Сущность валидна, добавляется в словарь ✅

---

### Пример 4: Сомнительное слово "Саш"

**Входные данные:**
- `entity_type`: "persons"
- `original_value`: "Саш"
- `normalized_value`: "саш"
- `total_count`: 5 (достиг порога)

**Промпт:**
```
Ты эксперт по анализу текста. Определи, является ли данное слово/фраза действительно имя человека.

Слово/фраза для проверки: "Саш" (нормализованное: "саш")

Правила:
1. Для типа "persons": это должно быть действительно имя человека, а не обычное слово, глагол, прилагательное или другое слово общего назначения.
2. Исключи мат, грубые слова, времена года, дни недели, обычные глаголы и прилагательные.
3. Если это сокращение или опечатка - отклони.
4. Если это имя собственное (начинается с заглавной буквы) и соответствует типу - прими.

Ответь ТОЛЬКО одним словом: "ДА" если это валидная имя человека, или "НЕТ" если это не валидная имя человека.
Не добавляй никаких объяснений, только "ДА" или "НЕТ".
```

**Ответ LLM:** "НЕТ" (распознано как сокращение или опечатка)

**Результат:** Сущность отклонена, не добавляется в словарь ✅

## Технические детали

### Асинхронная обработка

Валидация выполняется асинхронно через `_validate_entity_with_llm_async()`, но вызывается синхронно через обертку `_validate_entity_with_llm()`, которая:

1. Проверяет наличие event loop
2. Если loop запущен → создает новый в отдельном потоке
3. Если loop не запущен → использует существующий
4. Если нет loop → создает новый через `asyncio.run()`

### Таймауты и обработка ошибок

- **Таймаут**: 5 секунд на валидацию одной сущности
- **При ошибке**: валидация пропускается, сущность разрешается (консервативный подход)
- **При недоступности LLM**: валидация пропускается, сущность разрешается

### Параметры запроса

- **temperature**: 0.1 (низкая для детерминированных ответов)
- **max_tokens**: 10 (нужен только "ДА" или "НЕТ")
- **top_p**: 0.9
- **presence_penalty**: 0.0

## Преимущества подхода

1. **Контекстное понимание**: LLM понимает семантику, а не только правила
2. **Гибкость**: Может обрабатывать сложные случаи
3. **Точность**: Значительно снижает ложные срабатывания
4. **Надежность**: При ошибке система продолжает работать

## Логирование

Валидация логируется на уровне DEBUG:

```python
logger.debug(
    f"Сущность отклонена LLM: {entity_type}={normalized_value} "
    f"(встречается {total_count} раз, но не прошла валидацию)"
)
```

Для включения логов валидации установите уровень логирования на DEBUG:
```python
logging.getLogger('memory_mcp.analysis.entity_dictionary').setLevel(logging.DEBUG)
```

