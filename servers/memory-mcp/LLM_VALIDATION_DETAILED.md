# Детальное описание: Как LLM проверяет валидность сущности

## Полный процесс валидации

### 1. Точка входа: `track_entity()`

Когда сущность встречается достаточно часто (достигает порога), вызывается валидация:

```python
# src/memory_mcp/analysis/entity_dictionary.py, строка 108-117
if total_count >= threshold and normalized_value not in self.learned_dictionaries[entity_type]:
    # Валидация через LLM перед добавлением в словарь
    if self.enable_llm_validation:
        is_valid = self._validate_entity_with_llm(entity_type, normalized_value, value)
        if not is_valid:
            logger.debug(f"Сущность отклонена LLM: {entity_type}={normalized_value}")
            return False  # Не добавляем в словарь
    
    # Добавляем только если валидна
    self.learned_dictionaries[entity_type].add(normalized_value)
    return True
```

### 2. Синхронная обертка: `_validate_entity_with_llm()`

Метод обрабатывает разные сценарии event loop:

```python
# src/memory_mcp/analysis/entity_dictionary.py, строка 446-485
def _validate_entity_with_llm(self, entity_type, normalized_value, original_value) -> bool:
    try:
        # Пытаемся получить существующий event loop
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # Если loop уже запущен (например, в async функции),
                # создаем новый в отдельном потоке
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(
                        asyncio.run,
                        self._validate_entity_with_llm_async(...)
                    )
                    return future.result(timeout=5.0)  # Таймаут 5 секунд
            else:
                # Если loop не запущен, используем его
                return loop.run_until_complete(...)
        except RuntimeError:
            # Если нет event loop, создаем новый
            return asyncio.run(...)
    except Exception as e:
        # При любой ошибке разрешаем добавление (консервативный подход)
        return True
```

### 3. Асинхронная валидация: `_validate_entity_with_llm_async()`

Основная логика валидации:

```python
# src/memory_mcp/analysis/entity_dictionary.py, строка 368-444
async def _validate_entity_with_llm_async(self, entity_type, normalized_value, original_value) -> bool:
    # Шаг 1: Получаем LLM клиент
    llm_client = self._get_llm_client()
    if not llm_client:
        return True  # Если LLM недоступен, разрешаем добавление
    
    # Шаг 2: Формируем промпт
    entity_type_names = {
        "persons": "имя человека",
        "organizations": "название организации",
        # ... другие типы
    }
    type_name = entity_type_names.get(entity_type, entity_type)
    
    prompt = f"""Ты эксперт по анализу текста. Определи, является ли данное слово/фраза действительно {type_name}.

Слово/фраза для проверки: "{original_value}" (нормализованное: "{normalized_value}")

Правила:
1. Для типа "{entity_type}": это должно быть действительно {type_name}, а не обычное слово, глагол, прилагательное или другое слово общего назначения.
2. Исключи мат, грубые слова, времена года, дни недели, обычные глаголы и прилагательные.
3. Если это сокращение или опечатка - отклони.
4. Если это имя собственное (начинается с заглавной буквы) и соответствует типу - прими.

Ответь ТОЛЬКО одним словом: "ДА" если это валидная {type_name}, или "НЕТ" если это не валидная {type_name}.
Не добавляй никаких объяснений, только "ДА" или "НЕТ"."""
    
    # Шаг 3: Отправляем запрос к LLM
    try:
        async with llm_client:
            response = await llm_client.generate_summary(
                prompt=prompt,
                temperature=0.1,      # Низкая температура для детерминированных ответов
                max_tokens=10,        # Нужен только "ДА" или "НЕТ"
                top_p=0.9,
                presence_penalty=0.0,
            )
            
            # Шаг 4: Парсим ответ
            response_clean = response.strip().upper()
            if "ДА" in response_clean or "YES" in response_clean:
                return True   # Сущность валидна
            elif "НЕТ" in response_clean or "NO" in response_clean:
                return False  # Сущность не валидна
            else:
                # Неоднозначный ответ - разрешаем (консервативный подход)
                return True
    except Exception as e:
        # При ошибке разрешаем добавление
        return True
```

### 4. HTTP запрос к LLM

#### Для LM Studio:

**Endpoint:** `POST http://127.0.0.1:1234/v1/chat/completions`

**Запрос:**
```json
{
  "model": "gpt-oss-20b",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful AI assistant. Follow the user's instructions carefully and provide accurate responses."
    },
    {
      "role": "user",
      "content": "Ты эксперт по анализу текста. Определи, является ли данное слово/фраза действительно имя человека.\n\nСлово/фраза для проверки: \"походила\" (нормализованное: \"походила\")\n\nПравила:\n1. Для типа \"persons\": это должно быть действительно имя человека, а не обычное слово, глагол, прилагательное или другое слово общего назначения.\n2. Исключи мат, грубые слова, времена года, дни недели, обычные глаголы и прилагательные.\n3. Если это сокращение или опечатка - отклони.\n4. Если это имя собственное (начинается с заглавной буквы) и соответствует типу - прими.\n\nОтветь ТОЛЬКО одним словом: \"ДА\" если это валидная имя человека, или \"НЕТ\" если это не валидная имя человека.\nНе добавляй никаких объяснений, только \"ДА\" или \"НЕТ\"."
    }
  ],
  "temperature": 0.1,
  "max_tokens": 10,
  "top_p": 0.9,
  "presence_penalty": 0.0,
  "stream": false
}
```

**Ответ:**
```json
{
  "choices": [
    {
      "message": {
        "content": "НЕТ"
      }
    }
  ]
}
```

#### Для Ollama:

**Endpoint:** `POST http://localhost:11434/api/generate`

**Запрос:**
```json
{
  "model": "gpt-oss-20b:latest",
  "prompt": "Ты эксперт по анализу текста. Определи, является ли данное слово/фраза действительно имя человека.\n\nСлово/фраза для проверки: \"Иван\" (нормализованное: \"иван\")\n\n...",
  "temperature": 0.1,
  "num_predict": 10,
  "top_p": 0.9
}
```

**Ответ:**
```json
{
  "response": "ДА",
  "done": true
}
```

### 5. Обработка ответа

```python
# Извлекаем текст ответа
response_text = response.strip().upper()  # "НЕТ" или "ДА"

# Проверяем наличие ключевых слов
if "ДА" in response_text or "YES" in response_text:
    return True   # ✅ Сущность валидна, добавляем в словарь
elif "НЕТ" in response_text or "NO" in response_text:
    return False  # ❌ Сущность не валидна, не добавляем
else:
    # Неоднозначный ответ (например, "Возможно" или пустой ответ)
    return True   # Консервативный подход - разрешаем
```

## Примеры реальных валидаций

### Пример 1: Глагол "походила"

**Вход:**
- Тип: `persons`
- Значение: `"походила"`
- Частота: 5 (достиг порога)

**Промпт:**
```
Ты эксперт по анализу текста. Определи, является ли данное слово/фраза действительно имя человека.

Слово/фраза для проверки: "походила" (нормализованное: "походила")

Правила:
1. Для типа "persons": это должно быть действительно имя человека, а не обычное слово, глагол, прилагательное или другое слово общего назначения.
2. Исключи мат, грубые слова, времена года, дни недели, обычные глаголы и прилагательные.
3. Если это сокращение или опечатка - отклони.
4. Если это имя собственное (начинается с заглавной буквы) и соответствует типу - прими.

Ответь ТОЛЬКО одним словом: "ДА" если это валидная имя человека, или "НЕТ" если это не валидная имя человека.
Не добавляй никаких объяснений, только "ДА" или "НЕТ".
```

**Ответ LLM:** `"НЕТ"` (распознано как глагол)

**Результат:** ❌ Отклонено, не добавлено в словарь

---

### Пример 2: Правильное имя "Иван"

**Вход:**
- Тип: `persons`
- Значение: `"Иван"`
- Частота: 5 (достиг порога)

**Промпт:**
```
Ты эксперт по анализу текста. Определи, является ли данное слово/фраза действительно имя человека.

Слово/фраза для проверки: "Иван" (нормализованное: "иван")

Правила:
1. Для типа "persons": это должно быть действительно имя человека, а не обычное слово, глагол, прилагательное или другое слово общего назначения.
2. Исключи мат, грубые слова, времена года, дни недели, обычные глаголы и прилагательные.
3. Если это сокращение или опечатка - отклони.
4. Если это имя собственное (начинается с заглавной буквы) и соответствует типу - прими.

Ответь ТОЛЬКО одним словом: "ДА" если это валидная имя человека, или "НЕТ" если это не валидная имя человека.
Не добавляй никаких объяснений, только "ДА" или "НЕТ".
```

**Ответ LLM:** `"ДА"` (распознано как имя)

**Результат:** ✅ Принято, добавлено в словарь

---

### Пример 3: Сокращение "Саш"

**Вход:**
- Тип: `persons`
- Значение: `"Саш"`
- Частота: 5 (достиг порога)

**Промпт:**
```
Ты эксперт по анализу текста. Определи, является ли данное слово/фраза действительно имя человека.

Слово/фраза для проверки: "Саш" (нормализованное: "саш")

Правила:
1. Для типа "persons": это должно быть действительно имя человека, а не обычное слово, глагол, прилагательное или другое слово общего назначения.
2. Исключи мат, грубые слова, времена года, дни недели, обычные глаголы и прилагательные.
3. Если это сокращение или опечатка - отклони.
4. Если это имя собственное (начинается с заглавной буквы) и соответствует типу - прими.

Ответь ТОЛЬКО одним словом: "ДА" если это валидная имя человека, или "НЕТ" если это не валидная имя человека.
Не добавляй никаких объяснений, только "ДА" или "НЕТ".
```

**Ответ LLM:** `"НЕТ"` (распознано как сокращение/опечатка)

**Результат:** ❌ Отклонено, не добавлено в словарь

---

## Визуализация потока данных

```
┌─────────────────────────────────────────────────────────────┐
│ 1. Natasha извлекает "походила" как PER (Person)            │
└──────────────────────┬──────────────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────────────┐
│ 2. Базовая фильтрация (длина, стоп-слова, морфология)      │
│    → Проходит (начинается с заглавной, не в стоп-словах)   │
└──────────────────────┬──────────────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────────────┐
│ 3. Подсчет частоты: "походила" встречается 5 раз            │
│    → Достиг порога (5 для persons)                          │
└──────────────────────┬──────────────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────────────┐
│ 4. LLM валидация:                                           │
│    - Формируется промпт с правилами                         │
│    - Отправляется запрос к LLM                              │
│    - LLM анализирует: "походила" = глагол                   │
│    - Ответ: "НЕТ"                                           │
└──────────────────────┬──────────────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────────────┐
│ 5. Результат: ❌ Отклонено                                  │
│    → Не добавляется в словарь                               │
│    → Логируется на уровне DEBUG                             │
└─────────────────────────────────────────────────────────────┘
```

## Ключевые особенности

### 1. Консервативный подход

При любой ошибке или недоступности LLM сущность **разрешается** (добавляется в словарь). Это гарантирует, что система продолжит работать даже при проблемах с LLM.

### 2. Низкая температура

`temperature=0.1` обеспечивает детерминированные ответы - LLM будет давать одинаковые ответы на одинаковые запросы.

### 3. Минимальный токен-лимит

`max_tokens=10` - достаточно для ответа "ДА" или "НЕТ", что ускоряет валидацию и снижает стоимость.

### 4. Таймаут

5 секунд на валидацию - если LLM не отвечает, валидация пропускается.

## Производительность

- **Время валидации**: ~1-3 секунды на сущность (зависит от LLM)
- **Кэширование**: Валидация выполняется только один раз для каждой сущности
- **Батчинг**: В будущем можно валидировать несколько сущностей за один запрос

## Логирование

Для просмотра процесса валидации включите DEBUG логи:

```python
import logging
logging.getLogger('memory_mcp.analysis.entity_dictionary').setLevel(logging.DEBUG)
```

В логах вы увидите:
- Какие сущности отправляются на валидацию
- Какие сущности отклонены LLM
- Ошибки при валидации

