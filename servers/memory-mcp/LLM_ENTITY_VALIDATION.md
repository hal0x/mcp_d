# LLM валидация сущностей для словаря

## Обзор

Добавлена валидация сущностей через LLM перед добавлением в словарь. Это позволяет использовать контекстное понимание нейросети для фильтрации ложных срабатываний (глаголы, обычные слова, мат и т.д.).

## Как это работает

### Процесс валидации

1. **Извлечение сущностей** - Natasha NER извлекает потенциальные сущности из текста
2. **Базовая фильтрация** - применяются правила (длина, стоп-слова, морфология)
3. **Подсчет частоты** - сущности отслеживаются и подсчитываются
4. **Проверка порога** - когда частота достигает порога (например, 5 для имен)
5. **LLM валидация** - перед добавлением в словарь сущность проверяется через LLM
6. **Добавление в словарь** - только валидные сущности добавляются

### Промпт для валидации

LLM получает промпт с:
- Типом сущности (имя человека, организация, место и т.д.)
- Оригинальным значением (для контекста)
- Нормализованным значением
- Правилами валидации

LLM отвечает "ДА" или "НЕТ" - является ли это валидной сущностью.

## Конфигурация

### Включение/выключение

```python
from memory_mcp.analysis.entity_dictionary import get_entity_dictionary

# Включить LLM валидацию (по умолчанию)
dict_manager = get_entity_dictionary(enable_llm_validation=True)

# Выключить LLM валидацию
dict_manager = get_entity_dictionary(enable_llm_validation=False)
```

### Используемые LLM

Система автоматически выбирает LLM:

1. **Приоритет 1**: LM Studio (если установлен `LMSTUDIO_LLM_MODEL`)
   - Использует `LMStudioEmbeddingClient` с `llm_model_name`
   - Endpoint: `/v1/chat/completions`

2. **Приоритет 2**: Ollama (fallback)
   - Использует `OllamaEmbeddingClient`
   - Модель из `QUALITY_ANALYSIS_OLLAMA_MODEL` (по умолчанию `gpt-oss-20b:latest`)

### Переменные окружения

```bash
# LM Studio (приоритет 1)
LMSTUDIO_HOST=127.0.0.1
LMSTUDIO_PORT=1234
LMSTUDIO_LLM_MODEL=gpt-oss-20b  # Модель для генерации текста

# Ollama (fallback, если LM Studio не настроен)
QUALITY_ANALYSIS_OLLAMA_MODEL=gpt-oss-20b:latest
QUALITY_ANALYSIS_OLLAMA_BASE_URL=http://localhost:11434
```

## Результаты тестирования

```
✅ ОТКЛОНЕНО | persons | походила  (глагол)
✅ ОТКЛОНЕНО | persons | позвоню   (глагол)
✅ ОТКЛОНЕНО | persons | Саш       (сокращение/опечатка)
✅ ДОБАВЛЕНО  | persons | Иван      (правильное имя)
```

## Преимущества

1. **Контекстное понимание** - LLM понимает семантику, а не только правила
2. **Гибкость** - может обрабатывать сложные случаи, которые сложно описать правилами
3. **Точность** - значительно снижает количество ложных срабатываний
4. **Масштабируемость** - легко добавлять новые типы сущностей

## Производительность

- **Таймаут**: 5 секунд на валидацию одной сущности
- **Кэширование**: Валидация выполняется только один раз для каждой сущности (при достижении порога)
- **Fallback**: При ошибке или недоступности LLM сущность разрешается (консервативный подход)

## Обработка ошибок

- Если LLM недоступен → валидация пропускается (разрешается добавление)
- Если ошибка при валидации → валидация пропускается (разрешается добавление)
- Если неоднозначный ответ → разрешается добавление (консервативный подход)

Это гарантирует, что система продолжит работать даже при проблемах с LLM.

## Интеграция

Валидация автоматически интегрирована в:
- `EntityDictionary.track_entity()` - вызывается перед добавлением в словарь
- `EntityExtractor` - передает флаг `enable_llm_validation` в словарь
- Индексация чатов - использует валидацию при обучении словарей

## Примеры использования

### Программное использование

```python
from memory_mcp.analysis.entity_dictionary import EntityDictionary

# Создание словаря с LLM валидацией
dict_manager = EntityDictionary(enable_llm_validation=True)

# Отслеживание сущности (валидация выполнится автоматически при достижении порога)
dict_manager.track_entity("persons", "Иван", "test_chat")
```

### В индексации

```python
from memory_mcp.analysis.entity_extraction import EntityExtractor

# Создание экстрактора с LLM валидацией
extractor = EntityExtractor(
    enable_learning=True,
    enable_natasha=True,
    enable_llm_validation=True  # Включить LLM валидацию
)

# Извлечение сущностей (валидация выполнится автоматически)
entities = extractor.extract_entities("Иван пришел домой", chat_name="test")
```

## Будущие улучшения

1. **Батчинг** - валидация нескольких сущностей за один запрос
2. **Кэширование результатов** - сохранение результатов валидации для повторного использования
3. **Контекстные промпты** - использование контекста сообщения для более точной валидации
4. **Метрики** - отслеживание точности валидации

