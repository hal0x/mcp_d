#!/usr/bin/env python3
"""
SearchExplainer - –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞

–í–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π HALv1:
- –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è scores (BM25, Vector, RRF)
- Connection graph —á–µ—Ä–µ–∑ TypedGraphMemory
- –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
"""

import logging
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

logger = logging.getLogger(__name__)


@dataclass
class ScoreBreakdown:
    """–î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è score —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–æ–∏—Å–∫–∞"""

    doc_id: str
    final_score: float

    # BM25 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    bm25_score: float
    bm25_rank: Optional[int]

    # Vector –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    vector_similarity: float
    vector_distance: float
    vector_rank: Optional[int]

    # RRF –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    rrf_score: float
    rrf_vector_contribution: float
    rrf_bm25_contribution: float

    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    metadata: Dict[str, Any]

    def to_dict(self) -> Dict[str, Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å"""
        return {
            "doc_id": self.doc_id,
            "final_score": self.final_score,
            "bm25": {
                "score": self.bm25_score,
                "rank": self.bm25_rank,
            },
            "vector": {
                "similarity": self.vector_similarity,
                "distance": self.vector_distance,
                "rank": self.vector_rank,
            },
            "rrf": {
                "score": self.rrf_score,
                "vector_contribution": self.rrf_vector_contribution,
                "bm25_contribution": self.rrf_bm25_contribution,
            },
            "metadata": self.metadata,
        }


@dataclass
class ConnectionPath:
    """–ü—É—Ç—å —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–æ–º –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º"""

    query_entity: str
    result_entity: str
    path_length: int
    path_nodes: List[str]
    path_edges: List[str]
    path_strength: float  # –°–∏–ª–∞ —Å–≤—è–∑–∏ (0-1)

    def to_dict(self) -> Dict[str, Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å"""
        return {
            "query_entity": self.query_entity,
            "result_entity": self.result_entity,
            "path_length": self.path_length,
            "path_nodes": self.path_nodes,
            "path_edges": self.path_edges,
            "path_strength": self.path_strength,
        }


@dataclass
class RelevanceExplanation:
    """–ü–æ–ª–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""

    doc_id: str
    query: str
    rank: int

    # –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è score
    score_breakdown: ScoreBreakdown

    # –°–≤—è–∑–∏ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ
    connection_paths: List[ConnectionPath]

    # –¢–µ–∫—Å—Ç–æ–≤–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
    explanation_text: str

    # –§–∞–∫—Ç–æ—Ä—ã —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    relevance_factors: Dict[str, float]  # factor -> weight

    def to_dict(self) -> Dict[str, Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å"""
        return {
            "doc_id": self.doc_id,
            "query": self.query,
            "rank": self.rank,
            "score_breakdown": self.score_breakdown.to_dict(),
            "connection_paths": [cp.to_dict() for cp in self.connection_paths],
            "explanation_text": self.explanation_text,
            "relevance_factors": self.relevance_factors,
        }


class ScoreDecomposer:
    """–î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è scores –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è"""

    def __init__(self, alpha: float = 0.6, k: int = 60):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è

        Args:
            alpha: –í–µ—Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ RRF
            k: –ü–∞—Ä–∞–º–µ—Ç—Ä RRF
        """
        self.alpha = alpha
        self.k = k

        logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω ScoreDecomposer (alpha={alpha}, k={k})")

    def decompose(
        self,
        doc_id: str,
        final_score: float,
        bm25_results: List[Tuple[str, float]],
        vector_results: List[Tuple[str, float]],
        metadata: Optional[Dict[str, Any]] = None,
    ) -> ScoreBreakdown:
        """
        –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è score —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

        Args:
            doc_id: ID –¥–æ–∫—É–º–µ–Ω—Ç–∞
            final_score: –§–∏–Ω–∞–ª—å–Ω—ã–π RRF score
            bm25_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã BM25 –ø–æ–∏—Å–∫–∞ [(doc_id, score), ...]
            vector_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ [(doc_id, score), ...]
            metadata: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞

        Returns:
            –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è score
        """
        # –ò—â–µ–º –ø–æ–∑–∏—Ü–∏–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
        bm25_rank = None
        bm25_score = 0.0
        for rank, (bid, score) in enumerate(bm25_results):
            if bid == doc_id:
                bm25_rank = rank
                bm25_score = score
                break

        vector_rank = None
        vector_similarity = 0.0
        vector_distance = 0.0
        for rank, (vid, sim) in enumerate(vector_results):
            if vid == doc_id:
                vector_rank = rank
                vector_similarity = sim
                # –û–±—Ä–∞—Ç–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: distance = (1 / similarity) - 1
                vector_distance = (1.0 / sim) - 1.0 if sim > 0 else float("inf")
                break

        # –í—ã—á–∏—Å–ª—è–µ–º RRF –≤–∫–ª–∞–¥—ã
        rrf_vector_contribution = 0.0
        rrf_bm25_contribution = 0.0

        if vector_rank is not None:
            rrf_vector_contribution = self.alpha / (self.k + vector_rank + 1)

        if bm25_rank is not None:
            rrf_bm25_contribution = (1.0 - self.alpha) / (self.k + bm25_rank + 1)

        rrf_score = rrf_vector_contribution + rrf_bm25_contribution

        return ScoreBreakdown(
            doc_id=doc_id,
            final_score=final_score,
            bm25_score=bm25_score,
            bm25_rank=bm25_rank,
            vector_similarity=vector_similarity,
            vector_distance=vector_distance,
            vector_rank=vector_rank,
            rrf_score=rrf_score,
            rrf_vector_contribution=rrf_vector_contribution,
            rrf_bm25_contribution=rrf_bm25_contribution,
            metadata=metadata or {},
        )

    def explain_score(self, breakdown: ScoreBreakdown) -> str:
        """
        –¢–µ–∫—Å—Ç–æ–≤–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ score

        Args:
            breakdown: –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è score

        Returns:
            –¢–µ–∫—Å—Ç–æ–≤–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
        """
        explanation = []

        # –§–∏–Ω–∞–ª—å–Ω—ã–π score
        explanation.append(
            f"üìä –§–∏–Ω–∞–ª—å–Ω—ã–π score: {breakdown.final_score:.4f} (RRF fusion)"
        )
        explanation.append("")

        # BM25 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
        if breakdown.bm25_rank is not None:
            explanation.append("üî§ BM25 (–ª–µ–∫—Å–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫):")
            explanation.append(
                f"   Score: {breakdown.bm25_score:.4f} | Rank: #{breakdown.bm25_rank + 1}"
            )
            explanation.append(
                f"   –í–∫–ª–∞–¥ –≤ RRF: {breakdown.rrf_bm25_contribution:.4f} ({(1-self.alpha)*100:.0f}% –≤–µ—Å–∞)"
            )
        else:
            explanation.append("üî§ BM25: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

        explanation.append("")

        # Vector –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
        if breakdown.vector_rank is not None:
            explanation.append("üß† Vector (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫):")
            explanation.append(
                f"   Similarity: {breakdown.vector_similarity:.4f} | Distance: {breakdown.vector_distance:.4f}"
            )
            explanation.append(f"   Rank: #{breakdown.vector_rank + 1}")
            explanation.append(
                f"   –í–∫–ª–∞–¥ –≤ RRF: {breakdown.rrf_vector_contribution:.4f} ({self.alpha*100:.0f}% –≤–µ—Å–∞)"
            )
        else:
            explanation.append("üß† Vector: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

        explanation.append("")

        # –ê–Ω–∞–ª–∏–∑ –¥–æ–º–∏–Ω–∏—Ä—É—é—â–µ–≥–æ —Ñ–∞–∫—Ç–æ—Ä–∞
        if breakdown.rrf_vector_contribution > breakdown.rrf_bm25_contribution:
            dominant = "–≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫"
            ratio = breakdown.rrf_vector_contribution / (
                breakdown.rrf_bm25_contribution or 0.001
            )
        else:
            dominant = "BM25"
            ratio = breakdown.rrf_bm25_contribution / (
                breakdown.rrf_vector_contribution or 0.001
            )

        explanation.append(
            f"üéØ –î–æ–º–∏–Ω–∏—Ä—É—é—â–∏–π —Ñ–∞–∫—Ç–æ—Ä: {dominant} (–≤ {ratio:.1f}x —Ä–∞–∑ —Å–∏–ª—å–Ω–µ–µ)"
        )

        return "\n".join(explanation)


class ConnectionGraphBuilder:
    """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–æ–º –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"""

    def __init__(self, typed_graph_memory=None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è

        Args:
            typed_graph_memory: TypedGraphMemory –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–≤—è–∑–µ–π
        """
        self.graph = typed_graph_memory
        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω ConnectionGraphBuilder")

    def find_connections(
        self,
        query_entities: List[str],
        result_id: str,
        max_paths: int = 3,
        max_depth: int = 3,
    ) -> List[ConnectionPath]:
        """
        –ü–æ–∏—Å–∫ –ø—É—Ç–µ–π —Å–≤—è–∑–µ–π –º–µ–∂–¥—É —Å—É—â–Ω–æ—Å—Ç—è–º–∏ –∑–∞–ø—Ä–æ—Å–∞ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

        Args:
            query_entities: –°—É—â–Ω–æ—Å—Ç–∏ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
            result_id: ID —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            max_paths: –ú–∞–∫—Å–∏–º—É–º –ø—É—Ç–µ–π
            max_depth: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –ø–æ–∏—Å–∫–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π —Å–≤—è–∑–µ–π
        """
        if not self.graph:
            logger.warning(
                "TypedGraphMemory –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–∏—Å–∫ —Å–≤—è–∑–µ–π"
            )
            return []

        connections = []

        # –ü–æ–ª—É—á–∞–µ–º —É–∑–µ–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–∑ –≥—Ä–∞—Ñ–∞
        result_node = self.graph.get_node(result_id)
        if not result_node:
            logger.debug(f"–£–∑–µ–ª {result_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –≥—Ä–∞—Ñ–µ")
            return []

        # –î–ª—è –∫–∞–∂–¥–æ–π —Å—É—â–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–∞ –∏—â–µ–º –ø—É—Ç—å –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É
        for query_entity in query_entities:
            try:
                # –ò—â–µ–º —É–∑–µ–ª —Å—É—â–Ω–æ—Å—Ç–∏ –≤ –≥—Ä–∞—Ñ–µ
                entity_nodes = [
                    n
                    for n in self.graph.get_nodes_by_type("Entity")
                    if query_entity.lower() in n.label.lower()
                ]

                if not entity_nodes:
                    continue

                entity_node = entity_nodes[0]

                # –ò—â–µ–º –ø—É—Ç—å –º–µ–∂–¥—É —É–∑–ª–∞–º–∏
                paths = self.graph.find_paths(
                    entity_node.id, result_id, max_depth=max_depth
                )

                for path in paths[:max_paths]:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—É—Ç–∏
                    path_nodes = [node.label for node in path]
                    path_edges = self._extract_edge_types(path)
                    path_strength = self._calculate_path_strength(path)

                    connection = ConnectionPath(
                        query_entity=query_entity,
                        result_entity=result_node.label,
                        path_length=len(path) - 1,
                        path_nodes=path_nodes,
                        path_edges=path_edges,
                        path_strength=path_strength,
                    )
                    connections.append(connection)

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Å–≤—è–∑–µ–π –¥–ª—è {query_entity}: {e}")
                continue

        return connections[:max_paths]

    def _extract_edge_types(self, path: List[Any]) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ —Ä—ë–±–µ—Ä –∏–∑ –ø—É—Ç–∏"""
        if not self.graph or len(path) < 2:
            return []

        edge_types = []
        for i in range(len(path) - 1):
            source = path[i]
            target = path[i + 1]

            # –ü–æ–ª—É—á–∞–µ–º —Ä—ë–±—Ä–∞ –º–µ–∂–¥—É —É–∑–ª–∞–º–∏
            neighbors = self.graph.get_neighbors(source.id)
            for neighbor in neighbors:
                if neighbor.id == target.id:
                    # –ü–æ–ª—É—á–∞–µ–º —Ç–∏–ø —Ä–µ–±—Ä–∞ (—É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
                    edge_types.append("relates_to")
                    break

        return edge_types

    def _calculate_path_strength(self, path: List[Any]) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å–∏–ª—ã –ø—É—Ç–∏"""
        if len(path) <= 1:
            return 1.0

        # –°–∏–ª–∞ –æ–±—Ä–∞—Ç–Ω–æ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–∞ –¥–ª–∏–Ω–µ –ø—É—Ç–∏
        # –ö–æ—Ä–æ—Ç–∫–∏–µ –ø—É—Ç–∏ = —Å–∏–ª—å–Ω—ã–µ —Å–≤—è–∑–∏
        return 1.0 / len(path)


class MarkdownExporter:
    """–≠–∫—Å–ø–æ—Ä—Ç –æ–±—ä—è—Å–Ω–µ–Ω–∏–π –≤ Markdown"""

    @staticmethod
    def export_explanation(explanation: RelevanceExplanation) -> str:
        """
        –≠–∫—Å–ø–æ—Ä—Ç –æ–¥–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –≤ Markdown

        Args:
            explanation: –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏

        Returns:
            Markdown —Ç–µ–∫—Å—Ç
        """
        lines = []

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        lines.append(f"## üîç –†–µ–∑—É–ª—å—Ç–∞—Ç #{explanation.rank + 1}")
        lines.append("")
        lines.append(f"**–ó–∞–ø—Ä–æ—Å**: `{explanation.query}`")
        lines.append(f"**–î–æ–∫—É–º–µ–Ω—Ç**: `{explanation.doc_id}`")
        lines.append(f"**Score**: `{explanation.score_breakdown.final_score:.4f}`")
        lines.append("")

        # Score breakdown
        breakdown = explanation.score_breakdown
        lines.append("### üìä –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è Score")
        lines.append("")
        lines.append("| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –ó–Ω–∞—á–µ–Ω–∏–µ | Rank | –í–∫–ª–∞–¥ –≤ RRF |")
        lines.append("|-----------|----------|------|-------------|")

        # BM25
        if breakdown.bm25_rank is not None:
            lines.append(
                f"| **BM25** | {breakdown.bm25_score:.4f} | "
                f"#{breakdown.bm25_rank + 1} | {breakdown.rrf_bm25_contribution:.4f} |"
            )
        else:
            lines.append("| **BM25** | - | - | 0.0000 |")

        # Vector
        if breakdown.vector_rank is not None:
            lines.append(
                f"| **Vector** | {breakdown.vector_similarity:.4f} | "
                f"#{breakdown.vector_rank + 1} | {breakdown.rrf_vector_contribution:.4f} |"
            )
        else:
            lines.append("| **Vector** | - | - | 0.0000 |")

        # RRF
        lines.append(f"| **RRF Total** | - | - | {breakdown.rrf_score:.4f} |")
        lines.append("")

        # –°–≤—è–∑–∏ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ
        if explanation.connection_paths:
            lines.append("### üï∏Ô∏è  –°–≤—è–∑–∏ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π")
            lines.append("")
            for i, path in enumerate(explanation.connection_paths, 1):
                lines.append(f"{i}. **{path.query_entity}** ‚Üí **{path.result_entity}**")
                lines.append(f"   - –ü—É—Ç—å: `{' ‚Üí '.join(path.path_nodes)}`")
                lines.append(
                    f"   - –î–ª–∏–Ω–∞: {path.path_length}, –°–∏–ª–∞: {path.path_strength:.2f}"
                )
                lines.append("")

        # –§–∞–∫—Ç–æ—Ä—ã —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        if explanation.relevance_factors:
            lines.append("### üéØ –§–∞–∫—Ç–æ—Ä—ã —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏")
            lines.append("")
            lines.append("| –§–∞–∫—Ç–æ—Ä | –í–µ—Å |")
            lines.append("|--------|-----|")
            for factor, weight in sorted(
                explanation.relevance_factors.items(), key=lambda x: x[1], reverse=True
            ):
                lines.append(f"| {factor} | {weight:.4f} |")
            lines.append("")

        lines.append("---")
        lines.append("")

        return "\n".join(lines)

    @staticmethod
    def export_batch(
        explanations: List[RelevanceExplanation], output_file: str
    ) -> None:
        """
        –≠–∫—Å–ø–æ—Ä—Ç –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π –≤ Markdown —Ñ–∞–π–ª

        Args:
            explanations: –°–ø–∏—Å–æ–∫ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
            output_file: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        with open(output_file, "w", encoding="utf-8") as f:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            f.write("# üîç –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞\n\n")

            if explanations:
                f.write(f"**–ó–∞–ø—Ä–æ—Å**: `{explanations[0].query}`\n")
                f.write(f"**–†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤**: {len(explanations)}\n\n")
                f.write("---\n\n")

            # –≠–∫—Å–ø–æ—Ä—Ç –∫–∞–∂–¥–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
            for explanation in explanations:
                f.write(MarkdownExporter.export_explanation(explanation))

        logger.info(f"–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(explanations)} –æ–±—ä—è—Å–Ω–µ–Ω–∏–π –≤ {output_file}")


class SearchExplainer:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞"""

    def __init__(
        self,
        alpha: float = 0.6,
        k: int = 60,
        typed_graph_memory=None,
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è

        Args:
            alpha: –í–µ—Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ RRF
            k: –ü–∞—Ä–∞–º–µ—Ç—Ä RRF
            typed_graph_memory: TypedGraphMemory –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–≤—è–∑–µ–π
        """
        self.score_decomposer = ScoreDecomposer(alpha=alpha, k=k)
        self.connection_builder = ConnectionGraphBuilder(typed_graph_memory)
        self.markdown_exporter = MarkdownExporter()

        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω SearchExplainer")

    def explain_result(
        self,
        doc_id: str,
        query: str,
        rank: int,
        final_score: float,
        bm25_results: List[Tuple[str, float]],
        vector_results: List[Tuple[str, float]],
        metadata: Optional[Dict[str, Any]] = None,
        query_entities: Optional[List[str]] = None,
    ) -> RelevanceExplanation:
        """
        –ü–æ–ª–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

        Args:
            doc_id: ID –¥–æ–∫—É–º–µ–Ω—Ç–∞
            query: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞
            rank: –ü–æ–∑–∏—Ü–∏—è –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö (0-based)
            final_score: –§–∏–Ω–∞–ª—å–Ω—ã–π score
            bm25_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã BM25
            vector_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
            metadata: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            query_entities: –°—É—â–Ω–æ—Å—Ç–∏ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ (–¥–ª—è –≥—Ä–∞—Ñ–∞ —Å–≤—è–∑–µ–π)

        Returns:
            –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        """
        # 1. –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è score
        score_breakdown = self.score_decomposer.decompose(
            doc_id=doc_id,
            final_score=final_score,
            bm25_results=bm25_results,
            vector_results=vector_results,
            metadata=metadata,
        )

        # 2. –ü–æ–∏—Å–∫ —Å–≤—è–∑–µ–π —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ
        connection_paths = []
        if query_entities:
            connection_paths = self.connection_builder.find_connections(
                query_entities=query_entities,
                result_id=doc_id,
                max_paths=3,
                max_depth=3,
            )

        # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
        explanation_text = self._generate_explanation_text(
            query=query,
            rank=rank,
            score_breakdown=score_breakdown,
            connection_paths=connection_paths,
        )

        # 4. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ—Ä–æ–≤ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        relevance_factors = self._compute_relevance_factors(
            score_breakdown=score_breakdown,
            connection_paths=connection_paths,
        )

        return RelevanceExplanation(
            doc_id=doc_id,
            query=query,
            rank=rank,
            score_breakdown=score_breakdown,
            connection_paths=connection_paths,
            explanation_text=explanation_text,
            relevance_factors=relevance_factors,
        )

    def _generate_explanation_text(
        self,
        query: str,
        rank: int,
        score_breakdown: ScoreBreakdown,
        connection_paths: List[ConnectionPath],
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è"""
        lines = []

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        lines.append(f"üîç –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ #{rank + 1}")
        lines.append(f'–ó–∞–ø—Ä–æ—Å: "{query}"')
        lines.append(f"–î–æ–∫—É–º–µ–Ω—Ç: {score_breakdown.doc_id}")
        lines.append("=" * 70)
        lines.append("")

        # Score breakdown
        lines.append(self.score_decomposer.explain_score(score_breakdown))
        lines.append("")

        # –°–≤—è–∑–∏ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ
        if connection_paths:
            lines.append("üï∏Ô∏è  –°–≤—è–∑–∏ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π:")
            lines.append("")
            for i, path in enumerate(connection_paths, 1):
                lines.append(f"   {i}. {path.query_entity} ‚Üí {path.result_entity}")
                lines.append(f"      –ü—É—Ç—å: {' ‚Üí '.join(path.path_nodes)}")
                lines.append(
                    f"      –î–ª–∏–Ω–∞: {path.path_length}, –°–∏–ª–∞: {path.path_strength:.2f}"
                )
                lines.append("")
        else:
            lines.append("üï∏Ô∏è  –°–≤—è–∑–∏ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ: –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            lines.append("")

        return "\n".join(lines)

    def _compute_relevance_factors(
        self,
        score_breakdown: ScoreBreakdown,
        connection_paths: List[ConnectionPath],
    ) -> Dict[str, float]:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ —Ñ–∞–∫—Ç–æ—Ä–æ–≤ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏"""
        factors = {}

        # –í–∫–ª–∞–¥ BM25
        if score_breakdown.bm25_rank is not None:
            factors["bm25_lexical_match"] = score_breakdown.rrf_bm25_contribution

        # –í–∫–ª–∞–¥ Vector
        if score_breakdown.vector_rank is not None:
            factors[
                "vector_semantic_similarity"
            ] = score_breakdown.rrf_vector_contribution

        # –í–∫–ª–∞–¥ –≥—Ä–∞—Ñ–∞ —Å–≤—è–∑–µ–π
        if connection_paths:
            avg_path_strength = sum(p.path_strength for p in connection_paths) / len(
                connection_paths
            )
            factors["graph_connections"] = avg_path_strength * 0.1  # –ú–µ–Ω—å—à–∏–π –≤–µ—Å

        return factors

    def explain_batch(
        self,
        results: List[Dict[str, Any]],
        query: str,
        bm25_results: List[Tuple[str, float]],
        vector_results: List[Tuple[str, float]],
        query_entities: Optional[List[str]] = None,
        max_explain: int = 5,
    ) -> List[RelevanceExplanation]:
        """
        –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Args:
            results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
            query: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞
            bm25_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã BM25
            vector_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
            query_entities: –°—É—â–Ω–æ—Å—Ç–∏ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
            max_explain: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è

        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
        """
        explanations = []

        for rank, result in enumerate(results[:max_explain]):
            try:
                explanation = self.explain_result(
                    doc_id=result.get("id", ""),
                    query=query,
                    rank=rank,
                    final_score=result.get("score", 0.0),
                    bm25_results=bm25_results,
                    vector_results=vector_results,
                    metadata=result.get("metadata", {}),
                    query_entities=query_entities,
                )
                explanations.append(explanation)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ {rank}: {e}")
                continue

        return explanations

    def export_to_markdown(
        self, explanations: List[RelevanceExplanation], output_file: str
    ) -> None:
        """
        –≠–∫—Å–ø–æ—Ä—Ç –æ–±—ä—è—Å–Ω–µ–Ω–∏–π –≤ Markdown —Ñ–∞–π–ª

        Args:
            explanations: –°–ø–∏—Å–æ–∫ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
            output_file: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        self.markdown_exporter.export_batch(explanations, output_file)
