#!/usr/bin/env python3
"""
–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç—á–µ—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞

–°–æ–∑–¥–∞–µ—Ç Markdown –æ—Ç—á–µ—Ç—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞:
- –û—Ç—á–µ—Ç—ã –ø–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º —á–∞—Ç–∞–º
- –û–±—â–∏–µ –æ—Ç—á–µ—Ç—ã –ø–æ –≤—Å–µ–º —á–∞—Ç–∞–º
- –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã —Å –∏—Å—Ç–æ—Ä–∏–µ–π
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
"""

import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from ...core.lmql_adapter import LMQLAdapter, build_lmql_adapter_from_env

logger = logging.getLogger(__name__)


class ReportGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç—á–µ—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞"""

    def __init__(
        self,
        reports_dir: Path = Path("artifacts/reports"),
        quality_subdir: Optional[str] = "quality_analysis",
        llm_model: Optional[str] = None,
        llm_base_url: Optional[str] = None,
        temperature: float = 0.2,
        max_tokens: int = 131072,  # –î–ª—è gpt-oss-20b (–º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ª–∏–º–∏—Ç)
        thinking_level: Optional[str] = None,
        lmql_adapter: Optional[LMQLAdapter] = None,
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –æ—Ç—á–µ—Ç–æ–≤

        Args:
            reports_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–æ–≤
            quality_subdir: –ü–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –æ—Ç—á–µ—Ç–æ–≤ –∫–∞—á–µ—Å—Ç–≤–∞
            llm_model: –ú–æ–¥–µ–ª—å LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            llm_base_url: URL LM Studio —Å–µ—Ä–≤–µ—Ä–∞
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
            thinking_level: –£—Ä–æ–≤–µ–Ω—å –º—ã—à–ª–µ–Ω–∏—è (thinking)
            lmql_adapter: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π LMQL –∞–¥–∞–ø—Ç–µ—Ä –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.
                         –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, —Å–æ–∑–¥–∞–µ—Ç—Å—è –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –æ–∫—Ä—É–∂–µ–Ω–∏—è.
        """
        self.reports_dir = reports_dir
        if quality_subdir:
            self.quality_reports_dir = reports_dir / quality_subdir
        else:
            self.quality_reports_dir = reports_dir

        self.quality_reports_dir.mkdir(parents=True, exist_ok=True)

        from ...core.langchain_adapters import LangChainLLMAdapter
        from .templates import DEFAULT_PROMPTS_DIR, PromptTemplateManager

        self.report_template_manager = PromptTemplateManager(
            Path(__file__).resolve().parent.parent / "templates" / "reports"
        )

        self.prompt_manager = PromptTemplateManager(DEFAULT_PROMPTS_DIR)

        self.temperature = temperature
        self.max_tokens = max_tokens
        self.embedding_client: Optional[LangChainLLMAdapter] = None
        self.thinking_level = thinking_level

        if llm_model and llm_base_url:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º LM Studio Server
            self.embedding_client = LangChainLLMAdapter(
                model_name=llm_model,
                base_url=llm_base_url,
            )

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LMQL –∞–¥–∞–ø—Ç–µ—Ä–∞
        try:
            self.lmql_adapter = lmql_adapter or build_lmql_adapter_from_env()
        except RuntimeError:
            self.lmql_adapter = None
            logger.debug("LMQL –∞–¥–∞–ø—Ç–µ—Ä –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –¥–ª—è ReportGenerator")

        logger.info(
            "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω ReportGenerator (–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: %s)",
            self.quality_reports_dir,
        )

    def generate_chat_report(
        self,
        chat_name: str,
        analysis_results: List[Dict[str, Any]],
        metrics: Dict[str, Any],
        llm_recommendations: Optional[List[Dict[str, Any]]] = None,
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —á–∞—Ç—É

        Args:
            chat_name: –ù–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞
            analysis_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
            metrics: –†–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏

        Returns:
            Markdown –æ—Ç—á–µ—Ç
        """
        logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –¥–ª—è —á–∞—Ç–∞: {chat_name}")

        basic_section = self._format_basic_section(metrics)
        type_section = self._format_type_section(metrics)
        problem_section = self._format_problem_section(metrics)
        comparative_section = self._format_comparative_section(metrics)
        details_section = self._format_details_section(analysis_results)
        recommendations_section = self._format_recommendations_section(
            metrics,
            llm_recommendations=llm_recommendations,
        )

        context = {
            "chat_name": chat_name,
            "analysis_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "basic_section": basic_section,
            "type_section": type_section,
            "problem_section": problem_section,
            "comparative_section": comparative_section,
            "details_section": details_section,
            "recommendations_section": recommendations_section,
        }

        try:
            report_content = self.report_template_manager.format(
                "main_report", **context
            )
        except Exception as exc:  # pragma: no cover - fallback
            logger.error("–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞ –ø–æ —à–∞–±–ª–æ–Ω—É: %s", exc)
            report_content = self._fallback_chat_report(
                chat_name,
                metrics,
                analysis_results,
            )

        self._save_chat_report(chat_name, report_content)

        logger.info("–û—Ç—á–µ—Ç –¥–ª—è —á–∞—Ç–∞ %s —Å–æ—Ö—Ä–∞–Ω–µ–Ω", chat_name)
        return report_content

    def generate_overall_report(
        self,
        chat_results: Dict[str, Any],
        overall_metrics: Dict[str, Any],
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—â–µ–≥–æ –æ—Ç—á–µ—Ç–∞ –ø–æ –≤—Å–µ–º —á–∞—Ç–∞–º

        Args:
            chat_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –≤—Å–µ—Ö —á–∞—Ç–æ–≤
            overall_metrics: –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏

        Returns:
            –û–±—â–∏–π Markdown –æ—Ç—á–µ—Ç
        """
        logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—â–µ–≥–æ –æ—Ç—á–µ—Ç–∞")

        summary_section = self._format_overall_basic(overall_metrics)
        chat_table = self._format_chat_table(overall_metrics)
        problem_summary = self._format_overall_problems(overall_metrics)
        recommendations_section = self._format_overall_recommendations(overall_metrics)

        context = {
            "analysis_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "summary_section": summary_section,
            "chat_table": chat_table,
            "problem_summary": problem_summary,
            "recommendations_section": recommendations_section,
        }

        try:
            report_content = self.report_template_manager.format(
                "summary_report", **context
            )
        except Exception as exc:  # pragma: no cover
            logger.error("–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—â–µ–≥–æ –æ—Ç—á–µ—Ç–∞: %s", exc)
            report_content = self._fallback_overall_report(overall_metrics)

        self._save_overall_report(report_content)

        logger.info("–û–±—â–∏–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
        return report_content

    async def generate_llm_recommendations(
        self,
        chat_name: str,
        metrics: Dict[str, Any],
        analysis_results: List[Dict[str, Any]],
        max_problem_examples: int = 5,
    ) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —á–µ—Ä–µ–∑ LLM."""

        payload = self._build_recommendation_payload(
            chat_name,
            metrics,
            analysis_results,
            limit=max_problem_examples,
        )

        if not payload:
            logger.debug("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ LLM-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
            return []

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º LMQL –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        if self.lmql_adapter:
            logger.debug("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è LMQL –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
            return await self._generate_recommendations_with_lmql(
                chat_name, payload
            )

        # Fallback –Ω–∞ —Å—Ç–∞—Ä—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é, –µ—Å–ª–∏ LMQL –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
        if not self.embedding_client:
            logger.debug("–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π LM Studio –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
            return []

        try:
            prompt = self.prompt_manager.format(
                "quality_recommendations_base",
                chat_name=chat_name,
                metrics_json=json.dumps(payload, ensure_ascii=False, indent=2),
            )
        except Exception as exc:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –ø—Ä–æ–º–ø—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: %s", exc)
            return []

        if not prompt.strip():
            logger.warning("–ü—Ä–æ–º–ø—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø—É—Å—Ç ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é")
            return []

        try:
            async with self.embedding_client:
                response = await self.embedding_client.generate_summary(
                    prompt,
                    temperature=self.temperature,
                    max_tokens=self.max_tokens,
                )
        except Exception as exc:  # pragma: no cover - –≤–Ω–µ—à–Ω–µ–µ API
            logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç LM Studio: %s", exc)
            return []

        return self._parse_llm_recommendations(response)

    async def _generate_recommendations_with_lmql(
        self, chat_name: str, payload: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LMQL.
        
        Args:
            chat_name: –ù–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞
            payload: –î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            
        Raises:
            RuntimeError: –ï—Å–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞
        """
        try:
            prompt = self.prompt_manager.format(
                "quality_recommendations_base",
                chat_name=chat_name,
                metrics_json=json.dumps(payload, ensure_ascii=False, indent=2),
            )

            if not prompt.strip():
                logger.warning("–ü—Ä–æ–º–ø—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø—É—Å—Ç ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é")
                return []

            # –°–æ–∑–¥–∞–µ–º JSON —Å—Ö–µ–º—É –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            json_schema = """[{
    "title": "[TITLE]",
    "description": "[DESCRIPTION]",
    "suggestions": [SUGGESTIONS],
    "priority": "[PRIORITY]"
}]"""

            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–ª—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
            constraints = """
    len([RECOMMENDATIONS]) <= 10 and
    all(isinstance(r, dict) for r in [RECOMMENDATIONS]) and
    all("title" in r and "description" in r for r in [RECOMMENDATIONS]) and
    all(r.get("priority") in ["high", "medium", "low", "ai"] for r in [RECOMMENDATIONS] if "priority" in r)
"""

            # –í—ã–ø–æ–ª–Ω—è–µ–º LMQL –∑–∞–ø—Ä–æ—Å
            result = await self.lmql_adapter.execute_json_query(
                prompt=prompt,
                json_schema=json_schema,
                constraints=constraints,
                temperature=self.temperature,
                max_tokens=min(self.max_tokens, 4096),  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            )

            if not result:
                return []

            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if isinstance(result, list):
                return self._normalize_llm_entries(result)
            elif isinstance(result, dict) and "recommendations" in result:
                recommendations = result["recommendations"]
                if isinstance(recommendations, list):
                    return self._normalize_llm_entries(recommendations)

            logger.warning(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ LMQL: {type(result)}")
            return []

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ LMQL –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
            # Fallback –Ω–∞ —Å—Ç–∞—Ä—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –ø—Ä–∏ –æ—à–∏–±–∫–µ
            if self.embedding_client:
                try:
                    prompt = self.prompt_manager.format(
                        "quality_recommendations_base",
                        chat_name=chat_name,
                        metrics_json=json.dumps(payload, ensure_ascii=False, indent=2),
                    )
                    async with self.embedding_client:
                        response = await self.embedding_client.generate_summary(
                            prompt,
                            temperature=self.temperature,
                            max_tokens=self.max_tokens,
                        )
                    return self._parse_llm_recommendations(response)
                except Exception as fallback_exc:
                    logger.warning(f"Fallback —Ç–∞–∫–∂–µ –Ω–µ —É–¥–∞–ª—Å—è: {fallback_exc}")
            return []

    def _get_type_display_name(self, query_type: str) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º–æ–≥–æ –∏–º–µ–Ω–∏ —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–∞"""
        type_names = {
            "factual": "–§–∞–∫—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã",
            "contextual": "–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã",
            "analytical": "–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã",
            "custom": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã",
        }
        return type_names.get(query_type, query_type.title())

    def _get_problem_display_name(self, problem_type: str) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º–æ–≥–æ –∏–º–µ–Ω–∏ —Ç–∏–ø–∞ –ø—Ä–æ–±–ª–µ–º—ã"""
        problem_names = {
            "indexing": "–ü—Ä–æ–±–ª–µ–º—ã –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏",
            "search": "–ü—Ä–æ–±–ª–µ–º—ã –ø–æ–∏—Å–∫–∞",
            "context": "–ü—Ä–æ–±–ª–µ–º—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞",
        }
        return problem_names.get(problem_type, problem_type.title())

    def _get_trend_display_name(self, trend: str) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º–æ–≥–æ –∏–º–µ–Ω–∏ —Ç—Ä–µ–Ω–¥–∞"""
        trend_names = {
            "improving": "üìà –£–ª—É—á—à–µ–Ω–∏–µ",
            "declining": "üìâ –£—Ö—É–¥—à–µ–Ω–∏–µ",
            "stable": "‚û°Ô∏è –°—Ç–∞–±–∏–ª—å–Ω–æ",
            "no_data": "‚ùì –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
            "no_historical_data": "‚ùì –ù–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö",
        }
        return trend_names.get(trend, trend.title())

    def _format_basic_section(self, metrics: Dict[str, Any]) -> str:
        basic = metrics.get("basic", {})
        lines = [
            f"- **–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏:** {basic.get('average_score', 0):.2f}/10",
            f"- **–ú–µ–¥–∏–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞:** {basic.get('median_score', 0):.2f}/10",
            f"- **–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤:** {basic.get('success_rate', 0)*100:.1f}%",
            f"- **–í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:** {basic.get('total_queries', 0)}",
            f"- **–£—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:** {basic.get('successful_queries', 0)}",
        ]
        return "\n".join(lines)

    def _format_type_section(self, metrics: Dict[str, Any]) -> str:
        type_metrics = metrics.get("by_type", {})
        if not type_metrics:
            return "_–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ç–∏–ø–∞–º –∑–∞–ø—Ä–æ—Å–æ–≤._"

        blocks = []
        for query_type, values in type_metrics.items():
            block = [
                f"### {self._get_type_display_name(query_type)}",
                f"- **–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞:** {values.get('average_score', 0):.2f}/10",
                f"- **–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞:** {values.get('success_rate', 0)*100:.1f}%",
                f"- **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤:** {values.get('total_queries', 0)}",
                "",
            ]
            blocks.append("\n".join(block))
        return "\n".join(blocks)

    def _format_problem_section(self, metrics: Dict[str, Any]) -> str:
        problem_metrics = metrics.get("problems", {})
        total_problems = problem_metrics.get("total_problems", {})
        if not any(total_problems.values()):
            return "‚úÖ **–ü—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ**"

        lines = [
            "### –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º",
            f"- **–ü—Ä–æ–±–ª–µ–º—ã –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏:** {total_problems.get('indexing', 0)}",
            f"- **–ü—Ä–æ–±–ª–µ–º—ã –ø–æ–∏—Å–∫–∞:** {total_problems.get('search', 0)}",
            f"- **–ü—Ä–æ–±–ª–µ–º—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞:** {total_problems.get('context', 0)}",
            "",
        ]

        details = problem_metrics.get("problem_details", {})
        for problem_type, items in details.items():
            if not items:
                continue
            lines.append(f"### {self._get_problem_display_name(problem_type)}")
            for detail in items[:5]:
                lines.append(
                    f"- **–ó–∞–ø—Ä–æ—Å:** {detail.get('query', 'N/A')} ‚Äî {detail.get('score', 0):.1f}/10"
                )
            lines.append("")

        return "\n".join(lines)

    def _format_comparative_section(self, metrics: Dict[str, Any]) -> str:
        comparative = metrics.get("comparative", {})
        if not comparative.get("comparison_available"):
            return "_–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç._"

        lines = [
            "## üìà –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ –∞–Ω–∞–ª–∏–∑–∞–º–∏",
            f"- **–¢—Ä–µ–Ω–¥:** {self._get_trend_display_name(comparative.get('trend', 'no_data'))}",
            f"- **Œî —Å—Ä–µ–¥–Ω–µ–π –æ—Ü–µ–Ω–∫–∏:** {comparative.get('score_improvement', 0):+.2f}",
            f"- **Œî –ø—Ä–æ—Ü–µ–Ω—Ç–∞ —É—Å–ø–µ—Ö–∞:** {comparative.get('success_rate_improvement', 0)*100:+.1f}%",
        ]
        return "\n".join(lines)

    def _format_details_section(self, analysis_results: List[Dict[str, Any]]) -> str:
        blocks = []
        for idx, result in enumerate(analysis_results[:10], start=1):
            query_data = result.get("query", {})
            relevance = result.get("relevance_analysis", {})
            block_lines = [
                f"### –ó–∞–ø—Ä–æ—Å {idx}",
                f"**–¢–µ–∫—Å—Ç:** {query_data.get('query', 'N/A')}",
                f"**–¢–∏–ø:** {query_data.get('type', 'unknown')}",
                f"**–û—Ü–µ–Ω–∫–∞:** {relevance.get('overall_score', 0):.1f}/10",
                f"**–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:** {relevance.get('explanation', 'N/A')}",
            ]
            recs = relevance.get("recommendations", [])
            if recs:
                block_lines.append("**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**")
                block_lines.extend(f"- {rec}" for rec in recs)
            blocks.append("\n".join(block_lines))

        return "\n\n".join(blocks) if blocks else "_–ü–æ–¥—Ä–æ–±–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç._"

    def _format_recommendations_section(
        self,
        metrics: Dict[str, Any],
        llm_recommendations: Optional[List[Dict[str, Any]]] = None,
    ) -> str:
        recommendations = self._generate_improvement_recommendations(metrics)

        if llm_recommendations:
            recommendations.extend(self._normalize_llm_entries(llm_recommendations))

        if not recommendations:
            return "‚úÖ **–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–µ—Ç**"

        blocks = []
        for rec in recommendations:
            block = [
                f"### {rec.get('title', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è')}",
                rec.get("description", ""),
            ]

            priority = rec.get("priority")
            if priority:
                block.append(f"**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** {priority}")

            block.append("**–ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:**")

            suggestions = rec.get("suggestions", [])
            if isinstance(suggestions, str):
                suggestions = [suggestions]

            if not suggestions:
                block.append("- (–Ω–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π)")
            else:
                block.extend(f"- {suggestion}" for suggestion in suggestions)

            blocks.append("\n".join(filter(None, block)))

        return "\n\n".join(blocks)

    def _build_recommendation_payload(
        self,
        chat_name: str,
        metrics: Dict[str, Any],
        analysis_results: List[Dict[str, Any]],
        limit: int = 5,
    ) -> Dict[str, Any]:
        basic_metrics = self._get_metric_section(metrics, "basic")
        problem_metrics = self._get_metric_section(metrics, "problems")
        comparative_metrics = self._get_metric_section(metrics, "comparative")

        if not basic_metrics:
            return {}

        sorted_results = sorted(
            analysis_results,
            key=lambda item: item.get("relevance_analysis", {}).get(
                "overall_score", 0.0
            ),
        )

        low_score_examples: List[Dict[str, Any]] = []
        for result in sorted_results[:limit]:
            query_data = result.get("query", {})
            relevance = result.get("relevance_analysis", {})
            low_score_examples.append(
                {
                    "query": query_data.get("query"),
                    "query_type": query_data.get("type"),
                    "overall_score": relevance.get("overall_score"),
                    "problems": relevance.get("problems", {}),
                    "explanation": relevance.get("explanation"),
                    "recommendations": relevance.get("recommendations", []),
                }
            )

        problem_details = (
            problem_metrics.get("problem_details", {}) if problem_metrics else {}
        )
        limited_problem_details = {
            key: details[:limit] for key, details in problem_details.items()
        }

        return {
            "chat_name": chat_name,
            "basic_metrics": basic_metrics,
            "problem_summary": problem_metrics.get("total_problems", {})
            if problem_metrics
            else {},
            "comparative": comparative_metrics,
            "low_scores": low_score_examples,
            "problem_details": limited_problem_details,
        }

    def _parse_llm_recommendations(self, response: str) -> List[Dict[str, Any]]:
        if not response:
            return []

        response = response.strip()
        if not response:
            return []

        import re

        parsed_entries: List[Dict[str, Any]] = []
        match = re.search(r"\[[\s\S]*\]", response)

        if match:
            json_blob = match.group(0)
            try:
                data = json.loads(json_blob)
                if isinstance(data, list):
                    parsed_entries = [item for item in data if isinstance(item, dict)]
            except json.JSONDecodeError:
                logger.warning("–û—Ç–≤–µ—Ç LLM —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON")

        if not parsed_entries:
            text = response.replace("```", "").strip()
            if not text:
                return []

            suggestions = [
                line.strip("-‚Ä¢ ") for line in text.splitlines() if line.strip()
            ]

            return [
                {
                    "title": "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç LLM",
                    "description": suggestions[0] if suggestions else text[:200],
                    "suggestions": suggestions,
                    "priority": "ai",
                }
            ]

        return self._normalize_llm_entries(parsed_entries)

    def _normalize_llm_entries(
        self, entries: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        normalized: List[Dict[str, Any]] = []

        for entry in entries:
            title = entry.get("title") or entry.get("name") or "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è"
            description = entry.get("description") or entry.get("summary") or ""

            suggestions = (
                entry.get("suggestions") or entry.get("actions") or entry.get("steps")
            )
            if isinstance(suggestions, str):
                suggestions = [
                    item.strip("-‚Ä¢ ")
                    for item in suggestions.splitlines()
                    if item.strip()
                ]
            elif suggestions is None:
                suggestions = []

            priority = entry.get("priority") or entry.get("impact")
            if isinstance(priority, (dict, list)):
                priority = None

            normalized.append(
                {
                    "title": title,
                    "description": description,
                    "suggestions": suggestions,
                    "priority": priority,
                }
            )

        return normalized

    def _get_metric_section(
        self, metrics: Dict[str, Any], section: str
    ) -> Dict[str, Any]:
        if section in metrics:
            value = metrics.get(section)
            return value if isinstance(value, dict) else {}

        details = metrics.get("details")
        if isinstance(details, dict):
            sub_value = details.get(section)
            if isinstance(sub_value, dict):
                return sub_value

        return {}

    def _format_overall_basic(self, overall_metrics: Dict[str, Any]) -> str:
        lines = [
            f"- **–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞:** {overall_metrics.get('average_score', 0):.2f}/10",
            f"- **–ú–µ–¥–∏–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞:** {overall_metrics.get('median_score', 0):.2f}/10",
            f"- **–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —á–∞—Ç–æ–≤:** {overall_metrics.get('total_chats', 0)}",
            f"- **–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ:** {overall_metrics.get('successful_chats', 0)}",
        ]
        return "\n".join(lines)

    def _format_chat_table(self, overall_metrics: Dict[str, Any]) -> str:
        chat_metrics = overall_metrics.get("chat_metrics", {})
        if not chat_metrics:
            return "_–ù–µ—Ç –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ —á–∞—Ç–∞–º._"

        header = "| –ß–∞—Ç | –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ | –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞ | –ó–∞–ø—Ä–æ—Å–æ–≤ |\n|-----|----------------|----------------|----------|"
        rows = [
            f"| {chat_name} | {vals.get('average_score', 0):.2f} | {vals.get('success_rate', 0)*100:.1f}% | {vals.get('total_queries', 0)} |"
            for chat_name, vals in chat_metrics.items()
        ]
        return "\n".join([header, *rows])

    def _format_overall_problems(self, overall_metrics: Dict[str, Any]) -> str:
        total_problems = overall_metrics.get("total_problems", {})
        if not any(total_problems.values()):
            return "‚úÖ **–û–±—â–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã**"
        return "\n".join(
            [
                f"- –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è: {total_problems.get('indexing', 0)}",
                f"- –ü–æ–∏—Å–∫: {total_problems.get('search', 0)}",
                f"- –ö–æ–Ω—Ç–µ–∫—Å—Ç: {total_problems.get('context', 0)}",
            ]
        )

    def _format_overall_recommendations(self, overall_metrics: Dict[str, Any]) -> str:
        recs = self._generate_general_recommendations(overall_metrics)
        if not recs:
            return (
                "‚úÖ **–°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ, –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è**"
            )
        blocks = []
        for rec in recs:
            block = [
                f"### {rec.get('title', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è')}",
                rec.get("description", ""),
                "**–ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:**",
            ]
            block.extend(f"- {suggestion}" for suggestion in rec.get("suggestions", []))
            blocks.append("\n".join(block))
        return "\n\n".join(blocks)

    def _fallback_chat_report(
        self,
        chat_name: str,
        metrics: Dict[str, Any],
        analysis_results: List[Dict[str, Any]],
        llm_recommendations: Optional[List[Dict[str, Any]]] = None,
    ) -> str:
        logger.warning("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –¥–ª—è %s", chat_name)
        return "\n".join(
            [
                f"# –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞ - {chat_name}",
                f"**–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                "",
                self._format_basic_section(metrics),
                self._format_type_section(metrics),
                self._format_problem_section(metrics),
                self._format_comparative_section(metrics),
                self._format_details_section(analysis_results),
                self._format_recommendations_section(
                    metrics,
                    llm_recommendations=llm_recommendations,
                ),
            ]
        )

    def _fallback_overall_report(self, overall_metrics: Dict[str, Any]) -> str:
        logger.warning("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞")
        return "\n".join(
            [
                "# –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞",
                f"**–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                self._format_overall_basic(overall_metrics),
                self._format_chat_table(overall_metrics),
                self._format_overall_problems(overall_metrics),
                self._format_overall_recommendations(overall_metrics),
            ]
        )

    def _generate_improvement_recommendations(
        self, metrics: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —á–∞—Ç–∞"""
        recommendations = []

        basic_metrics = metrics.get("basic", {})
        average_score = basic_metrics.get("average_score", 0)
        basic_metrics.get("success_rate", 0)

        problem_metrics = metrics.get("problems", {})
        total_problems = problem_metrics.get("total_problems", {})

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –Ω–∏–∑–∫–∏–º –æ—Ü–µ–Ω–∫–∞–º
        if average_score < 5:
            recommendations.append(
                {
                    "title": "–ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞",
                    "description": f"–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç {average_score:.2f}/10, —á—Ç–æ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Å–µ—Ä—å–µ–∑–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã.",
                    "suggestions": [
                        "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏",
                        "–£–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤",
                        "–ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞",
                        "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
                    ],
                }
            )

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–æ–±–ª–µ–º–∞–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        if total_problems.get("indexing", 0) > 0:
            recommendations.append(
                {
                    "title": "–ü—Ä–æ–±–ª–µ–º—ã —Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–µ–π",
                    "description": f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {total_problems['indexing']} –ø—Ä–æ–±–ª–µ–º —Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–µ–π.",
                    "suggestions": [
                        "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π",
                        "–£–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–æ–≤ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π",
                        "–£–ª—É—á—à–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π",
                        "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤",
                    ],
                }
            )

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–æ–±–ª–µ–º–∞–º –ø–æ–∏—Å–∫–∞
        if total_problems.get("search", 0) > 0:
            recommendations.append(
                {
                    "title": "–ü—Ä–æ–±–ª–µ–º—ã —Å –ø–æ–∏—Å–∫–æ–º",
                    "description": f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {total_problems['search']} –ø—Ä–æ–±–ª–µ–º —Å –ø–æ–∏—Å–∫–æ–º.",
                    "suggestions": [
                        "–ù–∞—Å—Ç—Ä–æ–∏—Ç—å –≤–µ—Å–∞ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞",
                        "–£–ª—É—á—à–∏—Ç—å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞",
                        "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ—Ä–æ–≥–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏",
                        "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è",
                    ],
                }
            )

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–æ–±–ª–µ–º–∞–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if total_problems.get("context", 0) > 0:
            recommendations.append(
                {
                    "title": "–ü—Ä–æ–±–ª–µ–º—ã —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º",
                    "description": f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {total_problems['context']} –ø—Ä–æ–±–ª–µ–º —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º.",
                    "suggestions": [
                        "–£–ª—É—á—à–∏—Ç—å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Å–µ—Å—Å–∏–∏",
                        "–ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏",
                        "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏",
                        "–£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö",
                    ],
                }
            )

        return recommendations

    def _generate_general_recommendations(
        self, overall_metrics: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—â–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        recommendations = []

        average_score = overall_metrics.get("average_score", 0)
        total_problems = overall_metrics.get("total_problems", {})

        # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
        if average_score < 6:
            recommendations.append(
                {
                    "title": "–û–±—â–µ–µ —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∏—Å—Ç–µ–º—ã",
                    "description": f"–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç {average_score:.2f}/10, —á—Ç–æ —Ç—Ä–µ–±—É–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —É–ª—É—á—à–µ–Ω–∏–π.",
                    "suggestions": [
                        "–ü—Ä–æ–≤–µ—Å—Ç–∏ –ø–æ–ª–Ω—ã–π –∞—É–¥–∏—Ç —Å–∏—Å—Ç–µ–º—ã –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏",
                        "–û–±–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤",
                        "–ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞ –¥–ª—è –≤—Å–µ—Ö —á–∞—Ç–æ–≤",
                        "–í–Ω–µ–¥—Ä–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞—á–µ—Å—Ç–≤–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏",
                    ],
                }
            )

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–æ–±–ª–µ–º–∞–º
        total_problem_count = sum(total_problems.values())
        if total_problem_count > 0:
            recommendations.append(
                {
                    "title": "–°–∏—Å—Ç–µ–º–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º",
                    "description": f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {total_problem_count} –ø—Ä–æ–±–ª–µ–º –≤ —Å–∏—Å—Ç–µ–º–µ.",
                    "suggestions": [
                        "–°–æ–∑–¥–∞—Ç—å –ø–ª–∞–Ω —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É",
                        "–í–Ω–µ–¥—Ä–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã –∫–∞—á–µ—Å—Ç–≤–∞",
                        "–ù–∞—Å—Ç—Ä–æ–∏—Ç—å –∞–ª–µ—Ä—Ç—ã –ø—Ä–∏ —Å–Ω–∏–∂–µ–Ω–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞",
                        "–†–µ–≥—É–ª—è—Ä–Ω–æ –ø—Ä–æ–≤–æ–¥–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞",
                    ],
                }
            )

        return recommendations

    def _save_chat_report(self, chat_name: str, report_content: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –ø–æ —á–∞—Ç—É"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{chat_name}_quality_analysis_{timestamp}.md"
        filepath = self.quality_reports_dir / filename

        with open(filepath, "w", encoding="utf-8") as f:
            f.write(report_content)

        logger.info(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filepath}")

    def _save_overall_report(self, report_content: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—â–µ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"overall_quality_analysis_{timestamp}.md"
        filepath = self.quality_reports_dir / filename

        with open(filepath, "w", encoding="utf-8") as f:
            f.write(report_content)

        logger.info(f"–û–±—â–∏–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filepath}")
