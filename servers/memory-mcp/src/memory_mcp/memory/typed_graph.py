#!/usr/bin/env python3
"""
–¢–∏–ø–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π

–í–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω–æ HALv1 Memory 2.0 Typed Graph Memory.
–•—Ä–∞–Ω–∏—Ç —É–∑–ª—ã –∏ —Ä—ë–±—Ä–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –≤ SQLite + NetworkX.
"""

import json
import logging
import sqlite3
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Tuple

import networkx as nx

from ..utils.russian_tokenizer import STOP_WORDS, get_tokenizer, get_word_variants
from .graph_types import EdgeType, GraphEdge, GraphNode, GraphPath, GraphStats, NodeType

logger = logging.getLogger(__name__)


class TypedGraphMemory:
    """–¢–∏–ø–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π —Å –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ–º"""

    def __init__(self, db_path: str = "./data/memory_graph.db"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∞

        Args:
            db_path: –ü—É—Ç—å –∫ SQLite –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        """
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)

        # NetworkX –≥—Ä–∞—Ñ –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
        self.graph = nx.DiGraph()

        # SQLite –¥–ª—è –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        self.conn = sqlite3.connect(str(self.db_path))
        self.conn.row_factory = sqlite3.Row

        self._initialize_schema()
        self._load_graph_from_db()

        logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω TypedGraphMemory: {db_path}")

    def _initialize_schema(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ö–µ–º—ã –ë–î"""
        cursor = self.conn.cursor()

        # –¢–∞–±–ª–∏—Ü–∞ —É–∑–ª–æ–≤
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS nodes (
                id TEXT PRIMARY KEY,
                type TEXT NOT NULL,
                label TEXT NOT NULL,
                properties TEXT,
                embedding BLOB,
                created_at TEXT,
                updated_at TEXT
            )
        """
        )

        # –¢–∞–±–ª–∏—Ü–∞ —Ä—ë–±–µ—Ä
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS edges (
                id TEXT PRIMARY KEY,
                source_id TEXT NOT NULL,
                target_id TEXT NOT NULL,
                type TEXT NOT NULL,
                weight REAL DEFAULT 1.0,
                properties TEXT,
                created_at TEXT,
                bidirectional INTEGER DEFAULT 0,
                FOREIGN KEY (source_id) REFERENCES nodes(id) ON DELETE CASCADE,
                FOREIGN KEY (target_id) REFERENCES nodes(id) ON DELETE CASCADE
            )
        """
        )

        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_nodes_type ON nodes(type)")
        cursor.execute(
            "CREATE INDEX IF NOT EXISTS idx_edges_source ON edges(source_id)"
        )
        cursor.execute(
            "CREATE INDEX IF NOT EXISTS idx_edges_target ON edges(target_id)"
        )
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_edges_type ON edges(type)")

        # –¢–∞–±–ª–∏—Ü–∞ –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞
        cursor.execute(
            """
            CREATE VIRTUAL TABLE IF NOT EXISTS node_search
            USING fts5(
                node_id UNINDEXED,
                content,
                source,
                tags,
                entities,
                tokenize = 'unicode61'
            )
        """
        )

        self.conn.commit()
        logger.info("–°—Ö–µ–º–∞ –ë–î –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

    def _load_graph_from_db(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞—Ñ–∞ –∏–∑ –ë–î –≤ –ø–∞–º—è—Ç—å (NetworkX)"""
        cursor = self.conn.cursor()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —É–∑–ª—ã (–≤–∫–ª—é—á–∞—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∏)
        cursor.execute("SELECT id, type, label, properties, embedding FROM nodes")
        for row in cursor.fetchall():
            props = json.loads(row["properties"]) if row["properties"] else {}
            node_attrs = {
                "node_type": row["type"],
                "label": row["label"],
                "properties": props,
                **props,
            }
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥, –µ—Å–ª–∏ –µ—Å—Ç—å
            if row["embedding"]:
                try:
                    embedding = json.loads(row["embedding"].decode())
                    node_attrs["embedding"] = embedding
                except Exception:
                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                    pass
            self.graph.add_node(row["id"], **node_attrs)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä—ë–±—Ä–∞
        cursor.execute(
            "SELECT source_id, target_id, type, weight, properties FROM edges"
        )
        for row in cursor.fetchall():
            props = json.loads(row["properties"]) if row["properties"] else {}
            self.graph.add_edge(
                row["source_id"],
                row["target_id"],
                edge_type=row["type"],
                weight=row["weight"],
                **props,
            )

        logger.info(
            f"–ì—Ä–∞—Ñ –∑–∞–≥—Ä—É–∂–µ–Ω: {self.graph.number_of_nodes()} —É–∑–ª–æ–≤, "
            f"{self.graph.number_of_edges()} —Ä—ë–±–µ—Ä"
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º FTS –∏–Ω–¥–µ–∫—Å –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        for node_id, data in self.graph.nodes(data=True):
            if data.get("node_type") in (NodeType.DOC_CHUNK, NodeType.DOC_CHUNK.value):
                props = data.get("properties", {})
                self._fts_refresh_doc(
                    node_id=node_id,
                    content=data.get("content", ""),
                    source=data.get("source", ""),
                    tags=props.get("tags", []),
                    entities=props.get("entities", []),
                    properties=props,
                )

    def add_node(self, node: GraphNode) -> bool:
        """
        –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —É–∑–ª–∞ –≤ –≥—Ä–∞—Ñ

        Args:
            node: –£–∑–µ–ª –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è

        Returns:
            True –µ—Å–ª–∏ —É–∑–µ–ª –¥–æ–±–∞–≤–ª–µ–Ω, False –µ—Å–ª–∏ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        """
        if node.id in self.graph:
            logger.warning(f"–£–∑–µ–ª {node.id} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            return False

        try:
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ NetworkX
            node_data = node.dict(exclude={"embedding"})
            self.graph.add_node(node.id, **node_data)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
            cursor = self.conn.cursor()

            embedding_bytes = (
                json.dumps(node.embedding).encode() if node.embedding else None
            )

            cursor.execute(
                """
                INSERT INTO nodes (id, type, label, properties, embedding, created_at, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """,
                (
                    node.id,
                    node.type.value if isinstance(node.type, NodeType) else node.type,
                    node.label,
                    json.dumps(node.properties),
                    embedding_bytes,
                    node.created_at or datetime.now().isoformat(),
                    node.updated_at or datetime.now().isoformat(),
                ),
            )

            self.conn.commit()

            if node.type == NodeType.DOC_CHUNK:
                self._fts_refresh_doc(
                    node_id=node.id,
                    content=getattr(node, "content", ""),
                    source=getattr(node, "source", ""),
                    tags=node.properties.get("tags", []),
                    entities=node.properties.get("entities", []),
                    properties=node.properties,
                )

            logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω —É–∑–µ–ª: {node.id} ({node.type})")
            return True

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —É–∑–ª–∞ {node.id}: {e}")
            self.conn.rollback()
            return False

    def update_node(
        self,
        node_id: str,
        *,
        properties: Optional[Dict[str, Any]] = None,
        content: Optional[str] = None,
        source: Optional[str] = None,
        tags: Optional[List[str]] = None,
        entities: Optional[List[str]] = None,
        embedding: Optional[List[float]] = None,
    ) -> bool:
        """
        –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–≤–æ–π—Å—Ç–≤ —É–∑–ª–∞

        Args:
            node_id: ID —É–∑–ª–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            properties: –ù–æ–≤—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞ (–æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏)
            content: –ù–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (–¥–ª—è DOC_CHUNK)
            source: –ù–æ–≤—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫
            tags: –ù–æ–≤—ã–µ —Ç–µ–≥–∏
            entities: –ù–æ–≤—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏
            embedding: –ù–æ–≤—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥

        Returns:
            True –µ—Å–ª–∏ —É–∑–µ–ª –æ–±–Ω–æ–≤–ª—ë–Ω
        """
        if node_id not in self.graph:
            logger.error(f"–£–∑–µ–ª {node_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False

        try:
            cursor = self.conn.cursor()
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ —É–∑–ª–∞
            cursor.execute(
                "SELECT type, properties, embedding FROM nodes WHERE id = ?",
                (node_id,),
            )
            row = cursor.fetchone()
            if not row:
                logger.error(f"–£–∑–µ–ª {node_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ë–î")
                return False

            node_type = row["type"]
            current_props = json.loads(row["properties"]) if row["properties"] else {}
            current_embedding = (
                json.loads(row["embedding"].decode()) if row["embedding"] else None
            )

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–≤–æ–π—Å—Ç–≤–∞
            updated_props = dict(current_props)
            if properties:
                updated_props.update(properties)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–æ–ª—è
            if content is not None:
                updated_props["content"] = content
            if source is not None:
                updated_props["source"] = source
            if tags is not None:
                updated_props["tags"] = tags
            if entities is not None:
                updated_props["entities"] = entities

            # –û–±–Ω–æ–≤–ª—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
            new_embedding = embedding if embedding is not None else current_embedding
            embedding_bytes = (
                json.dumps(new_embedding).encode() if new_embedding else None
            )

            # –û–±–Ω–æ–≤–ª—è–µ–º –≤ –ë–î
            cursor.execute(
                """
                UPDATE nodes 
                SET properties = ?, embedding = ?, updated_at = ?
                WHERE id = ?
            """,
                (
                    json.dumps(updated_props),
                    embedding_bytes,
                    datetime.now().isoformat(),
                    node_id,
                ),
            )

            # –û–±–Ω–æ–≤–ª—è–µ–º –≤ NetworkX –≥—Ä–∞—Ñ–µ
            if node_id in self.graph:
                self.graph.nodes[node_id]["properties"] = updated_props
                if content is not None:
                    self.graph.nodes[node_id]["content"] = content
                if source is not None:
                    self.graph.nodes[node_id]["source"] = source
                if new_embedding is not None:
                    self.graph.nodes[node_id]["embedding"] = new_embedding

            self.conn.commit()

            # –û–±–Ω–æ–≤–ª—è–µ–º FTS –∏–Ω–¥–µ–∫—Å –¥–ª—è DOC_CHUNK
            if node_type == NodeType.DOC_CHUNK.value or node_type == NodeType.DOC_CHUNK:
                final_content = content or updated_props.get("content", "")
                final_source = source or updated_props.get("source", "")
                final_tags = tags or updated_props.get("tags", [])
                final_entities = entities or updated_props.get("entities", [])
                
                self._fts_refresh_doc(
                    node_id=node_id,
                    content=final_content,
                    source=final_source,
                    tags=final_tags,
                    entities=final_entities,
                    properties=updated_props,
                )

            logger.info(f"–û–±–Ω–æ–≤–ª—ë–Ω —É–∑–µ–ª: {node_id}")
            return True

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —É–∑–ª–∞ {node_id}: {e}")
            self.conn.rollback()
            return False

    def delete_node(self, node_id: str) -> bool:
        """
        –£–¥–∞–ª–µ–Ω–∏–µ —É–∑–ª–∞ –∏–∑ –≥—Ä–∞—Ñ–∞

        Args:
            node_id: ID —É–∑–ª–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è

        Returns:
            True –µ—Å–ª–∏ —É–∑–µ–ª —É–¥–∞–ª—ë–Ω
        """
        if node_id not in self.graph:
            logger.warning(f"–£–∑–µ–ª {node_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –≥—Ä–∞—Ñ–µ")
            return False

        try:
            cursor = self.conn.cursor()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —É–∑–ª–∞ –≤ –ë–î
            cursor.execute("SELECT id FROM nodes WHERE id = ?", (node_id,))
            if not cursor.fetchone():
                logger.warning(f"–£–∑–µ–ª {node_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ë–î")
                return False

            # –£–¥–∞–ª—è–µ–º –∏–∑ FTS –∏–Ω–¥–µ–∫—Å–∞
            cursor.execute("DELETE FROM node_search WHERE node_id = ?", (node_id,))

            # –£–¥–∞–ª—è–µ–º –≤—Å–µ —Ä—ë–±—Ä–∞, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å —É–∑–ª–æ–º
            # –°–Ω–∞—á–∞–ª–∞ —É–¥–∞–ª—è–µ–º –∏—Å—Ö–æ–¥—è—â–∏–µ —Ä—ë–±—Ä–∞
            cursor.execute(
                "DELETE FROM edges WHERE source_id = ? OR target_id = ?",
                (node_id, node_id),
            )

            # –£–¥–∞–ª—è–µ–º —É–∑–µ–ª –∏–∑ –ë–î
            cursor.execute("DELETE FROM nodes WHERE id = ?", (node_id,))

            # –£–¥–∞–ª—è–µ–º –∏–∑ NetworkX –≥—Ä–∞—Ñ–∞ (—ç—Ç–æ —Ç–∞–∫–∂–µ —É–¥–∞–ª–∏—Ç –≤—Å–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ä—ë–±—Ä–∞)
            if node_id in self.graph:
                self.graph.remove_node(node_id)

            self.conn.commit()
            logger.info(f"–£–¥–∞–ª—ë–Ω —É–∑–µ–ª: {node_id}")
            return True

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —É–∑–ª–∞ {node_id}: {e}")
            self.conn.rollback()
            return False

    def delete_nodes_by_chat(self, chat_name: str) -> int:
        """
        –£–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö —É–∑–ª–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —á–∞—Ç–∞ –∏–∑ –≥—Ä–∞—Ñ–∞.

        Args:
            chat_name: –ù–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è

        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö —É–∑–ª–æ–≤
        """
        deleted_count = 0
        try:
            cursor = self.conn.cursor()

            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —É–∑–ª—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å —á–∞—Ç–æ–º
            # 1. –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ FTS –∏–Ω–¥–µ–∫—Å –ø–æ tags
            node_ids_from_fts = set()
            try:
                # FTS –ø–æ–∏—Å–∫ –ø–æ —Ç–µ–≥–∞–º (tags —Ö—Ä–∞–Ω—è—Ç—Å—è –∫–∞–∫ —Å—Ç—Ä–æ–∫–∞ —Å –ø—Ä–æ–±–µ–ª–∞–º–∏)
                fts_rows = cursor.execute(
                    "SELECT node_id FROM node_search WHERE tags MATCH ?",
                    (chat_name,),
                ).fetchall()
                node_ids_from_fts.update(row["node_id"] for row in fts_rows)
            except Exception as e:
                logger.debug(f"FTS –ø–æ–∏—Å–∫ –ø–æ —Ç–µ–≥–∞–º –Ω–µ —É–¥–∞–ª—Å—è: {e}")

            # 2. –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ properties –≤ nodes (chat –≤ metadata –∏–ª–∏ tags –≤ —Å–ø–∏—Å–∫–µ)
            node_ids_from_props = set()
            try:
                # –ò—â–µ–º —É–∑–ª—ã, –≥–¥–µ chat_name –≤—Ö–æ–¥–∏—Ç –≤ tags –∏–ª–∏ metadata.chat
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º JSON —Ñ—É–Ω–∫—Ü–∏–∏ SQLite –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ JSON
                all_nodes = cursor.execute(
                    "SELECT id, properties FROM nodes WHERE properties IS NOT NULL"
                ).fetchall()

                for row in all_nodes:
                    try:
                        props = json.loads(row["properties"]) if row["properties"] else {}
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º metadata.chat
                        metadata = props.get("metadata", {})
                        if isinstance(metadata, dict) and metadata.get("chat") == chat_name:
                            node_ids_from_props.add(row["id"])
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º tags (–º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ø–∏—Å–æ–∫ –∏–ª–∏ —Å—Ç—Ä–æ–∫–∞)
                        tags = props.get("tags", [])
                        if isinstance(tags, list) and chat_name in tags:
                            node_ids_from_props.add(row["id"])
                        elif isinstance(tags, str) and chat_name in tags:
                            node_ids_from_props.add(row["id"])
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º chat –Ω–∞–ø—Ä—è–º—É—é –≤ properties
                        if props.get("chat") == chat_name:
                            node_ids_from_props.add(row["id"])
                    except (json.JSONDecodeError, Exception) as e:
                        logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ properties –¥–ª—è —É–∑–ª–∞ {row['id']}: {e}")
                        continue
            except Exception as e:
                logger.debug(f"–ü–æ–∏—Å–∫ –ø–æ properties –Ω–µ —É–¥–∞–ª—Å—è: {e}")

            # 3. –ü–æ–∏—Å–∫ –ø–æ record_id (—Ñ–æ—Ä–º–∞—Ç: source:chat_name:record_id)
            node_ids_from_id = set()
            try:
                id_pattern = f"%:{chat_name}:%"
                id_rows = cursor.execute(
                    "SELECT id FROM nodes WHERE id LIKE ?",
                    (id_pattern,),
                ).fetchall()
                node_ids_from_id.update(row["id"] for row in id_rows)
            except Exception as e:
                logger.debug(f"–ü–æ–∏—Å–∫ –ø–æ ID –Ω–µ —É–¥–∞–ª—Å—è: {e}")

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ ID
            all_node_ids = node_ids_from_fts | node_ids_from_props | node_ids_from_id

            logger.info(
                f"–ù–∞–π–¥–µ–Ω–æ {len(all_node_ids)} —É–∑–ª–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è (—á–∞—Ç: {chat_name})"
            )

            # –£–¥–∞–ª—è–µ–º –∫–∞–∂–¥—ã–π —É–∑–µ–ª (delete_node —É–∂–µ —É–¥–∞–ª—è–µ—Ç —Ä—ë–±—Ä–∞ –∏ FTS –∑–∞–ø–∏—Å–∏)
            for node_id in all_node_ids:
                if self.delete_node(node_id):
                    deleted_count += 1

            logger.info(f"–£–¥–∞–ª–µ–Ω–æ {deleted_count} —É–∑–ª–æ–≤ –¥–ª—è —á–∞—Ç–∞ {chat_name}")
            return deleted_count

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —É–∑–ª–æ–≤ —á–∞—Ç–∞ {chat_name}: {e}", exc_info=True)
            self.conn.rollback()
            return deleted_count

    def add_edge(self, edge: GraphEdge) -> bool:
        """
        –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–±—Ä–∞ –≤ –≥—Ä–∞—Ñ

        Args:
            edge: –†–µ–±—Ä–æ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è

        Returns:
            True –µ—Å–ª–∏ —Ä–µ–±—Ä–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —É–∑–ª–æ–≤
        if edge.source_id not in self.graph or edge.target_id not in self.graph:
            logger.error(
                f"–£–∑–ª—ã –¥–ª—è —Ä–µ–±—Ä–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç: {edge.source_id} -> {edge.target_id}"
            )
            return False

        try:
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ NetworkX
            self.graph.add_edge(
                edge.source_id,
                edge.target_id,
                edge_type=edge.type.value
                if isinstance(edge.type, EdgeType)
                else edge.type,
                weight=edge.weight,
                **edge.properties,
            )

            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ–µ —Ä–µ–±—Ä–æ –µ—Å–ª–∏ bidirectional
            if edge.bidirectional:
                self.graph.add_edge(
                    edge.target_id,
                    edge.source_id,
                    edge_type=edge.type.value
                    if isinstance(edge.type, EdgeType)
                    else edge.type,
                    weight=edge.weight,
                    **edge.properties,
                )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
            cursor = self.conn.cursor()
            cursor.execute(
                """
                INSERT INTO edges (id, source_id, target_id, type, weight, properties, created_at, bidirectional)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """,
                (
                    edge.id,
                    edge.source_id,
                    edge.target_id,
                    edge.type.value if isinstance(edge.type, EdgeType) else edge.type,
                    edge.weight,
                    json.dumps(edge.properties),
                    edge.created_at or datetime.now().isoformat(),
                    1 if edge.bidirectional else 0,
                ),
            )

            self.conn.commit()
            logger.info(
                f"–î–æ–±–∞–≤–ª–µ–Ω–æ —Ä–µ–±—Ä–æ: {edge.source_id} -> {edge.target_id} ({edge.type})"
            )
            return True

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ä–µ–±—Ä–∞ {edge.id}: {e}")
            self.conn.rollback()
            return False

    # ------------------------------------------------------------------
    def _fts_refresh_doc(
        self,
        *,
        node_id: str,
        content: str,
        source: str,
        tags: Iterable[str],
        entities: Iterable[str],
        properties: Optional[Dict[str, Any]] = None,
    ) -> None:
        """
        Insert or update document chunk entry in FTS index.
        –í–∫–ª—é—á–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ –ø–æ–ª–µ content –¥–ª—è –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞.
        """
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ properties –∏–ª–∏ –∏–∑ —É–∑–ª–∞ –≥—Ä–∞—Ñ–∞
        metadata_parts = []
        if properties is None and node_id in self.graph:
            properties = self.graph.nodes[node_id].get("properties", {})
        
        if properties:
            # –î–æ–±–∞–≤–ª—è–µ–º username –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è, –µ—Å–ª–∏ –µ—Å—Ç—å
            sender_username = properties.get("sender_username")
            if sender_username:
                metadata_parts.append(f"@{sender_username}")
            elif properties.get("author"):
                metadata_parts.append(properties.get("author"))
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∞–∫—Ü–∏–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
            reactions = properties.get("reactions")
            if reactions and isinstance(reactions, list) and len(reactions) > 0:
                reaction_strs = []
                for reaction in reactions:
                    if isinstance(reaction, dict):
                        emoji = reaction.get("emoji", "")
                        count = reaction.get("count", 0)
                        if emoji and count > 0:
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º emoji –∏–∑ —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞ "ReactionEmoji(emoticon='üëç')"
                            if "emoticon=" in str(emoji):
                                try:
                                    emoji_value = str(emoji).split("emoticon=")[1].split("'")[1]
                                    reaction_strs.append(f"{emoji_value} x{count}")
                                except (IndexError, AttributeError):
                                    reaction_strs.append(f"{emoji} x{count}")
                            else:
                                reaction_strs.append(f"{emoji} x{count}")
                if reaction_strs:
                    metadata_parts.append(f"–†–µ–∞–∫—Ü–∏–∏: {', '.join(reaction_strs)}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
            edited_utc = properties.get("edited_utc")
            if edited_utc:
                metadata_parts.append(f"–û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–æ: {edited_utc}")

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è FTS5
        extended_content = content or ""
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã —Å–ª–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞
        if extended_content:
            try:
                tokenizer = get_tokenizer()
                # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
                tokens = tokenizer.tokenize(extended_content)
                # –°–æ–±–∏—Ä–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã
                normalized_forms = []
                for token in tokens:
                    # –ü–æ–ª—É—á–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å–ª–æ–≤–∞ (–∏—Å—Ö–æ–¥–Ω–æ–µ + –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞)
                    variants = get_word_variants(token)
                    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã, –æ—Ç–ª–∏—á–Ω—ã–µ –æ—Ç –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞
                    for variant in variants:
                        if variant != token.lower():
                            normalized_forms.append(variant)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã –∫ –∫–æ–Ω—Ç–µ–Ω—Ç—É
                if normalized_forms:
                    extended_content = f"{extended_content} {' '.join(normalized_forms)}"
            except Exception as e:
                # –ï—Å–ª–∏ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –Ω–µ—ë
                logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–æ—Ä–º –¥–ª—è {node_id}: {e}")
        
        if metadata_parts:
            extended_content = f"{extended_content}\n{' '.join(metadata_parts)}"

        cursor = self.conn.cursor()
        cursor.execute("DELETE FROM node_search WHERE node_id = ?", (node_id,))
        cursor.execute(
            """
            INSERT INTO node_search (node_id, content, source, tags, entities)
            VALUES (?, ?, ?, ?, ?)
        """,
            (
                node_id,
                extended_content,
                source or "",
                " ".join(sorted({str(tag) for tag in tags if tag})),
                " ".join(sorted({str(entity) for entity in entities if entity})),
            ),
        )
        self.conn.commit()

    def _prepare_match_expression(self, query: str) -> str:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è FTS5 –ø–æ–∏—Å–∫–∞ —Å –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—é –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º–∏ —Ñ–æ—Ä–º–∞–º–∏ —Å–ª–æ–≤.
        –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ –¥–æ–±–∞–≤–ª—è–µ—Ç –µ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç—ã (–∏—Å—Ö–æ–¥–Ω–æ–µ + –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞).
        –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ (–ø—Ä–µ–¥–ª–æ–≥–∏, —Å–æ—é–∑—ã, –º–µ—Å—Ç–æ–∏–º–µ–Ω–∏—è).
        
        –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (<=3 –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤–∞) –∏—Å–ø–æ–ª—å–∑—É–µ—Ç AND –ª–æ–≥–∏–∫—É.
        –î–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (>3 –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤–∞) –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≥–∏–±–∫—É—é –ª–æ–≥–∏–∫—É:
        - –ü–µ—Ä–≤—ã–µ 2-3 —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ AND (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ)
        - –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ OR (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ)
        –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –Ω–∞—Ö–æ–¥–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–ª–æ–≤–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.
        """
        # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å —Å –ø–æ–º–æ—â—å—é russian_tokenizer
        tokenizer = get_tokenizer()
        tokens = tokenizer.tokenize(query)
        
        if not tokens:
            # Fallback –Ω–∞ –ø—Ä–æ—Å—Ç—É—é —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é, –µ—Å–ª–∏ russian_tokenizer –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
            tokens = [token.strip().lower() for token in query.replace('"', "").split() if token.strip()]
            if not tokens:
                return ""
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –∏ –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–æ–∫–µ–Ω—ã (–º–µ–Ω—å—à–µ 2 —Å–∏–º–≤–æ–ª–æ–≤)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ —Å—Ç–æ–ø-—Å–ª–æ–≤ –∏–∑ russian_tokenizer
        significant_tokens = [
            token for token in tokens
            if token.lower() not in STOP_WORDS and len(token) >= 2
        ]
        
        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –∑–Ω–∞—á–∏–º—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ —Ç–æ–∫–µ–Ω—ã
        if not significant_tokens:
            significant_tokens = tokens
        
        # –†–∞—Å—à–∏—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω –µ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ (–∏—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ + –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞)
        expanded_tokens = []
        for token in significant_tokens:
            variants = get_word_variants(token)
            if len(variants) > 1:
                # –ï—Å–ª–∏ –µ—Å—Ç—å –≤–∞—Ä–∏–∞–Ω—Ç—ã, —Å–æ–∑–¥–∞–µ–º OR –≤—ã—Ä–∞–∂–µ–Ω–∏–µ
                variants_list = " OR ".join(f'"{v}"' for v in sorted(variants))
                expanded_tokens.append(f"({variants_list})")
            else:
                # –ï—Å–ª–∏ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ
                expanded_tokens.append(f'"{token}"')
        
        if not expanded_tokens:
            return ""
        
        if len(expanded_tokens) == 1:
            return expanded_tokens[0]
        
        # –ì–∏–±–∫–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        if len(expanded_tokens) > 3:
            # –î–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: –ø–µ—Ä–≤—ã–µ 2-3 —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ AND, –æ—Å—Ç–∞–ª—å–Ω—ã–µ —á–µ—Ä–µ–∑ OR
            # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –Ω–∞—Ö–æ–¥–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–ª–æ–≤–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç
            and_tokens = expanded_tokens[:2]  # –ü–µ—Ä–≤—ã–µ 2 —Å–ª–æ–≤–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã
            or_tokens = expanded_tokens[2:]   # –û—Å—Ç–∞–ª—å–Ω—ã–µ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã
            
            and_expr = " AND ".join(and_tokens)
            or_expr = " OR ".join(or_tokens)
            
            # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º: (AND —á–∞—Å—Ç—å) AND (OR —á–∞—Å—Ç—å)
            return f"({and_expr}) AND ({or_expr})"
        else:
            # –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (<=3 —Å–ª–æ–≤–∞) –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–æ–≥—É—é AND –ª–æ–≥–∏–∫—É
            return " AND ".join(expanded_tokens)

    def _get_node_attrs(self, node_id: str) -> Dict[str, Any]:
        if node_id in self.graph:
            return self.graph.nodes[node_id]
        cursor = self.conn.cursor()
        cursor.execute(
            "SELECT properties FROM nodes WHERE id = ?",
            (node_id,),
        )
        row = cursor.fetchone()
        if not row:
            return {}
        props = json.loads(row["properties"]) if row["properties"] else {}
        return {"properties": props, **props}

    def search_text(
        self,
        query: str,
        *,
        limit: int = 5,
        source: Optional[str] = None,
        tags: Optional[List[str]] = None,
        date_from: Optional[datetime] = None,
        date_to: Optional[datetime] = None,
    ) -> Tuple[List[Dict[str, Any]], int]:
        """Search doc chunks using FTS with optional filters."""

        if not query.strip():
            return [], 0

        match_expr = self._prepare_match_expression(query)
        if not match_expr:
            return [], 0

        cursor = self.conn.cursor()
        fetch_limit = max(limit * 5, 50)
        rows = cursor.execute(
            """
            SELECT node_id,
                   content,
                   snippet(node_search, 1, '<b>', '</b>', ' ‚Ä¶ ', 15) AS snippet,
                   bm25(node_search) AS score,
                   source,
                   tags,
                   entities
            FROM node_search
            WHERE node_search MATCH ?
            ORDER BY score
            LIMIT ?
        """,
            (match_expr, fetch_limit),
        ).fetchall()

        results: List[Dict[str, Any]] = []
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ BM25 scores –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        bm25_scores = []
        for row in rows:
            bm25_score = row["score"] if row["score"] is not None else 0.0
            bm25_scores.append(bm25_score)
        
        # –í—ã—á–∏—Å–ª—è–µ–º min/max –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        if bm25_scores:
            min_bm25 = min(bm25_scores)
            max_bm25 = max(bm25_scores)
            bm25_range = max_bm25 - min_bm25 if max_bm25 != min_bm25 else 1.0
        else:
            min_bm25 = 0.0
            max_bm25 = 0.0
            bm25_range = 1.0
        
        result_count = 0  # –°—á–µ—Ç—á–∏–∫ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏)
        for idx, row in enumerate(rows):
            node_id = row["node_id"]
            attrs = self._get_node_attrs(node_id)
            props = attrs.get("properties") if isinstance(attrs.get("properties"), dict) else {}
            node_source = (
                row["source"]
                or props.get("source")
                or attrs.get("source")
                or props.get("chat")
                or attrs.get("chat")
            )
            if source and node_source != source:
                continue

            node_tags = set(props.get("tags", attrs.get("tags", [])))
            if tags and not set(tags).issubset(node_tags):
                continue

            timestamp_raw = (
                props.get("timestamp")
                or attrs.get("timestamp")
                or props.get("created_at")
                or attrs.get("created_at")
            )
            timestamp_dt = None
            if timestamp_raw:
                try:
                    if isinstance(timestamp_raw, (int, float)):
                        timestamp_dt = datetime.fromtimestamp(float(timestamp_raw), tz=timezone.utc)
                    else:
                        ts = str(timestamp_raw)
                        from ..utils.datetime_utils import parse_datetime_utc

                        timestamp_dt = parse_datetime_utc(ts, return_none_on_error=True, use_zoneinfo=True)
                except Exception:
                    timestamp_dt = None

            if date_from and timestamp_dt and timestamp_dt < date_from:
                continue
            if date_to and timestamp_dt and timestamp_dt > date_to:
                continue

            # BM25 score –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º: –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–ª—É—á—à–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å) -> –≤—ã—à–µ score
            # BM25 –æ–±—ã—á–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, –≥–¥–µ –±–æ–ª–µ–µ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ = –ª—É—á—à–µ
            bm25_score = row["score"] if row["score"] is not None else 0.0
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º BM25 —Å —É—á–µ—Ç–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–∞ scores –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞–∑–ª–∏—á–µ–Ω–∏—è
            if bm25_range > 0.001:
                # –ï—Å—Ç—å —Ä–∞–∑–ª–∏—á–∏—è –≤ scores - –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É
                if bm25_score < 0:
                    # –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: –±–æ–ª–µ–µ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ = –ª—É—á—à–µ
                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ [0.5, 1.0] —Å —É—á–µ—Ç–æ–º –ø–æ–∑–∏—Ü–∏–∏ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ
                    normalized = (bm25_score - min_bm25) / bm25_range
                    score = 0.5 + (1.0 - normalized) * 0.5  # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º, —Ç–∞–∫ –∫–∞–∫ –º–µ–Ω—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ª—É—á—à–µ
                else:
                    # –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (—Ä–µ–¥–∫–æ)
                    normalized = (bm25_score - min_bm25) / bm25_range
                    score = 0.5 + normalized * 0.5
            else:
                # –í—Å–µ scores –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–∑–∏—Ü–∏—é –¥–ª—è —Ä–∞–∑–ª–∏—á–µ–Ω–∏—è
                # FTS5 —É–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –ø–µ—Ä–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω–¥–µ–∫—Å –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Å–ø–∏—Å–∫–µ –¥–ª—è —Ä–∞–∑–ª–∏—á–µ–Ω–∏—è
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–Ω–¥–µ–∫—Å –∫ [0, 1] –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ä–∞–∑–ª–∏—á–∏–π –≤ scores
                if len(rows) > 1:
                    position_factor = 1.0 - (idx / (len(rows) - 1))  # –û—Ç 1.0 (–ø–µ—Ä–≤—ã–π) –¥–æ 0.0 (–ø–æ—Å–ª–µ–¥–Ω–∏–π)
                else:
                    position_factor = 1.0  # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                score = 0.5 + position_factor * 0.2  # Score –æ—Ç 0.7 (–ø–µ—Ä–≤—ã–π) –¥–æ 0.5 (–ø–æ—Å–ª–µ–¥–Ω–∏–π)

            snippet = row["snippet"] or ""
            content = row["content"] or props.get("content") or attrs.get("content") or ""

            results.append(
                {
                    "node_id": node_id,
                    "score": score,
                    "snippet": snippet if snippet.strip() else content[:200],
                    "content": content,
                    "source": node_source or "unknown",
                    "timestamp": timestamp_dt or datetime.now(timezone.utc),
                    "author": props.get("author") or attrs.get("author"),
                    "metadata": dict(props) if props else dict(attrs),
                }
            )
            result_count += 1  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

        total = len(results)
        results.sort(key=lambda item: item["score"], reverse=True)
        return results[:limit], total

    def get_node(self, node_id: str) -> Optional[GraphNode]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —É–∑–ª–∞ –ø–æ ID

        Args:
            node_id: ID —É–∑–ª–∞

        Returns:
            –£–∑–µ–ª –∏–ª–∏ None
        """
        if node_id not in self.graph:
            return None

        cursor = self.conn.cursor()
        cursor.execute(
            "SELECT id, type, label, properties, created_at, updated_at FROM nodes WHERE id = ?",
            (node_id,),
        )

        row = cursor.fetchone()
        if not row:
            return None

        props = json.loads(row["properties"]) if row["properties"] else {}

        return GraphNode(
            id=row["id"],
            type=NodeType(row["type"]),
            label=row["label"],
            properties=props,
            created_at=row["created_at"],
            updated_at=row["updated_at"],
        )

    def get_nodes_by_type(
        self, node_type: NodeType, limit: int = 100
    ) -> List[GraphNode]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —É–∑–ª–æ–≤ –ø–æ —Ç–∏–ø—É

        Args:
            node_type: –¢–∏–ø —É–∑–ª–æ–≤
            limit: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ —É–∑–ª–æ–≤
        """
        cursor = self.conn.cursor()
        cursor.execute(
            """
            SELECT id, type, label, properties, created_at, updated_at
            FROM nodes
            WHERE type = ?
            LIMIT ?
        """,
            (node_type.value, limit),
        )

        nodes = []
        for row in cursor.fetchall():
            props = json.loads(row["properties"]) if row["properties"] else {}
            nodes.append(
                GraphNode(
                    id=row["id"],
                    type=NodeType(row["type"]),
                    label=row["label"],
                    properties=props,
                    created_at=row["created_at"],
                    updated_at=row["updated_at"],
                )
            )

        return nodes

    def get_neighbors(
        self,
        node_id: str,
        edge_type: Optional[EdgeType] = None,
        direction: str = "out",
    ) -> List[Tuple[str, Dict[str, Any]]]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ—Å–µ–¥–Ω–∏—Ö —É–∑–ª–æ–≤

        Args:
            node_id: ID —É–∑–ª–∞
            edge_type: –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É —Ä—ë–±–µ—Ä
            direction: –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ ("out", "in", "both")

        Returns:
            –°–ø–∏—Å–æ–∫ (neighbor_id, edge_data)
        """
        if node_id not in self.graph:
            return []

        neighbors = []

        if direction in ("out", "both"):
            for neighbor in self.graph.successors(node_id):
                edge_data = self.graph[node_id][neighbor]
                if edge_type is None or edge_data.get("edge_type") == edge_type.value:
                    neighbors.append((neighbor, edge_data))

        if direction in ("in", "both"):
            for neighbor in self.graph.predecessors(node_id):
                edge_data = self.graph[neighbor][node_id]
                if edge_type is None or edge_data.get("edge_type") == edge_type.value:
                    neighbors.append((neighbor, edge_data))

        return neighbors

    def find_path(
        self,
        source_id: str,
        target_id: str,
        max_length: int = 5,
    ) -> Optional[GraphPath]:
        """
        –ü–æ–∏—Å–∫ –∫—Ä–∞—Ç—á–∞–π—à–µ–≥–æ –ø—É—Ç–∏ –º–µ–∂–¥—É —É–∑–ª–∞–º–∏

        Args:
            source_id: ID –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —É–∑–ª–∞
            target_id: ID —Ü–µ–ª–µ–≤–æ–≥–æ —É–∑–ª–∞
            max_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø—É—Ç–∏

        Returns:
            –ü—É—Ç—å –∏–ª–∏ None
        """
        if source_id not in self.graph or target_id not in self.graph:
            return None

        try:
            path_nodes = nx.shortest_path(
                self.graph, source=source_id, target=target_id, weight="weight"
            )

            if len(path_nodes) > max_length + 1:
                return None

            # –°–æ–±–∏—Ä–∞–µ–º —É–∑–ª—ã –∏ —Ä—ë–±—Ä–∞
            nodes = [self.get_node(nid) for nid in path_nodes]
            nodes = [n for n in nodes if n is not None]

            edges = []
            total_weight = 0.0

            for i in range(len(path_nodes) - 1):
                src = path_nodes[i]
                tgt = path_nodes[i + 1]
                edge_data = self.graph[src][tgt]

                edges.append(
                    GraphEdge(
                        id=f"{src}-{tgt}",
                        source_id=src,
                        target_id=tgt,
                        type=EdgeType(edge_data.get("edge_type", "relates_to")),
                        weight=edge_data.get("weight", 1.0),
                        properties=edge_data,
                    )
                )

                total_weight += edge_data.get("weight", 1.0)

            return GraphPath(
                nodes=nodes,
                edges=edges,
                length=len(path_nodes) - 1,
                total_weight=total_weight,
            )

        except nx.NetworkXNoPath:
            return None
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø—É—Ç–∏: {e}")
            return None

    def get_stats(self) -> GraphStats:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≥—Ä–∞—Ñ–∞

        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        """
        node_types_count = {}
        for node_id in self.graph.nodes():
            node_type = self.graph.nodes[node_id].get("type", "unknown")
            node_types_count[node_type] = node_types_count.get(node_type, 0) + 1

        edge_types_count = {}
        for _, _, edge_data in self.graph.edges(data=True):
            edge_type = edge_data.get("edge_type", "unknown")
            edge_types_count[edge_type] = edge_types_count.get(edge_type, 0) + 1

        # –°—Ä–µ–¥–Ω—è—è —Å—Ç–µ–ø–µ–Ω—å —É–∑–ª–∞
        total_degree = sum(dict(self.graph.degree()).values())
        avg_degree = (
            total_degree / self.graph.number_of_nodes()
            if self.graph.number_of_nodes() > 0
            else 0
        )

        # –ü–ª–æ—Ç–Ω–æ—Å—Ç—å
        n = self.graph.number_of_nodes()
        max_edges = n * (n - 1) if n > 1 else 1
        density = self.graph.number_of_edges() / max_edges if max_edges > 0 else 0

        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–≤—è–∑–Ω–æ—Å—Ç–∏
        connected_components = nx.number_weakly_connected_components(self.graph)

        return GraphStats(
            node_count=self.graph.number_of_nodes(),
            edge_count=self.graph.number_of_edges(),
            node_types_count=node_types_count,
            edge_types_count=edge_types_count,
            avg_node_degree=avg_degree,
            density=density,
            connected_components=connected_components,
        )

    def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î"""
        self.conn.close()
        logger.info("–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î –∑–∞–∫—Ä—ã—Ç–æ")

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()
