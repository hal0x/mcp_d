#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å –¥–ª—è –¥–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
L1 - sessions (—Å–∞–º–º–∞—Ä–∏ + E1)
L2 - messages (—Ç–µ–∫—Å—Ç + —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç)
"""

import asyncio
import logging
from collections import Counter
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional
from zoneinfo import ZoneInfo

import chromadb

from ..analysis.cluster_summarizer import ClusterSummarizer
from ..analysis.day_grouping import DayGroupingSegmenter
from ..analysis.entity_extraction import EntityExtractor
from ..analysis.entity_dictionary import get_entity_dictionary
from ..analysis.instruction_manager import InstructionManager
from ..analysis.markdown_renderer import MarkdownRenderer
from ..analysis.session_clustering import SessionClusterer
from ..analysis.session_segmentation import SessionSegmenter
from ..analysis.session_summarizer import SessionSummarizer
from ..analysis.smart_rolling_aggregator import SmartRollingAggregator
from ..analysis.time_processor import TimeProcessor
from ..utils.naming import slugify
from ..utils.url_validator import validate_embedding_text
from .lmstudio_client import LMStudioEmbeddingClient

logger = logging.getLogger(__name__)

MIN_SESSION_MESSAGES = (
    15  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 30 –¥–æ 15 –¥–ª—è –±–æ–ª–µ–µ –≥–∏–±–∫–æ–≥–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –º–∞–ª–µ–Ω—å–∫–∏—Ö —Å–µ—Å—Å–∏–π
)


class TwoLevelIndexer:
    """–ö–ª–∞—Å—Å –¥–ª—è –¥–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ (L1: sessions, L2: messages)"""

    def __init__(
        self,
        chroma_path: str = "./artifacts/chroma_db",
        artifacts_path: str = "./artifacts",
        embedding_client: Optional[LMStudioEmbeddingClient] = None,
        enable_quality_check: bool = True,
        enable_iterative_refinement: bool = True,
        min_quality_score: float = 80.0,
        enable_clustering: bool = True,
        clustering_threshold: float = 0.8,
        min_cluster_size: int = 2,
        max_messages_per_group: int = 100,
        max_session_hours: int = 6,
        gap_minutes: int = 60,
        enable_smart_aggregation: bool = False,
        aggregation_strategy: str = "smart",
        now_window_hours: int = 24,
        fresh_window_days: int = 14,
        recent_window_days: int = 30,
        strategy_threshold: int = 1000,
        force: bool = False,
        enable_entity_learning: bool = True,
        enable_time_analysis: bool = True,
        graph: Optional[Any] = None,  # TypedGraphMemory
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞

        Args:
            chroma_path: –ü—É—Ç—å –∫ ChromaDB
            artifacts_path: –ö–∞—Ç–∞–ª–æ–≥ —Å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º–∏ (reports, –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã, –∫–æ–ª–ª–µ–∫—Ü–∏–∏)
            embedding_client: –ö–ª–∏–µ–Ω—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (LM Studio)
            enable_quality_check: –í–∫–ª—é—á–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
            enable_iterative_refinement: –í–∫–ª—é—á–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ
            min_quality_score: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–∏–µ–º–ª–µ–º—ã–π –±–∞–ª–ª –∫–∞—á–µ—Å—Ç–≤–∞
            enable_clustering: –í–∫–ª—é—á–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é —Å–µ—Å—Å–∏–π
            clustering_threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
            min_cluster_size: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞
            max_messages_per_group: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –≥—Ä—É–ø–ø–µ
            max_session_hours: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ—Å—Å–∏–∏ –≤ —á–∞—Å–∞—Ö
            gap_minutes: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑—Ä—ã–≤ –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ –≤ –º–∏–Ω—É—Ç–∞—Ö
            enable_smart_aggregation: –í–∫–ª—é—á–∏—Ç—å —É–º–Ω—É—é –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É —Å —Å–∫–æ–ª—å–∑—è—â–∏–º–∏ –æ–∫–Ω–∞–º–∏
            aggregation_strategy: –°—Ç—Ä–∞—Ç–µ–≥–∏—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ (smart/channel/legacy)
            now_window_hours: –†–∞–∑–º–µ—Ä NOW –æ–∫–Ω–∞ –≤ —á–∞—Å–∞—Ö
            fresh_window_days: –†–∞–∑–º–µ—Ä FRESH –æ–∫–Ω–∞ –≤ –¥–Ω—è—Ö
            recent_window_days: –†–∞–∑–º–µ—Ä RECENT –æ–∫–Ω–∞ –≤ –¥–Ω—è—Ö
            strategy_threshold: –ü–æ—Ä–æ–≥ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏
            force: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
            enable_entity_learning: –í–∫–ª—é—á–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä–µ–π —Å—É—â–Ω–æ—Å—Ç–µ–π
            enable_time_analysis: –í–∫–ª—é—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            graph: –ì—Ä–∞—Ñ –ø–∞–º—è—Ç–∏ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∑–∞–ø–∏—Å–µ–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        self.chroma_client = chromadb.PersistentClient(path=chroma_path)
        self.artifacts_path = Path(artifacts_path).expanduser()
        self.artifacts_path.mkdir(parents=True, exist_ok=True)
        self.reports_path = self.artifacts_path / "reports"
        self.reports_path.mkdir(parents=True, exist_ok=True)
        self.embedding_client = embedding_client or LMStudioEmbeddingClient()

        # –§–ª–∞–≥–∏ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
        self.enable_clustering = enable_clustering
        self.clustering_threshold = clustering_threshold
        self.min_cluster_size = min_cluster_size

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
        self.max_messages_per_group = max_messages_per_group
        self.max_session_hours = max_session_hours
        self.gap_minutes = gap_minutes

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —É–º–Ω–æ–π –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
        self.enable_smart_aggregation = enable_smart_aggregation
        self.aggregation_strategy = aggregation_strategy
        self.now_window_hours = now_window_hours
        self.fresh_window_days = fresh_window_days
        self.recent_window_days = recent_window_days
        self.strategy_threshold = strategy_threshold
        self.force = force

        # –ù–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        self.enable_entity_learning = enable_entity_learning
        self.enable_time_analysis = enable_time_analysis

        self.session_segmenter = SessionSegmenter(
            gap_minutes=gap_minutes,
            max_session_hours=max_session_hours,
            enable_time_analysis=enable_time_analysis,
        )
        self.day_grouping_segmenter = DayGroupingSegmenter(
            max_messages_per_group=max_messages_per_group,
        )

        # –°–æ–∑–¥–∞—ë–º –º–µ–Ω–µ–¥–∂–µ—Ä –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∏ SessionSummarizer —Å —Å–∏—Å—Ç–µ–º–æ–π –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        self.instruction_manager = InstructionManager()
        self.session_summarizer = SessionSummarizer(
            self.embedding_client,
            self.reports_path,
            instruction_manager=self.instruction_manager,
            enable_quality_check=enable_quality_check,
            enable_iterative_refinement=enable_iterative_refinement,
            min_quality_score=min_quality_score,
        )

        self.entity_extractor = EntityExtractor(
            enable_learning=enable_entity_learning,
            enable_natasha=True,
        )
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è TimeProcessor –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        self.time_processor = TimeProcessor() if enable_time_analysis else None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤–∞—Ä—è —Å—É—â–Ω–æ—Å—Ç–µ–π –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
        self.entity_dictionary = get_entity_dictionary() if enable_entity_learning else None
        
        self.markdown_renderer = MarkdownRenderer(self.reports_path)

        # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è (–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –ø–æ—Å–ª–µ –∫–æ–ª–ª–µ–∫—Ü–∏–π)
        self.session_clusterer = None
        self.cluster_summarizer = None

        # –ö–æ–ª–ª–µ–∫—Ü–∏–∏
        self.sessions_collection = None
        self.messages_collection = None
        self.tasks_collection = None
        self.clusters_collection = None
        self.progress_collection = None  # –ù–æ–≤–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

        self._initialize_collections()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é –ø–æ—Å–ª–µ –∫–æ–ª–ª–µ–∫—Ü–∏–π
        if self.enable_clustering:
            self.session_clusterer = SessionClusterer(
                similarity_threshold=self.clustering_threshold,
                min_cluster_size=self.min_cluster_size,
                use_hdbscan=False,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º threshold-based –¥–ª—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º–∞
            )
            self.cluster_summarizer = ClusterSummarizer(
                embedding_client=self.embedding_client
            )

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —É–º–Ω—ã–π –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä
        if self.enable_smart_aggregation:
            self.smart_aggregator = SmartRollingAggregator(
                chats_dir=Path("chats"),
                use_smart_strategy=(self.aggregation_strategy == "smart"),
            )
        else:
            self.smart_aggregator = None

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        self.graph = graph
        if self.graph:
            from ..memory.ingest import MemoryIngestor
            self.ingestor = MemoryIngestor(self.graph)
            logger.info("TwoLevelIndexer: –≥—Ä–∞—Ñ –ø–∞–º—è—Ç–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω, –∑–∞–ø–∏—Å–∏ –±—É–¥—É—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è")
        else:
            self.ingestor = None
            logger.debug("TwoLevelIndexer: –≥—Ä–∞—Ñ –ø–∞–º—è—Ç–∏ –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω, –∑–∞–ø–∏—Å–∏ –±—É–¥—É—Ç —Ç–æ–ª—å–∫–æ –≤ ChromaDB")

    def _get_embedding_dimension(self) -> Optional[int]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ –∫–ª–∏–µ–Ω—Ç–∞."""
        if not self.embedding_client:
            return None
        
        # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏–∑ –∫–ª–∏–µ–Ω—Ç–∞
        if hasattr(self.embedding_client, '_embedding_dimension') and self.embedding_client._embedding_dimension:
            return self.embedding_client._embedding_dimension
        
        # –ï—Å–ª–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –µ—â—ë –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞, –¥–µ–ª–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        try:
            import asyncio
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # –ï—Å–ª–∏ —Ü–∏–∫–ª —É–∂–µ –∑–∞–ø—É—â–µ–Ω, —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π
                import nest_asyncio
                try:
                    nest_asyncio.apply()
                except ImportError:
                    pass
            
            async def _get_dim():
                async with self.embedding_client:
                    test_embedding = await self.embedding_client.get_embedding("test")
                    return len(test_embedding) if test_embedding else None
            
            try:
                dimension = asyncio.run(_get_dim())
                if dimension:
                    self.embedding_client._embedding_dimension = dimension
                return dimension
            except RuntimeError:
                # –ï—Å–ª–∏ —Ü–∏–∫–ª —É–∂–µ –∑–∞–ø—É—â–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None - —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—Å—è –ø–æ–∑–∂–µ
                return None
        except Exception as e:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}")
            return None

    def _check_and_recreate_collection(self, collection_name: str, description: str, force_recreate: bool = False):
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é –∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –ø—Ä–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏."""
        expected_dimension = self._get_embedding_dimension()
        
        try:
            collection = self.chroma_client.get_collection(collection_name)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            if expected_dimension:
                try:
                    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
                    collection_info = collection.get()
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø–æ –ø–µ—Ä–≤–æ–º—É —ç–º–±–µ–¥–¥–∏–Ω–≥—É, –µ—Å–ª–∏ –µ—Å—Ç—å
                    if collection_info.get("embeddings") and len(collection_info["embeddings"]) > 0:
                        existing_dimension = len(collection_info["embeddings"][0])
                        if existing_dimension != expected_dimension:
                            logger.warning(
                                f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} –∏–º–µ–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å {existing_dimension}, "
                                f"–æ–∂–∏–¥–∞–µ—Ç—Å—è {expected_dimension}. –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º –∫–æ–ª–ª–µ–∫—Ü–∏—é..."
                            )
                            self.chroma_client.delete_collection(collection_name)
                            collection = None
                        else:
                            logger.info(
                                f"–ù–∞–π–¥–µ–Ω–∞ –∫–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} —Å {collection.count()} –∑–∞–ø–∏—Å—è–º–∏ "
                                f"(—Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {existing_dimension})"
                            )
                    else:
                        # –ï—Å–ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏—è –ø—É—Å—Ç–∞—è, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                        logger.info(
                            f"–ù–∞–π–¥–µ–Ω–∞ –ø—É—Å—Ç–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è {collection_name}"
                        )
                except Exception as e:
                    logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏–∏ {collection_name}: {e}")
                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –∫–∞–∫ –µ—Å—Ç—å
                    logger.info(
                        f"–ù–∞–π–¥–µ–Ω–∞ –∫–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} —Å {collection.count()} –∑–∞–ø–∏—Å—è–º–∏"
                    )
            else:
                logger.info(
                    f"–ù–∞–π–¥–µ–Ω–∞ –∫–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} —Å {collection.count()} –∑–∞–ø–∏—Å—è–º–∏"
                )
            
            if collection is None or force_recreate:
                # –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
                if collection:
                    self.chroma_client.delete_collection(collection_name)
                collection = self.chroma_client.create_collection(
                    name=collection_name,
                    metadata={"description": description},
                )
                logger.info(f"–°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è {collection_name}")
            
            return collection
            
        except Exception:
            # –ö–æ–ª–ª–µ–∫—Ü–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é
            collection = self.chroma_client.create_collection(
                name=collection_name,
                metadata={"description": description},
            )
            logger.info(f"–°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è {collection_name}")
            return collection

    def _initialize_collections(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–π ChromaDB —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        try:
            # L1: Sessions
            self.sessions_collection = self._check_and_recreate_collection(
                "chat_sessions",
                "–°–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å–µ—Å—Å–∏–π –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (L1)",
                force_recreate=self.force
            )

            # L2: Messages
            self.messages_collection = self._check_and_recreate_collection(
                "chat_messages",
                "–°–æ–æ–±—â–µ–Ω–∏—è —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–ª—è —É—Ç–æ—á–Ω—è—é—â–µ–≥–æ –ø–æ–∏—Å–∫–∞ (L2)",
                force_recreate=self.force
            )

            # Tasks
            self.tasks_collection = self._check_and_recreate_collection(
                "chat_tasks",
                "Action Items –∏–∑ —Å–µ—Å—Å–∏–π",
                force_recreate=self.force
            )

            # Clusters
            self.clusters_collection = self._check_and_recreate_collection(
                "session_clusters",
                "–¢–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∫–ª–∞—Å—Ç–µ—Ä—ã —Å–µ—Å—Å–∏–π",
                force_recreate=self.force
            )

            # Progress tracking (–Ω–µ —Ç—Ä–µ–±—É–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤, –ø–æ—ç—Ç–æ–º—É –±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏)
            try:
                self.progress_collection = self.chroma_client.get_collection(
                    "indexing_progress"
                )
                logger.info(
                    f"–ù–∞–π–¥–µ–Ω–∞ –∫–æ–ª–ª–µ–∫—Ü–∏—è indexing_progress —Å {self.progress_collection.count()} –∑–∞–ø–∏—Å—è–º–∏"
                )
            except Exception:
                self.progress_collection = self.chroma_client.create_collection(
                    name="indexing_progress",
                    metadata={
                        "description": "–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–ª—è –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π"
                    },
                )
                logger.info("–°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è indexing_progress")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–π: {e}")
            raise

    def _expand_day_groups(
        self, day_groups: List[Dict[str, Any]], chat_name: Optional[str]
    ) -> List[Dict[str, Any]]:
        """–†–∞—Å—à–∏—Ä—è–µ—Ç –¥–Ω–µ–≤–Ω—ã–µ –≥—Ä—É–ø–ø—ã –≤ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ —Å —É—á—ë—Ç–æ–º —Ä–∞–∑—Ä—ã–≤–æ–≤."""

        if not day_groups:
            return []

        sessions: List[Dict[str, Any]] = []
        chat_slug = slugify(chat_name) if chat_name else ""

        for day_index, day_group in enumerate(day_groups):
            base_id = day_group.get("session_id")
            if not base_id:
                base_id = (
                    f"{chat_slug}-D{day_index + 1:04d}"
                    if chat_slug
                    else f"D{day_index + 1:04d}"
                )

            raw_messages = day_group.get("messages", [])
            splitted = self.session_segmenter.segment_messages(raw_messages, chat_name)
            merged_segments = (
                self._merge_small_sessions(
                    splitted,
                    chat_name=chat_name,
                    min_messages=MIN_SESSION_MESSAGES,
                )
                if splitted
                else []
            )

            segments_to_use = merged_segments or splitted

            if not segments_to_use:
                session = day_group.copy()
                session["session_id"] = base_id
                session["day_group_id"] = base_id
                session["parent_session_id"] = base_id
                session["group_type"] = day_group.get("group_type", "day_grouped")
                session["chat"] = chat_name
                if chat_slug:
                    session["chat_id"] = chat_slug
                session["messages"] = session.get("messages", raw_messages)
                session["message_count"] = len(session.get("messages", []))
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
                if self.time_processor and self.enable_time_analysis:
                    try:
                        activity_patterns = self.time_processor.analyze_activity_patterns(session.get("messages", []))
                        session["activity_patterns"] = activity_patterns
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è —Å–µ—Å—Å–∏–∏ {base_id}: {e}")
                
                sessions.append(session)
                continue

            if len(segments_to_use) == 1:
                session_data = segments_to_use[0].copy()
                session_data["session_id"] = base_id
                session_data["day_group_id"] = base_id
                session_data["parent_session_id"] = base_id
                session_data["group_type"] = session_data.get("group_type") or (
                    "session_segmented"
                    if splitted
                    else day_group.get("group_type", "day_grouped")
                )
                session_data["chat"] = chat_name
                if chat_slug:
                    session_data["chat_id"] = chat_slug
                session_data["messages"] = session_data.get("messages", raw_messages)
                session_data["message_count"] = len(session_data["messages"])
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
                if self.time_processor and self.enable_time_analysis:
                    try:
                        activity_patterns = self.time_processor.analyze_activity_patterns(session_data.get("messages", []))
                        session_data["activity_patterns"] = activity_patterns
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è —Å–µ—Å—Å–∏–∏ {base_id}: {e}")
                
                sessions.append(session_data)
                continue

            for split_index, split_session in enumerate(segments_to_use):
                session_copy = split_session.copy()
                session_copy["session_id"] = f"{base_id}-S{split_index + 1:02d}"
                session_copy["day_group_id"] = base_id
                session_copy["parent_session_id"] = base_id
                session_copy["group_type"] = session_copy.get(
                    "group_type", "session_segmented"
                )
                session_copy["chat"] = chat_name
                if chat_slug:
                    session_copy["chat_id"] = chat_slug
                session_copy["messages"] = split_session.get("messages", raw_messages)
                session_copy["message_count"] = len(session_copy["messages"])
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
                if self.time_processor and self.enable_time_analysis:
                    try:
                        activity_patterns = self.time_processor.analyze_activity_patterns(session_copy.get("messages", []))
                        session_copy["activity_patterns"] = activity_patterns
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è —Å–µ—Å—Å–∏–∏ {session_copy['session_id']}: {e}")
                
                sessions.append(session_copy)

        return sessions

    def _merge_small_sessions(
        self,
        segments: List[Dict[str, Any]],
        chat_name: Optional[str],
        min_messages: int,
    ) -> List[Dict[str, Any]]:
        if not segments:
            return []

        grouped: List[List[Dict[str, Any]]] = []
        buffer: List[Dict[str, Any]] = []

        def segment_len(segment: Dict[str, Any]) -> int:
            return segment.get("message_count") or len(segment.get("messages", []))

        for segment in segments:
            count = segment_len(segment)
            if not buffer:
                buffer.append(segment)
                continue

            buffer_count = sum(segment_len(item) for item in buffer)

            # –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –º–∞–ª–µ–Ω—å–∫–∏—Ö —Å–µ—Å—Å–∏–π
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –µ—Å–ª–∏:
            # 1. –¢–µ–∫—É—â–∞—è —Å–µ—Å—Å–∏—è –º–µ–Ω—å—à–µ min_messages –ò–õ–ò
            # 2. –ë—É—Ñ–µ—Ä –º–µ–Ω—å—à–µ min_messages –ò–õ–ò
            # 3. –¢–µ–∫—É—â–∞—è —Å–µ—Å—Å–∏—è –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∞—è (‚â§3 —Å–æ–æ–±—â–µ–Ω–∏—è) –ò –±—É—Ñ–µ—Ä —Ç–æ–∂–µ –º–∞–ª–µ–Ω—å–∫–∏–π (‚â§10 —Å–æ–æ–±—â–µ–Ω–∏–π)
            should_merge = (
                count < min_messages
                or buffer_count < min_messages
                or (count <= 3 and buffer_count <= 10)
            )

            if should_merge:
                buffer.append(segment)
            else:
                grouped.append(buffer)
                buffer = [segment]

        if buffer:
            grouped.append(buffer)

        normalized: List[Dict[str, Any]] = []
        for group in grouped:
            total_messages = sum(segment_len(item) for item in group)

            if len(group) == 1 and total_messages >= min_messages:
                segment_copy = group[0].copy()
                segment_copy["group_type"] = segment_copy.get(
                    "group_type", "session_segmented"
                )
                normalized.append(segment_copy)
                continue

            # –õ–æ–≥–∏—Ä—É–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–µ—Å—Å–∏–π
            if len(group) > 1:
                segment_sizes = [segment_len(item) for item in group]
                logger.info(
                    f"üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ {len(group)} –º–∞–ª–µ–Ω—å–∫–∏—Ö —Å–µ—Å—Å–∏–π "
                    f"(—Ä–∞–∑–º–µ—Ä—ã: {segment_sizes}) –≤ –æ–¥–Ω—É —Å–µ—Å—Å–∏—é —Å {total_messages} —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏"
                )

            combined_messages: List[Dict[str, Any]] = []
            for segment in group:
                combined_messages.extend(segment.get("messages", []))

            combined_messages.sort(
                key=lambda msg: self.session_segmenter._parse_message_time(msg)
            )

            raw_session = {
                "messages": combined_messages,
                "start_time": self.session_segmenter._parse_message_time(
                    combined_messages[0]
                ),
                "end_time": self.session_segmenter._parse_message_time(
                    combined_messages[-1]
                ),
                "chat": chat_name,
            }
            merged_session = self.session_segmenter._finalize_session(
                raw_session,
                len(normalized),
            )
            merged_session["group_type"] = "session_merged"
            normalized.append(merged_session)

        return normalized

    def _get_last_indexed_date(self, chat_name: str) -> Optional[datetime]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è —á–∞—Ç–∞

        Args:
            chat_name: –ù–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞

        Returns:
            –î–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–ª–∏ None
        """
        try:
            result = self.progress_collection.get(
                ids=[f"progress_{slugify(chat_name)}"], include=["metadatas"]
            )

            if result["ids"] and result["metadatas"]:
                last_date_str = result["metadatas"][0].get("last_indexed_date")
                if last_date_str:
                    from ..utils.datetime_utils import parse_datetime_utc

                    return parse_datetime_utc(last_date_str, use_zoneinfo=True)
        except Exception as e:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –¥–ª—è {chat_name}: {e}")

        return None

    def _save_indexing_progress(
        self,
        chat_name: str,
        last_message_date: datetime,
        messages_count: int,
        sessions_count: int,
    ):
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–ª—è —á–∞—Ç–∞

        Args:
            chat_name: –ù–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞
            last_message_date: –î–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
            messages_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
            sessions_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π
        """
        try:
            progress_id = f"progress_{slugify(chat_name)}"
            now = datetime.now(ZoneInfo("UTC"))

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—ã –≤ ISO —Ñ–æ—Ä–º–∞—Ç
            last_date_iso = last_message_date.isoformat()
            now_iso = now.isoformat()

            metadata = {
                "chat_name": chat_name,
                "last_indexed_date": last_date_iso,
                "last_indexing_time": now_iso,
                "total_messages": messages_count,
                "total_sessions": sessions_count,
            }

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Å—Ç–æ–π —ç–º–±–µ–¥–¥–∏–Ω–≥ (–Ω–µ –Ω—É–∂–µ–Ω –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö)
            dummy_embedding = [0.0] * 1024  # BGE-M3 —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å

            self.progress_collection.upsert(
                ids=[progress_id],
                documents=[f"Progress for {chat_name}"],
                embeddings=[dummy_embedding],
                metadatas=[metadata],
            )

            logger.info(
                f"–°–æ—Ö—Ä–∞–Ω—ë–Ω –ø—Ä–æ–≥—Ä–µ—Å—Å –¥–ª—è {chat_name}: "
                f"–ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ {last_date_iso}, "
                f"–≤—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π {messages_count}, —Å–µ—Å—Å–∏–π {sessions_count}"
            )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –¥–ª—è {chat_name}: {e}")

    def _parse_session_start_time(self, session: Dict[str, Any]) -> datetime:
        """
        –ü–∞—Ä—Å–∏—Ç –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ —Å–µ—Å—Å–∏–∏ –¥–ª—è —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—â—É—é —É—Ç–∏–ª–∏—Ç—É).

        Args:
            session: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ —Å–µ—Å—Å–∏–∏

        Returns:
            datetime: –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ —Å–µ—Å—Å–∏–∏ –∏–ª–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
        """
        from ..utils.datetime_utils import parse_datetime_utc

        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞—á–∞–ª–∞
        start_time = session.get("start_time")
        if start_time:
            if isinstance(start_time, str):
                result = parse_datetime_utc(start_time, use_zoneinfo=True)
                if result:
                    return result
            elif isinstance(start_time, datetime):
                return start_time

        # –ï—Å–ª–∏ –Ω–µ—Ç start_time, –±–µ—Ä–µ–º –≤—Ä–µ–º—è –ø–µ—Ä–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        messages = session.get("messages", [])
        if messages:
            first_message = messages[0]
            msg_date = first_message.get("date_utc")
            if msg_date:
                result = parse_datetime_utc(msg_date, use_zoneinfo=True)
                if result:
                    return result

        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–∞—Ç—É
        return datetime.min.replace(tzinfo=None)

    async def build_index(
        self,
        scope: str = "all",
        chat: Optional[str] = None,
        force_full: bool = False,
        recent_days: int = 7,
        adapter: Optional[Any] = None,  # MemoryServiceAdapter, –Ω–æ –∏–∑–±–µ–≥–∞–µ–º —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞
    ) -> Dict[str, Any]:
        """
        –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞

        Args:
            scope: "all" –∏–ª–∏ "chat"
            chat: –ù–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞ (–¥–ª—è scope="chat")
            force_full: –ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ—Å–±–æ—Ä–∫–∞
            recent_days: –ü–µ—Ä–µ—Å–∞–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π

        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        """
        logger.info(
            f"–ù–∞—á–∞–ª–æ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: scope={scope}, chat={chat}, force_full={force_full}"
        )

        stats = {
            "indexed_chats": [],
            "sessions_indexed": 0,
            "messages_indexed": 0,
            "tasks_indexed": 0,
        }

        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —á–∞—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        chats_path = Path("chats")
        if scope == "chat" and chat:
            chat_dirs = [chats_path / chat]
        else:
            chat_dirs = [d for d in chats_path.iterdir() if d.is_dir()]

        # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —á–∞—Ç
        total_chats = len(chat_dirs)
        for chat_idx, chat_dir in enumerate(chat_dirs, 1):
            try:
                chat_name = chat_dir.name
                logger.info(f"üìÅ –ß–∞—Ç {chat_idx}/{total_chats}: {chat_name}")

                # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –ø–æ–ª–Ω–æ–π –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
                if force_full and adapter is not None:
                    logger.info(f"üßπ –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö —á–∞—Ç–∞ {chat_name} –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–µ–π...")
                    try:
                        cleanup_stats = adapter.clear_chat_data(chat_name)
                        logger.info(
                            f"‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: "
                            f"—É–∑–ª–æ–≤={cleanup_stats.get('nodes_deleted', 0)}, "
                            f"–≤–µ–∫—Ç–æ—Ä–æ–≤={cleanup_stats.get('vectors_deleted', 0)}, "
                            f"ChromaDB={cleanup_stats.get('chromadb_deleted', 0)}"
                        )
                    except Exception as e:
                        logger.warning(
                            f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö —á–∞—Ç–∞ {chat_name}: {e}. "
                            f"–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é...",
                            exc_info=True,
                        )

                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ JSON —Ñ–∞–π–ª–æ–≤
                messages = await self._load_messages_from_chat(chat_dir)

                if not messages:
                    logger.warning(f"–ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —á–∞—Ç–µ {chat_name}")
                    continue

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å
                if not force_full:
                    # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è: –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                    last_indexed_date = self._get_last_indexed_date(chat_name)

                    if last_indexed_date:
                        # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–æ–≤–µ–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ
                        messages_to_index = [
                            m
                            for m in messages
                            if self._parse_message_time(m) > last_indexed_date
                        ]
                        logger.info(
                            f"üìä –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è: –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ "
                            f"—Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {last_indexed_date.strftime('%Y-%m-%d %H:%M:%S')}"
                        )
                    else:
                        # –ü–µ—Ä–≤–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —á–∞—Ç–∞ - –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –≤—Å–µ –∏–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π
                        if recent_days > 0:
                            recent_cutoff = datetime.now(ZoneInfo("UTC")) - timedelta(
                                days=recent_days
                            )
                            messages_to_index = [
                                m
                                for m in messages
                                if self._parse_message_time(m) >= recent_cutoff
                            ]
                            logger.info(
                                f"üìä –ü–µ—Ä–≤–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ {recent_days} –¥–Ω–µ–π"
                            )
                        else:
                            messages_to_index = messages
                            logger.info(
                                "üìä –ü–µ—Ä–≤–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è"
                            )
                else:
                    messages_to_index = messages
                    logger.info("üìä –ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è")

                logger.info(
                    f"–°–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {len(messages_to_index)} –∏–∑ {len(messages)}"
                )

                # –í—ã–±–∏—Ä–∞–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
                if self.enable_smart_aggregation and self.smart_aggregator:
                    logger.info("üß† –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω—É—é –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É —Å —Å–∫–æ–ª—å–∑—è—â–∏–º–∏ –æ–∫–Ω–∞–º–∏")
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω—É—é –∞–≥—Ä–µ–≥–∞—Ü–∏—é
                    aggregation_result = await self.smart_aggregator.aggregate_chat(
                        chat_name, dry_run=False
                    )
                    sessions = aggregation_result.get("sessions", [])
                    logger.info(f"–£–º–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è —Å–æ–∑–¥–∞–ª–∞ {len(sessions)} —Å–µ—Å—Å–∏–π")
                else:
                    logger.info("üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª–∞—Å—Å–∏—á–µ—Å–∫—É—é –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É")
                    # –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Å —É–º–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π –æ–∫–æ–Ω
                    sessions = self._group_messages_by_smart_strategy(
                        messages_to_index, chat_name
                    )
                    logger.info(f"–°–æ–∑–¥–∞–Ω–æ {len(sessions)} —Å–µ—Å—Å–∏–π —Å —É–º–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π")

                # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π
                existing_session_ids = set()
                existing_summaries = []
                if not force_full:
                    try:
                        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ session_id –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —á–∞—Ç–∞
                        result = self.sessions_collection.get(
                            where={"chat": chat_name}, include=["metadatas"]
                        )
                        if result and result.get("ids"):
                            existing_session_ids = set(result["ids"])
                            logger.info(
                                f"üìã –ù–∞–π–¥–µ–Ω–æ {len(existing_session_ids)} —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π"
                            )

                            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –∏–∑ JSON —Ñ–∞–π–ª–æ–≤
                            reports_dir = self.reports_path
                            chat_slug = slugify(chat_name)
                            sessions_dir = reports_dir / chat_slug / "sessions"

                            if sessions_dir.exists():
                                import json

                                for session_id in existing_session_ids:
                                    json_file = sessions_dir / f"{session_id}.json"
                                    if json_file.exists():
                                        try:
                                            with open(json_file, encoding="utf-8") as f:
                                                summary = json.load(f)
                                                existing_summaries.append(summary)
                                        except Exception as e:
                                            logger.debug(
                                                f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {json_file}: {e}"
                                            )
                    except Exception as e:
                        logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–µ—Å—Å–∏–∏: {e}")

                # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–µ—Å—Å–∏–∏ —Å–Ω–∞—á–∞–ª–∞ –ø–æ —Ç–∏–ø—É –æ–∫–Ω–∞, –∑–∞—Ç–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞—á–∞–ª–∞
                # –ü–æ—Ä—è–¥–æ–∫: old -> recent -> fresh -> now –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                window_priority = {"old": 0, "recent": 1, "fresh": 2, "now": 3}

                def sort_key(session):
                    window = session.get("window", "unknown")
                    priority = window_priority.get(
                        window, 999
                    )  # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –æ–∫–Ω–∞ –≤ –∫–æ–Ω–µ—Ü
                    start_time = self._parse_session_start_time(session)
                    return (priority, start_time)

                sessions_sorted = sorted(sessions, key=sort_key)
                logger.info(
                    "üìÖ –°–µ—Å—Å–∏–∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ —Ç–∏–ø—É –æ–∫–Ω–∞ –∏ –≤—Ä–µ–º–µ–Ω–∏ (old -> recent -> fresh -> now)"
                )

                # –°–∞–º–º–∞—Ä–∏–∑–∏—Ä—É–µ–º –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —Å–µ—Å—Å–∏—é –≤ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –ø–æ—Ä—è–¥–∫–µ
                processed_summaries = []
                total_messages_in_chat = len(messages)
                processed_messages_count = 0
                skipped_sessions = 0

                for session_idx, session in enumerate(sessions_sorted, 1):
                    try:
                        if session is None:
                            logger.warning(
                                f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º None —Å–µ—Å—Å–∏—é –≤ –ø–æ–∑–∏—Ü–∏–∏ {session_idx}"
                            )
                            continue

                        session_id = session.get("session_id")
                        session_messages_count = len(session.get("messages", []))

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –±—ã–ª–∞ –ª–∏ —ç—Ç–∞ —Å–µ—Å—Å–∏—è —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∞
                        if session_id in existing_session_ids:
                            logger.debug(
                                f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å–µ—Å—Å–∏—é: {session_id}"
                            )
                            skipped_sessions += 1
                            processed_messages_count += session_messages_count
                            continue

                        processed_messages_count += session_messages_count

                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                        progress_pct = (
                            processed_messages_count / total_messages_in_chat
                        ) * 100
                        logger.info(
                            f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å —á–∞—Ç–∞ {chat_name}: "
                            f"{processed_messages_count}/{total_messages_in_chat} —Å–æ–æ–±—â–µ–Ω–∏–π "
                            f"({progress_pct:.1f}%) | "
                            f"–°–µ—Å—Å–∏—è {session_idx}/{len(sessions)}: {session_id}"
                        )

                        # –°–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è
                        summary = await self.session_summarizer.summarize_session(
                            session
                        )
                        processed_summaries.append(summary)

                        # L1: –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å–∞–º–º–∞—Ä–∏ —Å–µ—Å—Å–∏–∏
                        await self._index_session_l1(summary)
                        stats["sessions_indexed"] += 1

                        # L2: –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
                        messages_count = await self._index_messages_l2(session)
                        stats["messages_indexed"] += messages_count

                        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è tasks
                        tasks_count = await self._index_tasks(summary)
                        stats["tasks_indexed"] += tasks_count

                        # –†–µ–Ω–¥–µ—Ä–∏–Ω–≥ Markdown
                        self.markdown_renderer.render_session_summary(
                            summary, force=self.force
                        )
                        self.markdown_renderer.render_snippets(
                            session, force=self.force
                        )

                        # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                        await asyncio.sleep(0.5)

                    except Exception as e:
                        logger.error(
                            f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–µ—Å—Å–∏–∏ {session['session_id']}: {e}"
                        )
                        # –õ–æ–≥–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                        if "Invalid IPv6 URL" in str(e):
                            logger.error(
                                f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –æ—à–∏–±–∫–∞ IPv6 URL –≤ —Å–µ—Å—Å–∏–∏ {session['session_id']}. "
                                f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö URL."
                            )
                        continue

                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏ –Ω–æ–≤—ã–µ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è –æ—Ç—á–µ—Ç–æ–≤
                all_summaries = existing_summaries + processed_summaries

                # –°–æ–∑–¥–∞—ë–º –≥–ª–∞–≤–Ω—É—é —Å–≤–æ–¥–∫—É —á–∞—Ç–∞ –∏–∑ –≤—Å–µ—Ö —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–π
                if all_summaries:
                    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–µ—Å—Å–∏–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π –¥–ª—è —Ä–∞–∑–¥–µ–ª–∞ "–ê–∫—Ç—É–∞–ª—å–Ω–æ"
                    now = datetime.now(ZoneInfo("UTC"))
                    thirty_days_ago = now - timedelta(days=30)

                    recent_sessions = [
                        s
                        for s in all_summaries
                        if self._parse_message_time(
                            {"date_utc": s.get("meta", {}).get("end_time_utc", "")}
                        )
                        >= thirty_days_ago
                    ]

                    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–∞—á–µ—Å—Ç–≤—É (score) –¥–ª—è —Ç–æ–ø-—Å–µ—Å—Å–∏–π
                    top_sessions = sorted(
                        recent_sessions,
                        key=lambda s: s.get("quality", {}).get("score", 0),
                        reverse=True,
                    )

                    self.markdown_renderer.render_chat_summary(
                        chat_name,
                        all_summaries,
                        top_sessions=top_sessions,
                        force=self.force,
                    )
                    # –°–æ–∑–¥–∞—ë–º —Ñ–∞–π–ª –Ω–∞–∫–∞–ø–ª–∏–≤–∞—é—â–µ–≥–æ—Å—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                    self.markdown_renderer.render_cumulative_context(
                        chat_name, all_summaries, force=self.force
                    )
                    # –°–æ–∑–¥–∞—ë–º –∏–Ω–¥–µ–∫—Å —Å–µ—Å—Å–∏–π —á–∞—Ç–∞
                    self.markdown_renderer.render_chat_index(
                        chat_name, all_summaries, force=self.force
                    )

                    # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–π —á–∞—Ç–∞ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–æ–≤—ã–µ —Å–µ—Å—Å–∏–∏)
                    if (
                        self.enable_clustering
                        and len(processed_summaries) >= self.min_cluster_size
                    ):
                        logger.info(f"–ó–∞–ø—É—Å–∫ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è —á–∞—Ç–∞ {chat_name}")
                        try:
                            # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑—É–µ–º –≤—Å–µ —Å–µ—Å—Å–∏–∏ —á–∞—Ç–∞, –≤–∫–ª—é—á–∞—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ
                            cluster_stats = await self._cluster_chat_sessions(
                                chat_name, all_summaries
                            )
                            stats["clusters_created"] = cluster_stats.get(
                                "clusters_count", 0
                            )
                            stats["sessions_clustered"] = cluster_stats.get(
                                "sessions_clustered", 0
                            )
                            logger.info(f"–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {cluster_stats}")
                        except Exception as e:
                            logger.error(
                                f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ —á–∞—Ç–∞ {chat_name}: {e}"
                            )

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–ª—è –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π
                if messages_to_index:
                    # –ù–∞—Ö–æ–¥–∏–º –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
                    last_message_date = max(
                        self._parse_message_time(m) for m in messages_to_index
                    )
                    self._save_indexing_progress(
                        chat_name=chat_name,
                        last_message_date=last_message_date,
                        messages_count=len(messages_to_index),
                        sessions_count=len(processed_summaries),
                    )

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ª–æ–≤–∞—Ä–∏ —Å—É—â–Ω–æ—Å—Ç–µ–π –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ –æ–±—É—á–µ–Ω–∏–µ
                if self.entity_dictionary and self.enable_entity_learning:
                    try:
                        self.entity_dictionary.save_dictionaries()
                        logger.info(f"–°–ª–æ–≤–∞—Ä–∏ —Å—É—â–Ω–æ—Å—Ç–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–ª—è —á–∞—Ç–∞ {chat_name}")
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–ª–æ–≤–∞—Ä–µ–π —Å—É—â–Ω–æ—Å—Ç–µ–π: {e}")

                stats["indexed_chats"].append(chat_name)

                # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —á–∞—Ç—É
                if skipped_sessions > 0:
                    logger.info(
                        f"‚úÖ –ß–∞—Ç {chat_name} –∑–∞–≤–µ—Ä—à–µ–Ω: "
                        f"{len(processed_summaries)} –Ω–æ–≤—ã—Ö —Å–µ—Å—Å–∏–π, "
                        f"{skipped_sessions} –ø—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ), "
                        f"{processed_messages_count} —Å–æ–æ–±—â–µ–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ"
                    )
                else:
                    logger.info(
                        f"‚úÖ –ß–∞—Ç {chat_name} –∑–∞–≤–µ—Ä—à–µ–Ω: "
                        f"{len(processed_summaries)} —Å–µ—Å—Å–∏–π, "
                        f"{processed_messages_count} —Å–æ–æ–±—â–µ–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ"
                    )

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —á–∞—Ç–∞ {chat_dir.name}: {e}")
                continue

        logger.info(f"–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {stats}")
        return stats

    async def _load_messages_from_chat(self, chat_dir: Path) -> List[Dict[str, Any]]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ JSON —Ñ–∞–π–ª–æ–≤ —á–∞—Ç–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—â—É—é —É—Ç–∏–ª–∏—Ç—É).

        Args:
            chat_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —á–∞—Ç–∞

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
        """
        from ..utils.json_loader import load_json_or_jsonl

        messages = []
        json_files = list(chat_dir.glob("*.json"))

        for json_file in json_files:
            try:
                file_messages, _ = load_json_or_jsonl(json_file)
                messages.extend(file_messages)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {json_file}: {e}")
                continue

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        messages.sort(key=lambda x: x.get("date_utc") or x.get("date", ""))

        return messages

    async def _index_session_l1(self, summary: Dict[str, Any]):
        """
        –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ L1 (—Å–∞–º–º–∞—Ä–∏ + E1)

        Args:
            summary: –°–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏
        """
        session_id = summary["session_id"]

        meta = summary.get("meta", {})

        topics_text = "\n".join(
            f"{topic.get('title', '')}: {topic.get('summary', '')}"
            for topic in summary.get("topics", [])
        )
        claims_text = "\n".join(
            claim.get("summary", "") for claim in summary.get("claims", [])
        )
        discussion_text = "\n".join(
            item.get("quote", "") for item in summary.get("discussion", [])
        )
        entities_text = ", ".join(summary.get("entities", []))

        embedding_text = (
            f"Topics:\n{topics_text}\n\n"
            f"Claims:\n{claims_text}\n\n"
            f"Discussion:\n{discussion_text}\n\n"
            f"Entities: {entities_text}"
        )

        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥
        embedding_text, replaced_urls = validate_embedding_text(embedding_text)

        # –õ–æ–≥–∏—Ä—É–µ–º –∑–∞–º–µ–Ω–µ–Ω–Ω—ã–µ URL –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        if replaced_urls:
            logger.warning(
                f"–í —Å–µ—Å—Å–∏–∏ {session_id} –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ URL: {replaced_urls}"
            )

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
        async with self.embedding_client:
            embeddings = await self.embedding_client.generate_embeddings([embedding_text])
            embedding = embeddings[0]

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            "session_id": session_id,
            "chat": meta.get("chat_name", ""),
            "profile": meta.get("profile", ""),
            "start_time_utc": meta.get("start_time_utc", ""),
            "end_time_utc": meta.get("end_time_utc", ""),
            "time_span": meta.get("time_span", ""),
            "message_count": meta.get("messages_total", 0),
            "dominant_language": meta.get("dominant_language", "unknown"),
            "chat_mode": meta.get("chat_mode", "group"),
            "topics_count": len(summary.get("topics", [])),
            "claims_count": len(summary.get("claims", [])),
            "quality_score": summary.get("quality", {}).get("score", 0),
            "replaced_urls": ",".join(replaced_urls)
            if replaced_urls
            else "",  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–º–µ–Ω–µ–Ω–Ω—ã–µ URL –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
        }

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é
        self.sessions_collection.upsert(
            ids=[session_id],
            documents=[embedding_text],
            embeddings=[embedding],
            metadatas=[metadata],
        )

        # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –≥—Ä–∞—Ñ–æ–º –ø–∞–º—è—Ç–∏
        if self.ingestor and self.graph:
            from ..indexing import MemoryRecord
            from ..utils.datetime_utils import parse_datetime_utc
            
            try:
                # –ü–∞—Ä—Å–∏–º timestamp –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                start_time_utc = meta.get("start_time_utc", "")
                timestamp = parse_datetime_utc(start_time_utc, default=None) if start_time_utc else None
                if not timestamp:
                    from datetime import datetime, timezone
                    timestamp = datetime.now(timezone.utc)
                
                # –°–æ–∑–¥–∞—ë–º MemoryRecord –¥–ª—è —Å–µ—Å—Å–∏–∏
                record = MemoryRecord(
                    record_id=session_id,
                    source=meta.get("chat_name", "unknown"),
                    content=embedding_text,
                    timestamp=timestamp,
                    author=None,  # –°–µ—Å—Å–∏–∏ –Ω–µ –∏–º–µ—é—Ç –∞–≤—Ç–æ—Ä–∞
                    tags=[],
                    entities=summary.get("entities", []),
                    attachments=[],
                    metadata={
                        "chat": meta.get("chat_name", ""),
                        "profile": meta.get("profile", ""),
                        "start_time_utc": start_time_utc,
                        "end_time_utc": meta.get("end_time_utc", ""),
                        "time_span": meta.get("time_span", ""),
                        "message_count": meta.get("messages_total", 0),
                        "dominant_language": meta.get("dominant_language", "unknown"),
                        "chat_mode": meta.get("chat_mode", "group"),
                        "topics_count": len(summary.get("topics", [])),
                        "claims_count": len(summary.get("claims", [])),
                        "quality_score": summary.get("quality", {}).get("score", 0),
                        "session_type": "session_summary",  # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ —Å–∞–º–º–∞—Ä–∏ —Å–µ—Å—Å–∏–∏
                    },
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –≥—Ä–∞—Ñ
                self.ingestor.ingest([record])
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –≤ –≥—Ä–∞—Ñ
                if embedding:
                    try:
                        self.graph.update_node(
                            session_id,
                            embedding=embedding,
                        )
                    except Exception as e:
                        logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —Å–µ—Å—Å–∏–∏ {session_id}: {e}")
                
                logger.debug(f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å–µ—Å—Å–∏—è {session_id} —Å –≥—Ä–∞—Ñ–æ–º –ø–∞–º—è—Ç–∏")
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Å–µ—Å—Å–∏–∏ {session_id} —Å –≥—Ä–∞—Ñ–æ–º: {e}")

        logger.info(f"L1: –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∞ —Å–µ—Å—Å–∏—è {session_id}")

    async def _index_messages_l2(self, session: Dict[str, Any]) -> int:
        """
        –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –Ω–∞ —É—Ä–æ–≤–Ω–µ L2 (—Å —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º)

        Args:
            session: –°–µ—Å—Å–∏—è

        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        """
        messages = session["messages"]
        session_id = session["session_id"]
        chat = session["chat"]

        indexed_count = 0
        messages_to_index = []

        # –û–ø—Ä–µ–¥–µ–ª–∏–º —Ç–∏–ø —á–∞—Ç–∞ –¥–ª—è –ø–æ–¥—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        chat_mode = self._detect_chat_mode(messages)

        for i, msg in enumerate(messages):
            try:
                msg_text = msg.get("text", "").strip()
                if not msg_text or len(msg_text) < 10:
                    continue

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –±–∞–∑–µ
                msg_id = f"{session_id}-M{i+1:04d}"
                existing_msg = self.messages_collection.get(ids=[msg_id])
                if existing_msg and existing_msg.get("ids"):
                    # –°–æ–æ–±—â–µ–Ω–∏–µ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                    logger.debug(f"–°–æ–æ–±—â–µ–Ω–∏–µ {msg_id} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    continue

                # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–¥–æ 10 —Å–æ–æ–±—â–µ–Ω–∏–π, ‚â§ 1500 —Å–∏–º–≤–æ–ª–æ–≤)
                # –í –∫–∞–Ω–∞–ª–∞—Ö —Å–æ—Å–µ–¥–Ω–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç –º–µ–Ω–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω ‚Äî —É–º–µ–Ω—å—à–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                context_text = self._build_symmetric_context(
                    messages,
                    i,
                    max_messages=(3 if chat_mode == "channel" else 10),
                    max_chars=(500 if chat_mode == "channel" else 1500),
                )

                # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç + –∫–æ–Ω—Ç–µ–∫—Å—Ç
                embedding_text = f"{context_text}\n[CURRENT]: {msg_text}"

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –æ–±—Ä–µ–∑–∞–µ–º —Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –æ–Ω –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤
                # –û—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤: –ø—Ä–∏–º–µ—Ä–Ω–æ 4 —Å–∏–º–≤–æ–ª–∞ = 1 —Ç–æ–∫–µ–Ω
                estimated_tokens = len(embedding_text) // 4
                max_tokens = 8192  # –£–º–µ–Ω—å—à–∞–µ–º –¥–æ 8192 —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏

                if estimated_tokens > max_tokens:
                    # –°–Ω–∞—á–∞–ª–∞ –æ–±—Ä–µ–∑–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –æ–Ω —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π
                    max_context_chars = (
                        2000  # –£–º–µ–Ω—å—à–∞–µ–º –¥–æ 2000 —Å–∏–º–≤–æ–ª–æ–≤ (~500 —Ç–æ–∫–µ–Ω–æ–≤) –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ª–∏–º–∏—Ç—É 8192
                    )
                    if len(context_text) > max_context_chars:
                        context_text = context_text[:max_context_chars] + "..."

                    # –ó–∞—Ç–µ–º –æ–±—Ä–µ–∑–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                    # –£—á–∏—Ç—ã–≤–∞–µ–º –¥–ª–∏–Ω—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ + "[CURRENT]: " (~3 —Ç–æ–∫–µ–Ω–∞)
                    remaining_chars = (max_tokens - len(context_text) // 4 - 3) * 4
                    if remaining_chars > 0:
                        msg_text = msg_text[:remaining_chars] + "..."
                        embedding_text = f"{context_text}\n[CURRENT]: {msg_text}"
                    else:
                        # –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç —É–∂–µ –∑–∞–Ω–∏–º–∞–µ—Ç –ø–æ—á—Ç–∏ –≤–µ—Å—å –ª–∏–º–∏—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–µ
                        msg_text = msg_text[: max_tokens * 4 - 10] + "..."
                        embedding_text = f"[CURRENT]: {msg_text}"

                    final_tokens = len(embedding_text) // 4
                    original_tokens = estimated_tokens
                    logger.warning(
                        f"–¢–µ–∫—Å—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –æ–±—Ä–µ–∑–∞–Ω –¥–æ ~{final_tokens} —Ç–æ–∫–µ–Ω–æ–≤ "
                        f"(–∏—Å—Ö–æ–¥–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: ~{original_tokens} —Ç–æ–∫–µ–Ω–æ–≤)"
                    )

                # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥
                embedding_text, replaced_urls = validate_embedding_text(embedding_text)

                # –õ–æ–≥–∏—Ä—É–µ–º –∑–∞–º–µ–Ω–µ–Ω–Ω—ã–µ URL –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
                if replaced_urls:
                    logger.warning(
                        f"–í —Å–æ–æ–±—â–µ–Ω–∏–∏ {i+1} —Å–µ—Å—Å–∏–∏ {session_id} –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ URL: {replaced_urls}"
                    )

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                messages_to_index.append({
                    "msg_id": msg_id,
                    "msg_text": msg_text,
                    "embedding_text": embedding_text,
                    "msg_index": i,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞–≤—Ç–æ—Ä–∞
                    "msg": msg,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞–≤—Ç–æ—Ä–∞
                    "metadata": {
                        "msg_id": msg_id,
                        "session_id": session_id,
                        "chat": chat,
                        "date_utc": msg.get("date_utc") or msg.get("date", ""),
                        "has_context": len(context_text) > 0,
                        "context_length": len(context_text),
                        "chat_mode": chat_mode,
                        "replaced_urls": ",".join(replaced_urls)
                        if replaced_urls
                        else "",  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–º–µ–Ω–µ–Ω–Ω—ã–µ URL –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
                    }
                })

            except Exception as e:
                logger.error(
                    f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è {i} –≤ —Å–µ—Å—Å–∏–∏ {session_id} –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}"
                )
                # –õ–æ–≥–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                if "Invalid IPv6 URL" in str(e):
                    logger.error(
                        f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –æ—à–∏–±–∫–∞ IPv6 URL –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ {i} —Å–µ—Å—Å–∏–∏ {session_id}. "
                        f"–¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è: {msg.get('text', '')[:100]}..."
                    )
                continue

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –±–∞—Ç—á–∞–º–∏
        if messages_to_index:
            try:
                async with self.embedding_client:
                    # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç—ã –¥–ª—è –±–∞—Ç—á–∞
                    batch_texts = [msg["embedding_text"] for msg in messages_to_index]
                    
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –±–∞—Ç—á–µ–º
                    embeddings = await self.embedding_client.generate_embeddings(batch_texts, batch_size=32)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é –±–∞—Ç—á–µ–º
                    ids = [msg["msg_id"] for msg in messages_to_index]
                    documents = [msg["msg_text"] for msg in messages_to_index]
                    metadatas = [msg["metadata"] for msg in messages_to_index]
                    
                    self.messages_collection.upsert(
                        ids=ids,
                        documents=documents,
                        embeddings=embeddings,
                        metadatas=metadatas,
                    )
                    
                    # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –≥—Ä–∞—Ñ–æ–º –ø–∞–º—è—Ç–∏
                    if self.ingestor and self.graph:
                        from ..indexing import MemoryRecord, Attachment
                        from ..utils.datetime_utils import parse_datetime_utc
                        
                        records_to_ingest = []
                        for idx, msg_data in enumerate(messages_to_index):
                            try:
                                msg_id = msg_data["msg_id"]
                                msg_text = msg_data["msg_text"]
                                metadata = msg_data["metadata"]
                                embedding = embeddings[idx] if idx < len(embeddings) else None
                                
                                # –ü–∞—Ä—Å–∏–º timestamp
                                date_utc = metadata.get("date_utc", "")
                                timestamp = parse_datetime_utc(date_utc, default=None) if date_utc else None
                                if not timestamp:
                                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –∫–∞–∫ fallback
                                    from datetime import datetime, timezone
                                    timestamp = datetime.now(timezone.utc)
                                
                                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–≤—Ç–æ—Ä–∞ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
                                author = None
                                msg_obj = msg_data.get("msg")
                                if msg_obj:
                                    from_data = msg_obj.get("from") or {}
                                    author = from_data.get("username") or from_data.get("display") or from_data.get("id")
                                
                                # –°–æ–∑–¥–∞—ë–º MemoryRecord
                                record = MemoryRecord(
                                    record_id=msg_id,
                                    source=metadata.get("chat", "unknown"),
                                    content=msg_text,
                                    timestamp=timestamp,
                                    author=author,
                                    tags=[],
                                    entities=[],
                                    attachments=[],
                                    metadata={
                                        "chat": metadata.get("chat", ""),
                                        "session_id": metadata.get("session_id", ""),
                                        "has_context": metadata.get("has_context", False),
                                        "context_length": metadata.get("context_length", 0),
                                        "chat_mode": metadata.get("chat_mode", "group"),
                                        "date_utc": date_utc,
                                    },
                                )
                                records_to_ingest.append((record, embedding))
                            except Exception as e:
                                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –∑–∞–ø–∏—Å–∏ {msg_data.get('msg_id', 'unknown')} –¥–ª—è –≥—Ä–∞—Ñ–∞: {e}")
                                continue
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø–∏—Å–∏ –≤ –≥—Ä–∞—Ñ –±–∞—Ç—á–µ–º
                        if records_to_ingest:
                            try:
                                records_only = [r for r, _ in records_to_ingest]
                                self.ingestor.ingest(records_only)
                                
                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –≤ –≥—Ä–∞—Ñ
                                for record, embedding in records_to_ingest:
                                    if embedding:
                                        try:
                                            self.graph.update_node(
                                                record.record_id,
                                                embedding=embedding,
                                            )
                                        except Exception as e:
                                            logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è {record.record_id}: {e}")
                                
                                logger.debug(f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(records_to_ingest)} –∑–∞–ø–∏—Å–µ–π —Å –≥—Ä–∞—Ñ–æ–º –ø–∞–º—è—Ç–∏")
                            except Exception as e:
                                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∑–∞–ø–∏—Å–µ–π —Å –≥—Ä–∞—Ñ–æ–º: {e}")
                    
                    indexed_count += len(messages_to_index)
            except Exception as e:
                logger.error(
                    f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Å–µ—Å—Å–∏–∏ {session_id}: {e}"
                )

        logger.info(
            f"L2: –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {indexed_count} —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ —Å–µ—Å—Å–∏–∏ {session_id}"
        )
        return indexed_count

    def _detect_chat_mode(self, messages: List[Dict[str, Any]]) -> str:
        """–õ–æ–∫–∞–ª—å–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ —á–∞—Ç–∞: 'channel' –∏–ª–∏ 'group'."""
        authors = []
        for m in messages:
            fr = m.get("from") or {}
            name = fr.get("username") or fr.get("display") or fr.get("id") or "unknown"
            authors.append(str(name))
        total = len([a for a in authors if a != "unknown"])
        if total == 0:
            return "group"
        cnt = Counter(a for a in authors if a != "unknown")
        top, top_count = cnt.most_common(1)[0]
        top_share = top_count / total
        unique = len(cnt)
        if (top_share >= 0.85 and unique <= 3 and total >= 5) or unique == 1:
            return "channel"
        return "group"

    def _build_symmetric_context(
        self,
        messages: List[Dict[str, Any]],
        current_idx: int,
        max_messages: int = 10,
        max_chars: int = 1500,
    ) -> str:
        """
        –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è

        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
            current_idx: –ò–Ω–¥–µ–∫—Å —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
            max_messages: –ú–∞–∫—Å–∏–º—É–º —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10)
            max_chars: –ú–∞–∫—Å–∏–º—É–º —Å–∏–º–≤–æ–ª–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1500)

        Returns:
            –¢–µ–∫—Å—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        """
        context_parts = []
        total_chars = 0

        # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–∏: -1, +1, -2, +2, ...
        distance = 1
        while len(context_parts) < max_messages and distance <= max_messages // 2:
            # –ü—Ä–µ–¥—ã–¥—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            prev_idx = current_idx - distance
            if prev_idx >= 0:
                prev_text = messages[prev_idx].get("text", "").strip()
                if prev_text and total_chars + len(prev_text) <= max_chars:
                    context_parts.insert(0, prev_text)
                    total_chars += len(prev_text)

            # –°–ª–µ–¥—É—é—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            next_idx = current_idx + distance
            if next_idx < len(messages):
                next_text = messages[next_idx].get("text", "").strip()
                if next_text and total_chars + len(next_text) <= max_chars:
                    context_parts.append(next_text)
                    total_chars += len(next_text)

            distance += 1

        return " | ".join(context_parts)

    async def _index_tasks(self, summary: Dict[str, Any]) -> int:
        """
        –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è Action Items –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é tasks

        Args:
            summary: –°–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏

        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
        """
        actions = summary.get("actions", [])
        session_id = summary["session_id"]
        chat = summary.get("meta", {}).get("chat_name", "")

        indexed_count = 0

        for i, action in enumerate(actions):
            confidence = action.get("confidence", 0.8)
            if confidence < 0.6:
                continue

            try:
                # –¢–µ–∫—Å—Ç –∑–∞–¥–∞—á–∏
                task_text = action.get("text", "")
                if not task_text:
                    continue

                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
                async with self.embedding_client:
                    embeddings = await self.embedding_client.generate_embeddings(
                        [task_text]
                    )
                    embedding = embeddings[0]

                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                task_id = f"{session_id}-T{i+1:02d}"
                metadata = {
                    "task_id": task_id,
                    "session_id": session_id,
                    "chat": chat,
                    "owner": action.get("owner", ""),
                    "due": action.get("due", ""),
                    "priority": action.get("priority", "normal"),
                    "confidence": confidence,
                    "msg_id": action.get("msg_id", ""),
                    "topic_title": action.get("topic_title", ""),
                }

                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é
                self.tasks_collection.upsert(
                    ids=[task_id],
                    documents=[task_text],
                    embeddings=[embedding],
                    metadatas=[metadata],
                )

                indexed_count += 1

            except Exception as e:
                logger.error(
                    f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∑–∞–¥–∞—á–∏ {i} –≤ —Å–µ—Å—Å–∏–∏ {session_id}: {e}"
                )
                continue

        logger.info(
            f"Tasks: –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {indexed_count} –∑–∞–¥–∞—á –∏–∑ —Å–µ—Å—Å–∏–∏ {session_id}"
        )
        return indexed_count

    def _parse_message_time(self, msg: Dict[str, Any]) -> datetime:
        """–ü–∞—Ä—Å–∏–Ω–≥ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–æ–±—â–µ–Ω–∏—è (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—â—É—é —É—Ç–∏–ª–∏—Ç—É)."""
        from ..utils.datetime_utils import parse_message_time

        return parse_message_time(msg, use_zoneinfo=True)

    async def _cluster_chat_sessions(
        self, chat_name: str, summaries: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–π —á–∞—Ç–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Args:
            chat_name: –ù–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞
            summaries: –°–ø–∏—Å–æ–∫ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–π —Å–µ—Å—Å–∏–π

        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
        """
        if not self.session_clusterer or not self.cluster_summarizer:
            return {"clusters_count": 0, "sessions_clustered": 0}

        # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ ChromaDB –¥–ª—è —Å–µ—Å—Å–∏–π
        session_ids = [s["session_id"] for s in summaries]

        try:
            result = self.sessions_collection.get(
                ids=session_ids, include=["embeddings", "metadatas", "documents"]
            )

            if not result["ids"]:
                logger.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–µ—Å—Å–∏–π —á–∞—Ç–∞ {chat_name}")
                return {"clusters_count": 0, "sessions_clustered": 0}

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
            sessions_data = []
            embeddings_list = []

            for i, session_id in enumerate(result["ids"]):
                sessions_data.append(
                    {
                        "session_id": session_id,
                        "metadata": result["metadatas"][i],
                        "document": result["documents"][i],
                    }
                )
                embeddings_list.append(result["embeddings"][i])

            # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é
            logger.info(f"–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è {len(sessions_data)} —Å–µ—Å—Å–∏–π —á–∞—Ç–∞ {chat_name}")
            clustering_result = self.session_clusterer.cluster_sessions(
                sessions_data, embeddings_list
            )

            clusters = clustering_result.get("clusters", [])
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(clusters)} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–ª–∞—Å—Ç–µ—Ä—ã –≤ ChromaDB –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–π
            clusters_saved = 0
            sessions_clustered = 0

            for cluster in clusters:
                cluster_id = f"{slugify(chat_name)}-cluster-{cluster['cluster_id']}"

                # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–π, –¥–æ–±–∞–≤–ª—è—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–ª–∞—Å—Ç–µ—Ä–µ
                for session_id in cluster["session_ids"]:
                    try:
                        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏
                        session_data = self.sessions_collection.get(
                            ids=[session_id], include=["metadatas"]
                        )

                        if session_data["ids"]:
                            metadata = session_data["metadatas"][0]
                            metadata["cluster_id"] = cluster_id
                            metadata["cluster_label"] = cluster.get("label", "")

                            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                            self.sessions_collection.update(
                                ids=[session_id], metadatas=[metadata]
                            )
                            sessions_clustered += 1
                    except Exception as e:
                        logger.error(
                            f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–∏ {session_id}: {e}"
                        )

                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∞ (—Å—Ä–µ–¥–Ω–µ–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å–µ—Å—Å–∏–π)
                cluster_embedding = [0.0] * len(embeddings_list[0])
                for session_id in cluster["session_ids"]:
                    try:
                        idx = session_ids.index(session_id)
                        session_emb = embeddings_list[idx]
                        for i, val in enumerate(session_emb):
                            cluster_embedding[i] += val
                    except ValueError:
                        continue

                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
                n = len(cluster["session_ids"])
                if n > 0:
                    cluster_embedding = [val / n for val in cluster_embedding]

                # –°–æ–∑–¥–∞—ë–º –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∞
                cluster_doc = (
                    f"–ö–ª–∞—Å—Ç–µ—Ä: {cluster.get('label', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}\n"
                    f"–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(cluster.get('keywords', []))}\n"
                    f"–¢–æ–ø–∏–∫–∏: {', '.join(cluster.get('topics', []))}\n"
                    f"–°—É—â–Ω–æ—Å—Ç–∏: {', '.join(cluster.get('entities', []))}"
                )

                # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Ç–µ—Ä–∞
                cluster_metadata = {
                    "cluster_id": cluster_id,
                    "chat": chat_name,
                    "label": cluster.get("label", ""),
                    "size": cluster.get("size", 0),
                    "coherence": cluster.get("coherence", 0.0),
                    "session_ids": ",".join(cluster["session_ids"][:10]),  # –ü–µ—Ä–≤—ã–µ 10
                }

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–ª–∞—Å—Ç–µ—Ä
                try:
                    self.clusters_collection.upsert(
                        ids=[cluster_id],
                        documents=[cluster_doc],
                        embeddings=[cluster_embedding],
                        metadatas=[cluster_metadata],
                    )
                    clusters_saved += 1
                    logger.info(
                        f"–°–æ—Ö—Ä–∞–Ω—ë–Ω –∫–ª–∞—Å—Ç–µ—Ä {cluster_id}: {cluster.get('label', '')}"
                    )
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞ {cluster_id}: {e}")

            return {
                "clusters_count": clusters_saved,
                "sessions_clustered": sessions_clustered,
                "total_sessions": len(sessions_data),
                "noise_sessions": clustering_result.get("noise_count", 0),
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ —á–∞—Ç–∞ {chat_name}: {e}")
            return {"clusters_count": 0, "sessions_clustered": 0}

    def get_clusters(
        self, chat: Optional[str] = None, limit: int = 20
    ) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤

        Args:
            chat: –§–∏–ª—å—Ç—Ä –ø–æ —á–∞—Ç—É (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        """
        if not self.clusters_collection:
            return []

        try:
            where_filter = {"chat": chat} if chat else None

            result = self.clusters_collection.get(
                where=where_filter, limit=limit, include=["metadatas", "documents"]
            )

            clusters = []
            for i, cluster_id in enumerate(result["ids"]):
                clusters.append(
                    {
                        "cluster_id": cluster_id,
                        "metadata": result["metadatas"][i],
                        "document": result["documents"][i],
                    }
                )

            return clusters
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {e}")
            return []

    def get_cluster_sessions(self, cluster_id: str) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–µ—Å—Å–∏–∏, –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—â–∏–µ –∫–ª–∞—Å—Ç–µ—Ä—É

        Args:
            cluster_id: ID –∫–ª–∞—Å—Ç–µ—Ä–∞

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–µ—Å—Å–∏–π
        """
        if not self.sessions_collection:
            return []

        try:
            result = self.sessions_collection.get(
                where={"cluster_id": cluster_id}, include=["metadatas", "documents"]
            )

            sessions = []
            for i, session_id in enumerate(result["ids"]):
                sessions.append(
                    {
                        "session_id": session_id,
                        "metadata": result["metadatas"][i],
                        "document": result["documents"][i],
                    }
                )

            return sessions
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–µ—Å—Å–∏–π –∫–ª–∞—Å—Ç–µ—Ä–∞ {cluster_id}: {e}")
            return []

    def _count_indexed_messages_in_chat(self, chat_name: str) -> int:
        """
        –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —á–∞—Ç–µ

        Returns:
            int: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ chat_messages –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —á–∞—Ç–∞
            messages_collection = self.chroma_client.get_collection("chat_messages")
            existing_messages = messages_collection.get(where={"chat": chat_name})

            if existing_messages and existing_messages.get("ids") is not None:
                message_count = len(existing_messages["ids"])
                logger.info(
                    f"–ù–∞–π–¥–µ–Ω–æ {message_count} —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —á–∞—Ç–µ {chat_name}"
                )
                return message_count
            else:
                logger.info(f"–í —á–∞—Ç–µ {chat_name} –Ω–µ—Ç –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π")
                return 0

        except Exception as e:
            logger.warning(
                f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥—Å—á–µ—Ç–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —á–∞—Ç–∞ {chat_name}: {e}"
            )
            return 0

    def _group_messages_by_smart_strategy(
        self, messages: List[Dict[str, Any]], chat_name: str
    ) -> List[Dict[str, Any]]:
        """
        –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π —Å —É–º–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π –æ–∫–æ–Ω

        NOW (0-1 –¥–µ–Ω—å): –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–Ω—è–º –∏–ª–∏ —Å–µ—Å—Å–∏—è–º
        FRESH (1-14 –¥–Ω–µ–π): –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–Ω—è–º —Å –º–∏–Ω–∏–º—É–º–æ–º —Å–æ–æ–±—â–µ–Ω–∏–π
        RECENT (14-30 –¥–Ω–µ–π): –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –Ω–µ–¥–µ–ª—è–º
        OLD (30+ –¥–Ω–µ–π): –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –º–µ—Å—è—Ü–∞–º

        –ü–µ—Ä–µ—Ö–æ–¥ –º–µ–∂–¥—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏:
        - –ï—Å–ª–∏ —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ >1000 —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —á–∞—Ç–µ, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        - fresh -> recent -> old
        """
        from datetime import datetime

        if not messages:
            return []

        current_date = datetime.now(datetime.now().astimezone().tzinfo)

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —á–∞—Ç–µ
        indexed_messages_count = self._count_indexed_messages_in_chat(chat_name)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        if indexed_messages_count >= self.strategy_threshold:
            logger.info(
                f"üîÑ –ü–µ—Ä–µ—Ö–æ–¥ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è —á–∞—Ç–∞ {chat_name}: "
                f"—É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {indexed_messages_count} —Å–æ–æ–±—â–µ–Ω–∏–π "
                f"(–ø–æ—Ä–æ–≥: {self.strategy_threshold})"
            )

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–µ—Å—Å–∏–π
            current_strategy = self._determine_current_strategy(chat_name)
            logger.info(f"üìä –¢–µ–∫—É—â–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è —á–∞—Ç–∞ {chat_name}: {current_strategy}")

            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            next_strategy = self._get_next_strategy(current_strategy)
            logger.info(f"‚û°Ô∏è  –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: {next_strategy}")

            # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é
            return self._apply_strategy_transition(
                messages, chat_name, next_strategy, current_date
            )

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä —Å–µ—Å—Å–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–µ—Å—Å–∏–π
        existing_session_ids = set()
        try:
            existing_sessions = self.sessions_collection.get(where={"chat": chat_name})
            if existing_sessions and existing_sessions.get("ids"):
                existing_session_ids = set(existing_sessions["ids"])
                logger.info(
                    f"–ù–∞–π–¥–µ–Ω–æ {len(existing_session_ids)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–µ—Å—Å–∏–π –¥–ª—è —á–∞—Ç–∞ {chat_name}"
                )
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–µ—Å—Å–∏–π: {e}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä —Å–µ—Å—Å–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–∫–Ω–∞
        window_max_numbers = {}
        for session_id in existing_session_ids:
            if f"{slugify(chat_name)}-" in session_id:
                parts = session_id.split("-")
                if len(parts) >= 3:
                    window_name = parts[1]
                    try:
                        session_num = int(parts[2][1:])  # –£–±–∏—Ä–∞–µ–º 'S' –∏ –±–µ—Ä–µ–º —á–∏—Å–ª–æ
                        if window_name not in window_max_numbers:
                            window_max_numbers[window_name] = 0
                        window_max_numbers[window_name] = max(
                            window_max_numbers[window_name], session_num
                        )
                    except (ValueError, IndexError):
                        continue

        logger.info(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –Ω–æ–º–µ—Ä–∞ —Å–µ—Å—Å–∏–π –ø–æ –æ–∫–Ω–∞–º: {window_max_numbers}")

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é fresh –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –Ω–æ–≤—ã—Ö —á–∞—Ç–æ–≤
        return self._apply_strategy_transition(
            messages, chat_name, "fresh", current_date
        )

    def _determine_current_strategy(self, chat_name: str) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–µ—Å—Å–∏–π

        Returns:
            str: —Ç–µ–∫—É—â–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è (fresh, recent, old)
        """
        try:
            existing_sessions = self.sessions_collection.get(where={"chat": chat_name})

            if not existing_sessions or not existing_sessions.get("ids"):
                return "fresh"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–∞—á–∏–Ω–∞–µ–º —Å fresh

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–µ—Å—Å–∏–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            strategies_found = set()
            for session_id in existing_sessions["ids"]:
                if f"{slugify(chat_name)}-" in session_id:
                    parts = session_id.split("-")
                    if len(parts) >= 3:
                        window_name = parts[1]
                        if window_name in ["fresh", "recent", "old"]:
                            strategies_found.add(window_name)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω
            if "old" in strategies_found:
                return "old"
            elif "recent" in strategies_found:
                return "recent"
            elif "fresh" in strategies_found:
                return "fresh"
            else:
                return "fresh"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é

        except Exception as e:
            logger.warning(
                f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è —á–∞—Ç–∞ {chat_name}: {e}"
            )
            return "fresh"

    def _get_next_strategy(self, current_strategy: str) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

        Args:
            current_strategy: —Ç–µ–∫—É—â–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è

        Returns:
            str: —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
        """
        strategy_sequence = ["fresh", "recent", "old"]

        try:
            current_index = strategy_sequence.index(current_strategy)
            if current_index < len(strategy_sequence) - 1:
                return strategy_sequence[current_index + 1]
            else:
                return "old"  # –û—Å—Ç–∞–µ–º—Å—è –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        except ValueError:
            logger.warning(
                f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {current_strategy}, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º fresh"
            )
            return "fresh"

    def _apply_strategy_transition(
        self,
        messages: List[Dict[str, Any]],
        chat_name: str,
        strategy: str,
        current_date,
    ) -> List[Dict[str, Any]]:
        """
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø–µ—Ä–µ—Ö–æ–¥ –∫ –Ω–æ–≤–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏

        Args:
            messages: —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
            chat_name: –Ω–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞
            strategy: –Ω–æ–≤–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è (fresh, recent, old)
            current_date: —Ç–µ–∫—É—â–∞—è –¥–∞—Ç–∞

        Returns:
            List[Dict[str, Any]]: —Å–ø–∏—Å–æ–∫ —Å–µ—Å—Å–∏–π
        """
        logger.info(f"üéØ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ '{strategy}' –¥–ª—è —á–∞—Ç–∞ {chat_name}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–æ–∑—Ä–∞—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –æ–∫–Ω–∞–º
        now_messages = []
        fresh_messages = []
        recent_messages = []
        old_messages = []

        for msg in messages:
            if "date_utc" not in msg:
                continue

            try:
                from ..utils.datetime_utils import parse_datetime_utc

                msg_date = parse_datetime_utc(msg["date_utc"], use_zoneinfo=True)
                age_days = (current_date - msg_date).days

                if age_days <= 1:
                    now_messages.append(msg)
                elif age_days <= 14:
                    fresh_messages.append(msg)
                elif age_days <= 30:
                    recent_messages.append(msg)
                else:
                    old_messages.append(msg)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç—ã —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
                continue

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–π
        sessions = []

        if strategy == "fresh":
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ NOW –∏ FRESH –æ–∫–Ω–∞
            # –ï—Å–ª–∏ –≤ —ç—Ç–∏—Ö –æ–∫–Ω–∞—Ö –Ω–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π, –Ω–æ –µ—Å—Ç—å –≤ OLD, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ OLD
            if not now_messages and not fresh_messages and old_messages:
                logger.info(
                    f"‚ö†Ô∏è  –í –æ–∫–Ω–∞—Ö NOW –∏ FRESH –Ω–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π, –Ω–æ –µ—Å—Ç—å {len(old_messages)} –≤ OLD. "
                    "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é OLD."
                )
                strategy = "old"
                window_strategies = [
                    ("now", now_messages, "session"),
                    ("fresh", fresh_messages, "day"),
                    ("recent", recent_messages, "week"),
                    ("old", old_messages, "month"),
                ]
            else:
                window_strategies = [
                    ("now", now_messages, "session"),
                    ("fresh", fresh_messages, "day"),
                ]
        elif strategy == "recent":
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º NOW, FRESH –∏ RECENT –æ–∫–Ω–∞
            window_strategies = [
                ("now", now_messages, "session"),
                ("fresh", fresh_messages, "day"),
                ("recent", recent_messages, "week"),
            ]
        else:  # strategy == "old"
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –æ–∫–Ω–∞
            window_strategies = [
                ("now", now_messages, "session"),
                ("fresh", fresh_messages, "day"),
                ("recent", recent_messages, "week"),
                ("old", old_messages, "month"),
            ]

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä —Å–µ—Å—Å–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–∫–Ω–∞
        existing_session_ids = set()
        try:
            existing_sessions = self.sessions_collection.get(where={"chat": chat_name})
            if existing_sessions and existing_sessions.get("ids"):
                existing_session_ids = set(existing_sessions["ids"])
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–µ—Å—Å–∏–π: {e}")

        window_max_numbers = {}
        for session_id in existing_session_ids:
            if f"{slugify(chat_name)}-" in session_id:
                parts = session_id.split("-")
                if len(parts) >= 3:
                    window_name = parts[1]
                    try:
                        session_num = int(parts[2][1:])  # –£–±–∏—Ä–∞–µ–º 'S' –∏ –±–µ—Ä–µ–º —á–∏—Å–ª–æ
                        if window_name not in window_max_numbers:
                            window_max_numbers[window_name] = 0
                        window_max_numbers[window_name] = max(
                            window_max_numbers[window_name], session_num
                        )
                    except (ValueError, IndexError):
                        continue

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–µ –æ–∫–Ω–æ –ø–æ —Å–≤–æ–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        for window_name, window_messages, window_strategy in window_strategies:
            if not window_messages:
                continue

            logger.info(
                f"–û–∫–Ω–æ '{window_name}': {len(window_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π, —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {window_strategy}"
            )

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
            window_sessions = (
                self.day_grouping_segmenter.group_messages_by_window_strategy(
                    window_messages, chat_name, window_strategy
                )
            )

            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–∫–Ω–µ –∫ —Å–µ—Å—Å–∏—è–º
            window_counter = window_max_numbers.get(window_name, 0) + 1
            for session in window_sessions:
                session["window"] = window_name
                session[
                    "session_id"
                ] = f"{slugify(chat_name)}-{window_name}-S{window_counter:04d}"
                window_counter += 1

            sessions.extend(window_sessions)

        logger.info(
            f"‚úÖ –°—Ç—Ä–∞—Ç–µ–≥–∏—è '{strategy}' –ø—Ä–∏–º–µ–Ω–µ–Ω–∞: —Å–æ–∑–¥–∞–Ω–æ {len(sessions)} —Å–µ—Å—Å–∏–π"
        )
        return sessions


if __name__ == "__main__":
    # –¢–µ—Å—Ç –º–æ–¥—É–ª—è
    async def test():
        indexer = TwoLevelIndexer()
        stats = await indexer.build_index(scope="all", recent_days=7)
        print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {stats}")

    asyncio.run(test())
