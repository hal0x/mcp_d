#!/usr/bin/env python3
"""–î–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è: L1 (sessions —Å —Å–∞–º–º–∞—Ä–∏) –∏ L2 (messages —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º)."""

import asyncio
import json
import logging
from collections import Counter
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional
from zoneinfo import ZoneInfo

from ..memory.qdrant_collections import QdrantCollectionsManager

from ..analysis.adaptive_message_grouper import AdaptiveMessageGrouper
from ..analysis.cluster_summarizer import ClusterSummarizer
from ..analysis.day_grouping import DayGroupingSegmenter
from ..analysis.entity_extraction import EntityExtractor
from ..analysis.entity_dictionary import get_entity_dictionary
from ..analysis.instruction_manager import InstructionManager
from ..analysis.markdown_renderer import MarkdownRenderer
from ..analysis.semantic_regrouper import SemanticRegrouper
from ..analysis.session_clustering import SessionClusterer
from ..analysis.session_segmentation import SessionSegmenter
from ..analysis.session_summarizer import SessionSummarizer
from ..analysis.time_processor import TimeProcessor
from ..utils.naming import slugify
from ..utils.url_validator import validate_embedding_text
from .lmstudio_client import LMStudioEmbeddingClient

logger = logging.getLogger(__name__)

MIN_SESSION_MESSAGES = 15


class TwoLevelIndexer:
    """–î–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è: L1 (sessions —Å —Å–∞–º–º–∞—Ä–∏) –∏ L2 (messages —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º)."""

    def __init__(
        self,
        artifacts_path: str = "./artifacts",
        embedding_client: Optional[LMStudioEmbeddingClient] = None,
        enable_quality_check: bool = True,
        enable_iterative_refinement: bool = True,
        min_quality_score: float = 80.0,
        enable_clustering: bool = True,
        clustering_threshold: float = 0.8,
        min_cluster_size: int = 2,
        max_messages_per_group: int = 100,
        max_session_hours: int = 6,
        gap_minutes: int = 60,
        enable_smart_aggregation: bool = False,
        aggregation_strategy: str = "smart",
        now_window_hours: int = 24,
        fresh_window_days: int = 14,
        recent_window_days: int = 30,
        strategy_threshold: int = 1000,
        force: bool = False,
        enable_entity_learning: bool = True,
        enable_time_analysis: bool = True,
        graph: Optional[Any] = None,
        progress_callback: Optional[Callable[[str, str, Dict[str, Any]], None]] = None,
        enable_message_grouping: bool = True,
        message_grouping_strategy: str = "session",
        min_group_size: int = 3,
        max_group_size: int = 50,
        max_group_tokens: int = 8000,
    ):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.

        Args:
            artifacts_path: –ö–∞—Ç–∞–ª–æ–≥ —Å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º–∏ (reports, –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã, –∫–æ–ª–ª–µ–∫—Ü–∏–∏)
            embedding_client: –ö–ª–∏–µ–Ω—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (LM Studio)
            enable_quality_check: –í–∫–ª—é—á–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
            enable_iterative_refinement: –í–∫–ª—é—á–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ
            min_quality_score: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–∏–µ–º–ª–µ–º—ã–π –±–∞–ª–ª –∫–∞—á–µ—Å—Ç–≤–∞
            enable_clustering: –í–∫–ª—é—á–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é —Å–µ—Å—Å–∏–π
            clustering_threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
            min_cluster_size: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞
            max_messages_per_group: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –≥—Ä—É–ø–ø–µ
            max_session_hours: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ—Å—Å–∏–∏ –≤ —á–∞—Å–∞—Ö
            gap_minutes: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑—Ä—ã–≤ –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ –≤ –º–∏–Ω—É—Ç–∞—Ö
            enable_smart_aggregation: –í–∫–ª—é—á–∏—Ç—å —É–º–Ω—É—é –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É —Å —Å–∫–æ–ª—å–∑—è—â–∏–º–∏ –æ–∫–Ω–∞–º–∏
            aggregation_strategy: –°—Ç—Ä–∞—Ç–µ–≥–∏—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ (smart/channel/legacy)
            now_window_hours: –†–∞–∑–º–µ—Ä NOW –æ–∫–Ω–∞ –≤ —á–∞—Å–∞—Ö
            fresh_window_days: –†–∞–∑–º–µ—Ä FRESH –æ–∫–Ω–∞ –≤ –¥–Ω—è—Ö
            recent_window_days: –†–∞–∑–º–µ—Ä RECENT –æ–∫–Ω–∞ –≤ –¥–Ω—è—Ö
            strategy_threshold: –ü–æ—Ä–æ–≥ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏
            force: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
            enable_entity_learning: –í–∫–ª—é—á–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä–µ–π —Å—É—â–Ω–æ—Å—Ç–µ–π
            enable_time_analysis: –í–∫–ª—é—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            graph: –ì—Ä–∞—Ñ –ø–∞–º—è—Ç–∏ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∑–∞–ø–∏—Å–µ–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            progress_callback: Callback —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (job_id, event, data)
            enable_message_grouping: –í–∫–ª—é—á–∏—Ç—å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            message_grouping_strategy: –°—Ç—Ä–∞—Ç–µ–≥–∏—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ ("session"/"semantic"/"adaptive")
            min_group_size: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≥—Ä—É–ø–ø—ã —Å–æ–æ–±—â–µ–Ω–∏–π
            max_group_size: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≥—Ä—É–ø–ø—ã —Å–æ–æ–±—â–µ–Ω–∏–π
            max_group_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –≥—Ä—É–ø–ø–µ
        """
        self.progress_callback = progress_callback
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º embedding_client –ü–ï–†–ï–î –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
        self.artifacts_path = Path(artifacts_path).expanduser()
        self.artifacts_path.mkdir(parents=True, exist_ok=True)
        self.reports_path = self.artifacts_path / "reports"
        self.reports_path.mkdir(parents=True, exist_ok=True)
        self.embedding_client = embedding_client or LMStudioEmbeddingClient()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Qdrant –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
        from ..config import get_settings
        settings = get_settings()
        qdrant_url = settings.get_qdrant_url()
        if qdrant_url:
            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            embedding_dimension = self.embedding_client.dimension if self.embedding_client else 1024
            self.qdrant_manager = QdrantCollectionsManager(url=qdrant_url, vector_size=embedding_dimension)
            if not self.qdrant_manager.available():
                logger.warning("Qdrant –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –Ω–µ –±—É–¥—É—Ç —Å–æ–∑–¥–∞–Ω—ã")
                self.qdrant_manager = None
        else:
            logger.warning("QDRANT_URL –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –Ω–µ –±—É–¥—É—Ç —Å–æ–∑–¥–∞–Ω—ã")
            self.qdrant_manager = None
        
        # Qdrant –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞

        self.enable_clustering = enable_clustering
        self.clustering_threshold = clustering_threshold
        self.min_cluster_size = min_cluster_size
        self.max_messages_per_group = max_messages_per_group
        self.max_session_hours = max_session_hours
        self.gap_minutes = gap_minutes
        self.enable_smart_aggregation = enable_smart_aggregation
        self.aggregation_strategy = aggregation_strategy
        self.now_window_hours = now_window_hours
        self.fresh_window_days = fresh_window_days
        self.recent_window_days = recent_window_days
        self.strategy_threshold = strategy_threshold
        self.force = force
        self.enable_entity_learning = enable_entity_learning
        self.enable_time_analysis = enable_time_analysis
        self.enable_message_grouping = enable_message_grouping
        self.message_grouping_strategy = message_grouping_strategy
        self.min_group_size = min_group_size
        self.max_group_size = max_group_size
        self.max_group_tokens = max_group_tokens

        self.session_segmenter = SessionSegmenter(
            gap_minutes=gap_minutes,
            max_session_hours=max_session_hours,
            enable_time_analysis=enable_time_analysis,
        )
        self.day_grouping_segmenter = DayGroupingSegmenter(
            max_messages_per_group=max_messages_per_group,
        )

        self.instruction_manager = InstructionManager()
        self.session_summarizer = SessionSummarizer(
            self.embedding_client,
            self.reports_path,
            instruction_manager=self.instruction_manager,
            enable_quality_check=enable_quality_check,
            enable_iterative_refinement=enable_iterative_refinement,
            min_quality_score=min_quality_score,
        )

        self.entity_extractor = EntityExtractor(
            enable_learning=enable_entity_learning,
            enable_natasha=True,
            enable_llm_validation=True,
        )
        
        self.time_processor = TimeProcessor() if enable_time_analysis else None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä—å —Å—É—â–Ω–æ—Å—Ç–µ–π —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –∏–∑ config
        if enable_entity_learning:
            from ..config import get_settings
            settings = get_settings()
            self.entity_dictionary = get_entity_dictionary(
                enable_llm_validation=True,
                enable_description_generation=settings.entity_description_enabled,
                graph=graph,
            )
        else:
            self.entity_dictionary = None
        
        self.markdown_renderer = MarkdownRenderer(self.reports_path)

        self.session_clusterer = None
        self.cluster_summarizer = None
        self.sessions_collection = None
        self.messages_collection = None
        self.tasks_collection = None
        self.clusters_collection = None
        self.progress_collection = None

        self._initialize_collections()

        if self.enable_clustering:
            self.session_clusterer = SessionClusterer(
                similarity_threshold=self.clustering_threshold,
                min_cluster_size=self.min_cluster_size,
                use_hdbscan=False,
            )
            self.cluster_summarizer = ClusterSummarizer(
                embedding_client=self.embedding_client
            )

        if self.enable_smart_aggregation:
            from ..analysis.smart_rolling_aggregator import SmartRollingAggregator
            self.smart_aggregator = SmartRollingAggregator(
                chats_dir=Path("chats"),
                use_smart_strategy=(self.aggregation_strategy == "smart"),
            )
        else:
            self.smart_aggregator = None

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        self.semantic_regrouper = None
        self.adaptive_grouper = None
        if self.enable_message_grouping:
            if self.message_grouping_strategy == "semantic":
                self.semantic_regrouper = SemanticRegrouper(embedding_client=self.embedding_client)
            elif self.message_grouping_strategy == "adaptive":
                self.adaptive_grouper = AdaptiveMessageGrouper(
                    max_tokens=max_group_tokens,
                    strategy="hybrid"
                )

        self.graph = graph
        if self.graph:
            from ..memory.ingest import MemoryIngestor
            self.ingestor = MemoryIngestor(self.graph)
            logger.info("TwoLevelIndexer: –≥—Ä–∞—Ñ –ø–∞–º—è—Ç–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω, –∑–∞–ø–∏—Å–∏ –±—É–¥—É—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è")
        else:
            self.ingestor = None
            logger.debug("TwoLevelIndexer: –≥—Ä–∞—Ñ –ø–∞–º—è—Ç–∏ –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω, –∑–∞–ø–∏—Å–∏ –±—É–¥—É—Ç —Ç–æ–ª—å–∫–æ –≤ Qdrant")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º VectorStore –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ Qdrant
        from ..memory.vector_store import build_vector_store_from_env
        self.vector_store = build_vector_store_from_env()
        if self.vector_store and self.vector_store.available():
            logger.info("VectorStore (Qdrant) –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞")
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∫–æ–ª–ª–µ–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é
            if self.embedding_client:
                try:
                    dimension = self.embedding_client.dimension
                    if dimension:
                        self.vector_store.ensure_collection(dimension)
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é Qdrant: {e}")
        else:
            logger.warning("VectorStore (Qdrant) –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–µ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å")
            self.vector_store = None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º EntityVectorStore –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Å—É—â–Ω–æ—Å—Ç–µ–π
        if enable_entity_learning:
            from ..memory.vector_store import build_entity_vector_store_from_env
            self.entity_vector_store = build_entity_vector_store_from_env()
            if self.entity_vector_store:
                logger.info("EntityVectorStore –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Å—É—â–Ω–æ—Å—Ç–µ–π")
            else:
                logger.debug("EntityVectorStore –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (Qdrant –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω)")
        else:
            self.entity_vector_store = None

    def _get_embedding_dimension(self) -> Optional[int]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ –∫–ª–∏–µ–Ω—Ç–∞."""
        if not self.embedding_client:
            return None
        
        # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏–∑ –∫–ª–∏–µ–Ω—Ç–∞
        if hasattr(self.embedding_client, '_embedding_dimension') and self.embedding_client._embedding_dimension:
            return self.embedding_client._embedding_dimension
        
        # –ï—Å–ª–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –µ—â—ë –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞, –¥–µ–ª–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        try:
            import asyncio
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # –ï—Å–ª–∏ —Ü–∏–∫–ª —É–∂–µ –∑–∞–ø—É—â–µ–Ω, —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π
                import nest_asyncio
                try:
                    nest_asyncio.apply()
                except ImportError:
                    pass
            
            async def _get_dim():
                async with self.embedding_client:
                    test_embedding = await self.embedding_client.get_embedding("test")
                    return len(test_embedding) if test_embedding else None
            
            try:
                dimension = asyncio.run(_get_dim())
                if dimension:
                    self.embedding_client._embedding_dimension = dimension
                return dimension
            except RuntimeError:
                return None
        except Exception as e:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}")
            return None

    def _check_and_recreate_collection(self, collection_name: str, description: str, force_recreate: bool = False):
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é Qdrant –∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –ø—Ä–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏."""
        if not self.qdrant_manager or not self.qdrant_manager.available():
            logger.warning(f"Qdrant –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∫–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} –Ω–µ –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞")
            return None
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤ –º–µ–Ω–µ–¥–∂–µ—Ä–µ, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        expected_dimension = self._get_embedding_dimension()
        if expected_dimension and expected_dimension != self.qdrant_manager.vector_size:
            logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ Qdrant –º–µ–Ω–µ–¥–∂–µ—Ä–∞: {self.qdrant_manager.vector_size} -> {expected_dimension}")
            self.qdrant_manager.vector_size = expected_dimension
        
        # –°–æ–∑–¥–∞–µ–º/–ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é —á–µ—Ä–µ–∑ –º–µ–Ω–µ–¥–∂–µ—Ä
        if self.qdrant_manager.ensure_collection(collection_name, force_recreate=force_recreate):
            count = self.qdrant_manager.count(collection_name)
            logger.info(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è Qdrant {collection_name} –≥–æ—Ç–æ–≤–∞ ({count} –∑–∞–ø–∏—Å–µ–π)")
            return collection_name  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –≤–º–µ—Å—Ç–æ –æ–±—ä–µ–∫—Ç–∞
        else:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é Qdrant {collection_name}")
            return None

    def _initialize_collections(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–ª–ª–µ–∫—Ü–∏–∏ Qdrant —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤."""
        if not self.qdrant_manager or not self.qdrant_manager.available():
            logger.warning("Qdrant –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –Ω–µ –±—É–¥—É—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
            self.sessions_collection = None
            self.messages_collection = None
            self.tasks_collection = None
            self.clusters_collection = None
            self.progress_collection = None
            return
        
        try:
            self.sessions_collection = self._check_and_recreate_collection(
                "chat_sessions",
                "–°–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å–µ—Å—Å–∏–π –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (L1)",
                force_recreate=self.force
            )

            self.messages_collection = self._check_and_recreate_collection(
                "chat_messages",
                "–°–æ–æ–±—â–µ–Ω–∏—è —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–ª—è —É—Ç–æ—á–Ω—è—é—â–µ–≥–æ –ø–æ–∏—Å–∫–∞ (L2)",
                force_recreate=self.force
            )

            self.tasks_collection = self._check_and_recreate_collection(
                "chat_tasks",
                "Action Items –∏–∑ —Å–µ—Å—Å–∏–π",
                force_recreate=self.force
            )

            self.clusters_collection = self._check_and_recreate_collection(
                "session_clusters",
                "–¢–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∫–ª–∞—Å—Ç–µ—Ä—ã —Å–µ—Å—Å–∏–π",
                force_recreate=self.force
            )

            # indexing_progress —Ç–µ–ø–µ—Ä—å —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ SQLite —á–µ—Ä–µ–∑ IndexingJobTracker
            # Qdrant –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            self.progress_collection = None
            logger.info("–ö–æ–ª–ª–µ–∫—Ü–∏–∏ Qdrant –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–π: {e}")
            raise

    def _expand_day_groups(
        self, day_groups: List[Dict[str, Any]], chat_name: Optional[str]
    ) -> List[Dict[str, Any]]:
        """–†–∞—Å—à–∏—Ä—è–µ—Ç –¥–Ω–µ–≤–Ω—ã–µ –≥—Ä—É–ø–ø—ã –≤ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ —Å —É—á—ë—Ç–æ–º —Ä–∞–∑—Ä—ã–≤–æ–≤."""

        if not day_groups:
            return []

        sessions: List[Dict[str, Any]] = []
        chat_slug = slugify(chat_name) if chat_name else ""

        for day_index, day_group in enumerate(day_groups):
            base_id = day_group.get("session_id")
            if not base_id:
                base_id = (
                    f"{chat_slug}-D{day_index + 1:04d}"
                    if chat_slug
                    else f"D{day_index + 1:04d}"
                )

            raw_messages = day_group.get("messages", [])
            splitted = self.session_segmenter.segment_messages(raw_messages, chat_name)
            merged_segments = (
                self._merge_small_sessions(
                    splitted,
                    chat_name=chat_name,
                    min_messages=MIN_SESSION_MESSAGES,
                )
                if splitted
                else []
            )

            segments_to_use = merged_segments or splitted

            if not segments_to_use:
                session = day_group.copy()
                session["session_id"] = base_id
                session["day_group_id"] = base_id
                session["parent_session_id"] = base_id
                session["group_type"] = day_group.get("group_type", "day_grouped")
                session["chat"] = chat_name
                if chat_slug:
                    session["chat_id"] = chat_slug
                session["messages"] = session.get("messages", raw_messages)
                session["message_count"] = len(session.get("messages", []))
                
                if self.time_processor and self.enable_time_analysis:
                    try:
                        activity_patterns = self.time_processor.analyze_activity_patterns(session.get("messages", []))
                        session["activity_patterns"] = activity_patterns
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è —Å–µ—Å—Å–∏–∏ {base_id}: {e}")
                
                sessions.append(session)
                continue

            if len(segments_to_use) == 1:
                session_data = segments_to_use[0].copy()
                session_data["session_id"] = base_id
                session_data["day_group_id"] = base_id
                session_data["parent_session_id"] = base_id
                session_data["group_type"] = session_data.get("group_type") or (
                    "session_segmented"
                    if splitted
                    else day_group.get("group_type", "day_grouped")
                )
                session_data["chat"] = chat_name
                if chat_slug:
                    session_data["chat_id"] = chat_slug
                session_data["messages"] = session_data.get("messages", raw_messages)
                session_data["message_count"] = len(session_data["messages"])
                
                if self.time_processor and self.enable_time_analysis:
                    try:
                        activity_patterns = self.time_processor.analyze_activity_patterns(session_data.get("messages", []))
                        session_data["activity_patterns"] = activity_patterns
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è —Å–µ—Å—Å–∏–∏ {base_id}: {e}")
                
                sessions.append(session_data)
                continue

            for split_index, split_session in enumerate(segments_to_use):
                session_copy = split_session.copy()
                session_copy["session_id"] = f"{base_id}-S{split_index + 1:02d}"
                session_copy["day_group_id"] = base_id
                session_copy["parent_session_id"] = base_id
                session_copy["group_type"] = session_copy.get(
                    "group_type", "session_segmented"
                )
                session_copy["chat"] = chat_name
                if chat_slug:
                    session_copy["chat_id"] = chat_slug
                session_copy["messages"] = split_session.get("messages", raw_messages)
                session_copy["message_count"] = len(session_copy["messages"])
                
                if self.time_processor and self.enable_time_analysis:
                    try:
                        activity_patterns = self.time_processor.analyze_activity_patterns(session_copy.get("messages", []))
                        session_copy["activity_patterns"] = activity_patterns
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è —Å–µ—Å—Å–∏–∏ {session_copy['session_id']}: {e}")
                
                sessions.append(session_copy)

        return sessions

    def _merge_small_sessions(
        self,
        segments: List[Dict[str, Any]],
        chat_name: Optional[str],
        min_messages: int,
    ) -> List[Dict[str, Any]]:
        if not segments:
            return []

        grouped: List[List[Dict[str, Any]]] = []
        buffer: List[Dict[str, Any]] = []

        def segment_len(segment: Dict[str, Any]) -> int:
            return segment.get("message_count") or len(segment.get("messages", []))

        for segment in segments:
            count = segment_len(segment)
            if not buffer:
                buffer.append(segment)
                continue

            buffer_count = sum(segment_len(item) for item in buffer)

            # –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –º–∞–ª–µ–Ω—å–∫–∏—Ö —Å–µ—Å—Å–∏–π
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –µ—Å–ª–∏:
            # 1. –¢–µ–∫—É—â–∞—è —Å–µ—Å—Å–∏—è –º–µ–Ω—å—à–µ min_messages –ò–õ–ò
            # 2. –ë—É—Ñ–µ—Ä –º–µ–Ω—å—à–µ min_messages –ò–õ–ò
            # 3. –¢–µ–∫—É—â–∞—è —Å–µ—Å—Å–∏—è –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∞—è (‚â§3 —Å–æ–æ–±—â–µ–Ω–∏—è) –ò –±—É—Ñ–µ—Ä —Ç–æ–∂–µ –º–∞–ª–µ–Ω—å–∫–∏–π (‚â§10 —Å–æ–æ–±—â–µ–Ω–∏–π)
            should_merge = (
                count < min_messages
                or buffer_count < min_messages
                or (count <= 3 and buffer_count <= 10)
            )

            if should_merge:
                buffer.append(segment)
            else:
                grouped.append(buffer)
                buffer = [segment]

        if buffer:
            grouped.append(buffer)

        normalized: List[Dict[str, Any]] = []
        for group in grouped:
            total_messages = sum(segment_len(item) for item in group)

            if len(group) == 1 and total_messages >= min_messages:
                segment_copy = group[0].copy()
                segment_copy["group_type"] = segment_copy.get(
                    "group_type", "session_segmented"
                )
                normalized.append(segment_copy)
                continue

            if len(group) > 1:
                segment_sizes = [segment_len(item) for item in group]
                logger.info(
                    f"üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ {len(group)} –º–∞–ª–µ–Ω—å–∫–∏—Ö —Å–µ—Å—Å–∏–π "
                    f"(—Ä–∞–∑–º–µ—Ä—ã: {segment_sizes}) –≤ –æ–¥–Ω—É —Å–µ—Å—Å–∏—é —Å {total_messages} —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏"
                )

            combined_messages: List[Dict[str, Any]] = []
            for segment in group:
                combined_messages.extend(segment.get("messages", []))

            combined_messages.sort(
                key=lambda msg: self.session_segmenter._parse_message_time(msg)
            )

            raw_session = {
                "messages": combined_messages,
                "start_time": self.session_segmenter._parse_message_time(
                    combined_messages[0]
                ),
                "end_time": self.session_segmenter._parse_message_time(
                    combined_messages[-1]
                ),
                "chat": chat_name,
            }
            merged_session = self.session_segmenter._finalize_session(
                raw_session,
                len(normalized),
            )
            merged_session["group_type"] = "session_merged"
            normalized.append(merged_session)

        return normalized

    def _get_last_indexed_date(self, chat_name: str) -> Optional[datetime]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è —á–∞—Ç–∞

        Args:
            chat_name: –ù–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞

        Returns:
            –î–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–ª–∏ None
        """
        try:
            result = self.progress_collection.get(
                ids=[f"progress_{slugify(chat_name)}"], include=["metadatas"]
            )

            if result["ids"] and result["metadatas"]:
                last_date_str = result["metadatas"][0].get("last_indexed_date")
                if last_date_str:
                    from ..utils.datetime_utils import parse_datetime_utc

                    return parse_datetime_utc(last_date_str, use_zoneinfo=True)
        except Exception as e:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –¥–ª—è {chat_name}: {e}")

        return None

    def _save_indexing_progress(
        self,
        chat_name: str,
        last_message_date: datetime,
        messages_count: int,
        sessions_count: int,
    ):
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–ª—è —á–∞—Ç–∞

        Args:
            chat_name: –ù–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞
            last_message_date: –î–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
            messages_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
            sessions_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π
        """
        try:
            progress_id = f"progress_{slugify(chat_name)}"
            now = datetime.now(ZoneInfo("UTC"))

            last_date_iso = last_message_date.isoformat()
            now_iso = now.isoformat()

            metadata = {
                "chat_name": chat_name,
                "last_indexed_date": last_date_iso,
                "last_indexing_time": now_iso,
                "total_messages": messages_count,
                "total_sessions": sessions_count,
            }

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Å—Ç–æ–π —ç–º–±–µ–¥–¥–∏–Ω–≥ (–Ω–µ –Ω—É–∂–µ–Ω –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö)
            dummy_embedding = [0.0] * 1024  # BGE-M3 —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å

            self.progress_collection.upsert(
                ids=[progress_id],
                documents=[f"Progress for {chat_name}"],
                embeddings=[dummy_embedding],
                metadatas=[metadata],
            )

            logger.info(
                f"–°–æ—Ö—Ä–∞–Ω—ë–Ω –ø—Ä–æ–≥—Ä–µ—Å—Å –¥–ª—è {chat_name}: "
                f"–ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ {last_date_iso}, "
                f"–≤—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π {messages_count}, —Å–µ—Å—Å–∏–π {sessions_count}"
            )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –¥–ª—è {chat_name}: {e}")

    def _parse_session_start_time(self, session: Dict[str, Any]) -> datetime:
        """
        –ü–∞—Ä—Å–∏—Ç –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ —Å–µ—Å—Å–∏–∏ –¥–ª—è —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—â—É—é —É—Ç–∏–ª–∏—Ç—É).

        Args:
            session: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ —Å–µ—Å—Å–∏–∏

        Returns:
            datetime: –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ —Å–µ—Å—Å–∏–∏ –∏–ª–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
        """
        from ..utils.datetime_utils import parse_datetime_utc

        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞—á–∞–ª–∞
        start_time = session.get("start_time")
        if start_time:
            if isinstance(start_time, str):
                result = parse_datetime_utc(start_time, use_zoneinfo=True)
                if result:
                    return result
            elif isinstance(start_time, datetime):
                return start_time

        # –ï—Å–ª–∏ –Ω–µ—Ç start_time, –±–µ—Ä–µ–º –≤—Ä–µ–º—è –ø–µ—Ä–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        messages = session.get("messages", [])
        if messages:
            first_message = messages[0]
            msg_date = first_message.get("date_utc")
            if msg_date:
                result = parse_datetime_utc(msg_date, use_zoneinfo=True)
                if result:
                    return result

        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–∞—Ç—É
        return datetime.min.replace(tzinfo=None)

    def _call_progress_callback(
        self, job_id: Optional[str], event: str, data: Dict[str, Any]
    ) -> None:
        """–í—ã–∑–≤–∞—Ç—å callback –ø—Ä–æ–≥—Ä–µ—Å—Å–∞, –µ—Å–ª–∏ –æ–Ω —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω."""
        if self.progress_callback and job_id:
            try:
                self.progress_callback(job_id, event, data)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ progress_callback: {e}")

    async def build_index(
        self,
        scope: str = "all",
        chat: Optional[str] = None,
        force_full: bool = False,
        recent_days: int = 7,
        adapter: Optional[Any] = None,  # MemoryServiceAdapter, –Ω–æ –∏–∑–±–µ–≥–∞–µ–º —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞
        job_id: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞

        Args:
            scope: "all" –∏–ª–∏ "chat"
            chat: –ù–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞ (–¥–ª—è scope="chat")
            force_full: –ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ—Å–±–æ—Ä–∫–∞
            recent_days: –ü–µ—Ä–µ—Å–∞–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π
            adapter: –ê–¥–∞–ø—Ç–µ—Ä –ø–∞–º—è—Ç–∏ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
            job_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–¥–∞—á–∏ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        """
        logger.info(
            f"–ù–∞—á–∞–ª–æ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: scope={scope}, chat={chat}, force_full={force_full}"
        )
        if scope == "chat" and chat:
            logger.info(f"üéØ –†–µ–∂–∏–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –æ–¥–Ω–æ–≥–æ —á–∞—Ç–∞: '{chat}'")
        elif scope == "all":
            logger.info("üåê –†–µ–∂–∏–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≤—Å–µ—Ö —á–∞—Ç–æ–≤")
        else:
            logger.warning(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π scope={scope}, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω —Ä–µ–∂–∏–º 'all'")

        stats = {
            "indexed_chats": [],
            "sessions_indexed": 0,
            "messages_indexed": 0,
            "tasks_indexed": 0,
        }

        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —á–∞—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        chats_path = Path("chats")
        if scope == "chat" and chat:
            chat_dir = chats_path / chat
            if not chat_dir.exists() or not chat_dir.is_dir():
                logger.error(f"‚ùå –ß–∞—Ç '{chat}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ {chats_path}")
                return {
                    "indexed_chats": [],
                    "sessions_indexed": 0,
                    "messages_indexed": 0,
                    "tasks_indexed": 0,
                    "error": f"–ß–∞—Ç '{chat}' –Ω–µ –Ω–∞–π–¥–µ–Ω",
                }
            chat_dirs = [chat_dir]
        else:
            chat_dirs = [d for d in chats_path.iterdir() if d.is_dir()]

        # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —á–∞—Ç
        total_chats = len(chat_dirs)
        for chat_idx, chat_dir in enumerate(chat_dirs, 1):
            try:
                chat_name = chat_dir.name
                logger.info(f"üìÅ –ß–∞—Ç {chat_idx}/{total_chats}: {chat_name}")
                
                # Callback: –Ω–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞—Ç–∞
                self._call_progress_callback(
                    job_id,
                    "chat_started",
                    {
                        "chat": chat_name,
                        "chat_index": chat_idx,
                        "total_chats": total_chats,
                    },
                )

                # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –ø–æ–ª–Ω–æ–π –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
                if force_full and adapter is not None:
                    logger.info(f"üßπ –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö —á–∞—Ç–∞ {chat_name} –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–µ–π...")
                    try:
                        cleanup_stats = adapter.clear_chat_data(chat_name)
                        logger.info(
                            f"‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: "
                            f"—É–∑–ª–æ–≤={cleanup_stats.get('nodes_deleted', 0)}, "
                            f"–≤–µ–∫—Ç–æ—Ä–æ–≤={cleanup_stats.get('vectors_deleted', 0)}, "
                            f"Qdrant={cleanup_stats.get('qdrant_deleted', 0)}"
                        )
                    except Exception as e:
                        logger.warning(
                            f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö —á–∞—Ç–∞ {chat_name}: {e}. "
                            f"–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é...",
                            exc_info=True,
                        )

                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ JSON —Ñ–∞–π–ª–æ–≤
                messages = await self._load_messages_from_chat(chat_dir)

                if not messages:
                    logger.warning(f"–ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —á–∞—Ç–µ {chat_name}")
                    continue

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å
                if not force_full:
                    # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è: –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                    last_indexed_date = self._get_last_indexed_date(chat_name)

                    if last_indexed_date:
                        # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–æ–≤–µ–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ
                        messages_to_index = [
                            m
                            for m in messages
                            if self._parse_message_time(m) > last_indexed_date
                        ]
                        logger.info(
                            f"üìä –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è: –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ "
                            f"—Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {last_indexed_date.strftime('%Y-%m-%d %H:%M:%S')}"
                        )
                    else:
                        # –ü–µ—Ä–≤–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —á–∞—Ç–∞ - –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –≤—Å–µ –∏–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π
                        if recent_days > 0:
                            recent_cutoff = datetime.now(ZoneInfo("UTC")) - timedelta(
                                days=recent_days
                            )
                            messages_to_index = [
                                m
                                for m in messages
                                if self._parse_message_time(m) >= recent_cutoff
                            ]
                            logger.info(
                                f"üìä –ü–µ—Ä–≤–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ {recent_days} –¥–Ω–µ–π"
                            )
                        else:
                            messages_to_index = messages
                            logger.info(
                                "üìä –ü–µ—Ä–≤–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è"
                            )
                else:
                    messages_to_index = messages
                    logger.info("üìä –ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è")

                logger.info(
                    f"–°–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {len(messages_to_index)} –∏–∑ {len(messages)}"
                )

                # –í—ã–±–∏—Ä–∞–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
                if self.enable_smart_aggregation and self.smart_aggregator:
                    logger.info("üß† –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω—É—é –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É —Å —Å–∫–æ–ª—å–∑—è—â–∏–º–∏ –æ–∫–Ω–∞–º–∏")
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω—É—é –∞–≥—Ä–µ–≥–∞—Ü–∏—é
                    try:
                        aggregation_result = await self.smart_aggregator.aggregate_chat(
                            chat_name, dry_run=False
                        )
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç - —Å–ª–æ–≤–∞—Ä—å
                        if isinstance(aggregation_result, dict):
                            sessions = aggregation_result.get("sessions", [])
                        else:
                            logger.error(
                                f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏: {type(aggregation_result)}"
                            )
                            sessions = []
                        logger.info(f"–£–º–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è —Å–æ–∑–¥–∞–ª–∞ {len(sessions)} —Å–µ—Å—Å–∏–π")
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–º–Ω–æ–π –∞–≥—Ä–µ–≥–∞—Ü–∏–∏: {e}", exc_info=True)
                        # Fallback –Ω–∞ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫—É—é –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É
                        logger.info("–ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫—É—é –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É")
                        sessions = self._group_messages_by_smart_strategy(
                            messages_to_index, chat_name
                        )
                        logger.info(f"–°–æ–∑–¥–∞–Ω–æ {len(sessions)} —Å–µ—Å—Å–∏–π —Å —É–º–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π")
                else:
                    logger.info("üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª–∞—Å—Å–∏—á–µ—Å–∫—É—é –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É")
                    # –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Å —É–º–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π –æ–∫–æ–Ω
                    sessions = self._group_messages_by_smart_strategy(
                        messages_to_index, chat_name
                    )
                    logger.info(f"–°–æ–∑–¥–∞–Ω–æ {len(sessions)} —Å–µ—Å—Å–∏–π —Å —É–º–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π")

                # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π
                existing_session_ids = set()
                existing_summaries = []
                if not force_full:
                    try:
                        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ session_id –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —á–∞—Ç–∞
                        result = None
                        if self.qdrant_manager and self.sessions_collection:
                            result = self.qdrant_manager.get(
                                collection_name=self.sessions_collection,
                                where={"chat": chat_name}
                            )
                        if result and result.get("ids"):
                            existing_session_ids = set(result["ids"])
                            logger.info(
                                f"üìã –ù–∞–π–¥–µ–Ω–æ {len(existing_session_ids)} —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π"
                            )

                            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –∏–∑ JSON —Ñ–∞–π–ª–æ–≤
                            reports_dir = self.reports_path
                            chat_slug = slugify(chat_name)
                            sessions_dir = reports_dir / chat_slug / "sessions"

                            if sessions_dir.exists():
                                import json

                                for session_id in existing_session_ids:
                                    json_file = sessions_dir / f"{session_id}.json"
                                    if json_file.exists():
                                        try:
                                            with open(json_file, encoding="utf-8") as f:
                                                summary = json.load(f)
                                                existing_summaries.append(summary)
                                        except Exception as e:
                                            logger.debug(
                                                f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {json_file}: {e}"
                                            )
                    except Exception as e:
                        logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–µ—Å—Å–∏–∏: {e}")

                # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–µ—Å—Å–∏–∏ —Å–Ω–∞—á–∞–ª–∞ –ø–æ —Ç–∏–ø—É –æ–∫–Ω–∞, –∑–∞—Ç–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞—á–∞–ª–∞
                # –ü–æ—Ä—è–¥–æ–∫: old -> recent -> fresh -> now –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                window_priority = {"old": 0, "recent": 1, "fresh": 2, "now": 3}

                def sort_key(session):
                    window = session.get("window", "unknown")
                    priority = window_priority.get(
                        window, 999
                    )  # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –æ–∫–Ω–∞ –≤ –∫–æ–Ω–µ—Ü
                    start_time = self._parse_session_start_time(session)
                    return (priority, start_time)

                sessions_sorted = sorted(sessions, key=sort_key)
                logger.info(
                    "üìÖ –°–µ—Å—Å–∏–∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ —Ç–∏–ø—É –æ–∫–Ω–∞ –∏ –≤—Ä–µ–º–µ–Ω–∏ (old -> recent -> fresh -> now)"
                )

                # –°–∞–º–º–∞—Ä–∏–∑–∏—Ä—É–µ–º –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —Å–µ—Å—Å–∏—é –≤ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –ø–æ—Ä—è–¥–∫–µ
                processed_summaries = []
                total_messages_in_chat = len(messages)
                processed_messages_count = 0
                skipped_sessions = 0

                for session_idx, session in enumerate(sessions_sorted, 1):
                    try:
                        if session is None:
                            logger.warning(
                                f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º None —Å–µ—Å—Å–∏—é –≤ –ø–æ–∑–∏—Ü–∏–∏ {session_idx}"
                            )
                            continue

                        session_id = session.get("session_id")
                        session_messages_count = len(session.get("messages", []))

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –±—ã–ª–∞ –ª–∏ —ç—Ç–∞ —Å–µ—Å—Å–∏—è —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∞
                        if session_id in existing_session_ids:
                            logger.debug(
                                f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å–µ—Å—Å–∏—é: {session_id}"
                            )
                            skipped_sessions += 1
                            processed_messages_count += session_messages_count
                            continue

                        processed_messages_count += session_messages_count

                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                        progress_pct = (
                            processed_messages_count / total_messages_in_chat
                        ) * 100
                        logger.info(
                            f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å —á–∞—Ç–∞ {chat_name}: "
                            f"{processed_messages_count}/{total_messages_in_chat} —Å–æ–æ–±—â–µ–Ω–∏–π "
                            f"({progress_pct:.1f}%) | "
                            f"–°–µ—Å—Å–∏—è {session_idx}/{len(sessions)}: {session_id}"
                        )
                        
                        # Callback: –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ—Å—Å–∏–π
                        self._call_progress_callback(
                            job_id,
                            "sessions_processing",
                            {
                                "chat": chat_name,
                                "session_index": session_idx,
                                "total_sessions": len(sessions),
                                "sessions_count": len(processed_summaries),
                                "messages_count": processed_messages_count,
                                "total_messages": total_messages_in_chat,
                                "progress_pct": progress_pct,
                            },
                        )

                        # –°–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è
                        summary = await self.session_summarizer.summarize_session(
                            session
                        )
                        processed_summaries.append(summary)

                        # L1: –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å–∞–º–º–∞—Ä–∏ —Å–µ—Å—Å–∏–∏
                        await self._index_session_l1(summary)
                        stats["sessions_indexed"] += 1

                        # L2: –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
                        messages_count = await self._index_messages_l2(session)
                        stats["messages_indexed"] += messages_count

                        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è tasks
                        tasks_count = await self._index_tasks(summary)
                        stats["tasks_indexed"] += tasks_count

                        # –†–µ–Ω–¥–µ—Ä–∏–Ω–≥ Markdown
                        self.markdown_renderer.render_session_summary(
                            summary, force=self.force
                        )
                        self.markdown_renderer.render_snippets(
                            session, force=self.force
                        )

                        # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                        await asyncio.sleep(0.5)

                    except Exception as e:
                        logger.error(
                            f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–µ—Å—Å–∏–∏ {session['session_id']}: {e}"
                        )
                        # –õ–æ–≥–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                        if "Invalid IPv6 URL" in str(e):
                            logger.error(
                                f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –æ—à–∏–±–∫–∞ IPv6 URL –≤ —Å–µ—Å—Å–∏–∏ {session['session_id']}. "
                                f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö URL."
                            )
                        continue

                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏ –Ω–æ–≤—ã–µ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è –æ—Ç—á–µ—Ç–æ–≤
                all_summaries = existing_summaries + processed_summaries

                # –°–æ–∑–¥–∞—ë–º –≥–ª–∞–≤–Ω—É—é —Å–≤–æ–¥–∫—É —á–∞—Ç–∞ –∏–∑ –≤—Å–µ—Ö —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–π
                if all_summaries:
                    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–µ—Å—Å–∏–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π –¥–ª—è —Ä–∞–∑–¥–µ–ª–∞ "–ê–∫—Ç—É–∞–ª—å–Ω–æ"
                    now = datetime.now(ZoneInfo("UTC"))
                    thirty_days_ago = now - timedelta(days=30)

                    recent_sessions = [
                        s
                        for s in all_summaries
                        if self._parse_message_time(
                            {"date_utc": s.get("meta", {}).get("end_time_utc", "")}
                        )
                        >= thirty_days_ago
                    ]

                    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–∞—á–µ—Å—Ç–≤—É (score) –¥–ª—è —Ç–æ–ø-—Å–µ—Å—Å–∏–π
                    top_sessions = sorted(
                        recent_sessions,
                        key=lambda s: s.get("quality", {}).get("score", 0),
                        reverse=True,
                    )

                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –µ—Å—Ç—å –ª–∏ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
                    has_new_data = len(processed_summaries) > 0
                    
                    self.markdown_renderer.render_chat_summary(
                        chat_name,
                        all_summaries,
                        top_sessions=top_sessions,
                        force=self.force,
                        has_new_data=has_new_data,
                    )
                    # –°–æ–∑–¥–∞—ë–º —Ñ–∞–π–ª –Ω–∞–∫–∞–ø–ª–∏–≤–∞—é—â–µ–≥–æ—Å—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                    self.markdown_renderer.render_cumulative_context(
                        chat_name, all_summaries, force=self.force, has_new_data=has_new_data
                    )
                    # –°–æ–∑–¥–∞—ë–º –∏–Ω–¥–µ–∫—Å —Å–µ—Å—Å–∏–π —á–∞—Ç–∞
                    self.markdown_renderer.render_chat_index(
                        chat_name, all_summaries, force=self.force, has_new_data=has_new_data
                    )

                    # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–π —á–∞—Ç–∞ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–æ–≤—ã–µ —Å–µ—Å—Å–∏–∏)
                    if (
                        self.enable_clustering
                        and len(processed_summaries) >= self.min_cluster_size
                    ):
                        logger.info(f"–ó–∞–ø—É—Å–∫ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è —á–∞—Ç–∞ {chat_name}")
                        try:
                            # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑—É–µ–º –≤—Å–µ —Å–µ—Å—Å–∏–∏ —á–∞—Ç–∞, –≤–∫–ª—é—á–∞—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ
                            cluster_stats = await self._cluster_chat_sessions(
                                chat_name, all_summaries
                            )
                            stats["clusters_created"] = cluster_stats.get(
                                "clusters_count", 0
                            )
                            stats["sessions_clustered"] = cluster_stats.get(
                                "sessions_clustered", 0
                            )
                            logger.info(f"–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {cluster_stats}")
                        except Exception as e:
                            logger.error(
                                f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ —á–∞—Ç–∞ {chat_name}: {e}"
                            )

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–ª—è –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π
                if messages_to_index:
                    # –ù–∞—Ö–æ–¥–∏–º –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
                    last_message_date = max(
                        self._parse_message_time(m) for m in messages_to_index
                    )
                    self._save_indexing_progress(
                        chat_name=chat_name,
                        last_message_date=last_message_date,
                        messages_count=len(messages_to_index),
                        sessions_count=len(processed_summaries),
                    )
                
                # Callback: –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞—Ç–∞
                self._call_progress_callback(
                    job_id,
                    "chat_completed",
                    {
                        "chat": chat_name,
                        "chat_index": chat_idx,
                        "total_chats": total_chats,
                        "stats": {
                            "sessions_indexed": len(processed_summaries),
                            "messages_indexed": processed_messages_count,
                            "tasks_indexed": stats.get("tasks_indexed", 0),
                        },
                    },
                )

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ª–æ–≤–∞—Ä–∏ —Å—É—â–Ω–æ—Å—Ç–µ–π –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ –æ–±—É—á–µ–Ω–∏–µ
                if self.entity_dictionary and self.enable_entity_learning:
                    try:
                        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—á–µ—Ä–µ–¥—å –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
                        self.entity_dictionary.flush_validation_queue()
                        self.entity_dictionary.save_dictionaries()
                        logger.info(f"–°–ª–æ–≤–∞—Ä–∏ —Å—É—â–Ω–æ—Å—Ç–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–ª—è —á–∞—Ç–∞ {chat_name}")
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º EntityNode –≤ –≥—Ä–∞—Ñ–µ —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏
                        if self.graph:
                            await self._update_entity_nodes_with_descriptions()
                        
                        # –°—Ç—Ä–æ–∏–º –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –ø—Ä–æ—Ñ–∏–ª–∏ —Å—É—â–Ω–æ—Å—Ç–µ–π
                        await self._build_and_index_entities(chat_name)
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–ª–æ–≤–∞—Ä–µ–π —Å—É—â–Ω–æ—Å—Ç–µ–π: {e}")

                stats["indexed_chats"].append(chat_name)

                # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —á–∞—Ç—É
                if skipped_sessions > 0:
                    logger.info(
                        f"‚úÖ –ß–∞—Ç {chat_name} –∑–∞–≤–µ—Ä—à–µ–Ω: "
                        f"{len(processed_summaries)} –Ω–æ–≤—ã—Ö —Å–µ—Å—Å–∏–π, "
                        f"{skipped_sessions} –ø—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ), "
                        f"{processed_messages_count} —Å–æ–æ–±—â–µ–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ"
                    )
                else:
                    logger.info(
                        f"‚úÖ –ß–∞—Ç {chat_name} –∑–∞–≤–µ—Ä—à–µ–Ω: "
                        f"{len(processed_summaries)} —Å–µ—Å—Å–∏–π, "
                        f"{processed_messages_count} —Å–æ–æ–±—â–µ–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ"
                    )

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —á–∞—Ç–∞ {chat_dir.name}: {e}")
                # Callback: –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —á–∞—Ç–∞
                self._call_progress_callback(
                    job_id,
                    "error",
                    {
                        "chat": chat_dir.name,
                        "error": str(e),
                    },
                )
                continue

        logger.info(f"–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {stats}")
        
        # Callback: –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –≤—Å–µ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        self._call_progress_callback(
            job_id,
            "completed",
            {
                "stats": stats,
            },
        )
        
        return stats

    async def _load_messages_from_chat(self, chat_dir: Path) -> List[Dict[str, Any]]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ JSON —Ñ–∞–π–ª–æ–≤ —á–∞—Ç–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—â—É—é —É—Ç–∏–ª–∏—Ç—É).

        Args:
            chat_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —á–∞—Ç–∞

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
        """
        from ..utils.json_loader import load_json_or_jsonl

        messages = []
        json_files = list(chat_dir.glob("*.json"))

        for json_file in json_files:
            try:
                file_messages, _ = load_json_or_jsonl(json_file)
                messages.extend(file_messages)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {json_file}: {e}")
                continue

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        messages.sort(key=lambda x: x.get("date_utc") or x.get("date", ""))

        return messages

    async def _index_session_l1(self, summary: Dict[str, Any]):
        """
        –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ L1 (—Å–∞–º–º–∞—Ä–∏ + E1)

        Args:
            summary: –°–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏
        """
        session_id = summary["session_id"]

        meta = summary.get("meta", {})

        topics_text = "\n".join(
            f"{topic.get('title', '')}: {topic.get('summary', '')}"
            for topic in summary.get("topics", [])
        )
        claims_text = "\n".join(
            claim.get("summary", "") for claim in summary.get("claims", [])
        )
        discussion_text = "\n".join(
            item.get("quote", "") for item in summary.get("discussion", [])
        )
        entities_text = ", ".join(summary.get("entities", []))

        embedding_text = (
            f"Topics:\n{topics_text}\n\n"
            f"Claims:\n{claims_text}\n\n"
            f"Discussion:\n{discussion_text}\n\n"
            f"Entities: {entities_text}"
        )

        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥
        embedding_text, replaced_urls = validate_embedding_text(embedding_text)

        # –õ–æ–≥–∏—Ä—É–µ–º –∑–∞–º–µ–Ω–µ–Ω–Ω—ã–µ URL –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        if replaced_urls:
            logger.warning(
                f"–í —Å–µ—Å—Å–∏–∏ {session_id} –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ URL: {replaced_urls}"
            )

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
        async with self.embedding_client:
            embeddings = await self.embedding_client.generate_embeddings([embedding_text])
            embedding = embeddings[0]

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            "session_id": session_id,
            "chat": meta.get("chat_name", ""),
            "profile": meta.get("profile", ""),
            "start_time_utc": meta.get("start_time_utc", ""),
            "end_time_utc": meta.get("end_time_utc", ""),
            "time_span": meta.get("time_span", ""),
            "message_count": meta.get("messages_total", 0),
            "dominant_language": meta.get("dominant_language", "unknown"),
            "chat_mode": meta.get("chat_mode", "group"),
            "topics_count": len(summary.get("topics", [])),
            "claims_count": len(summary.get("claims", [])),
            "quality_score": summary.get("quality", {}).get("score", 0),
            "replaced_urls": ",".join(replaced_urls)
            if replaced_urls
            else "",  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–º–µ–Ω–µ–Ω–Ω—ã–µ URL –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
        }

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é Qdrant
        if self.qdrant_manager and self.sessions_collection:
            try:
                self.qdrant_manager.upsert(
                    collection_name=self.sessions_collection,
                    ids=[session_id],
                    embeddings=[embedding],
                    metadatas=[metadata],
                    documents=[embedding_text],
                )
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —Å–µ—Å—Å–∏–∏ {session_id} –≤ Qdrant: {e}")
        else:
            logger.warning("Qdrant –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, —Å–µ—Å—Å–∏—è –Ω–µ –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ")
        
        # Qdrant –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ (—Å–º. –∫–æ–¥ –≤—ã—à–µ)
        try:
            pass  # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã try-except
        except Exception as e:
            error_msg = str(e)
            if "embedding with dimension" in error_msg or "dimension" in error_msg.lower():
                logger.warning(
                    f"–û—à–∏–±–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ chat_sessions: {error_msg}. "
                    "–ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º –∫–æ–ª–ª–µ–∫—Ü–∏—é..."
                )
                # –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
                if self.qdrant_manager and self.sessions_collection:
                    self.qdrant_manager.delete_collection(self.sessions_collection)
                    self.sessions_collection = self._check_and_recreate_collection(
                        "chat_sessions",
                        "–°–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å–µ—Å—Å–∏–π –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (L1)",
                        force_recreate=True
                    )
                    if self.sessions_collection:
                        self.qdrant_manager.upsert(
                            collection_name=self.sessions_collection,
                            ids=[session_id],
                            embeddings=[embedding],
                            metadatas=[metadata],
                            documents=[embedding_text],
                        )
                        logger.info("–ö–æ–ª–ª–µ–∫—Ü–∏—è chat_sessions –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞ –∏ –∑–∞–ø–∏—Å—å –¥–æ–±–∞–≤–ª–µ–Ω–∞")
            else:
                raise

        # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –≥—Ä–∞—Ñ–æ–º –ø–∞–º—è—Ç–∏
        if self.ingestor and self.graph:
            from ..indexing import MemoryRecord
            from ..utils.datetime_utils import parse_datetime_utc
            
            try:
                # –ü–∞—Ä—Å–∏–º timestamp –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                start_time_utc = meta.get("start_time_utc", "")
                timestamp = parse_datetime_utc(start_time_utc, default=None) if start_time_utc else None
                if not timestamp:
                    from datetime import datetime, timezone
                    timestamp = datetime.now(timezone.utc)
                
                # –°–æ–∑–¥–∞—ë–º —Ç–µ–≥–∏ –¥–ª—è —Å–µ—Å—Å–∏–∏
                tags = []
                chat_name = meta.get("chat_name", "")
                if chat_name:
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–º–µ–Ω–∏ —á–∞—Ç–∞
                    chat_tag = chat_name.lower().replace(" ", "_")
                    tags.append(chat_tag)
                
                # –°–æ–∑–¥–∞—ë–º MemoryRecord –¥–ª—è —Å–µ—Å—Å–∏–∏
                record = MemoryRecord(
                    record_id=session_id,
                    source=meta.get("chat_name", "unknown"),
                    content=embedding_text,
                    timestamp=timestamp,
                    author=None,  # –°–µ—Å—Å–∏–∏ –Ω–µ –∏–º–µ—é—Ç –∞–≤—Ç–æ—Ä–∞
                    tags=tags,  # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–µ–≥–∏
                    entities=summary.get("entities", []),
                    attachments=[],
                    metadata={
                        "chat": meta.get("chat_name", ""),
                        "profile": meta.get("profile", ""),
                        "start_time_utc": start_time_utc,
                        "end_time_utc": meta.get("end_time_utc", ""),
                        "time_span": meta.get("time_span", ""),
                        "message_count": meta.get("messages_total", 0),
                        "dominant_language": meta.get("dominant_language", "unknown"),
                        "chat_mode": meta.get("chat_mode", "group"),
                        "topics_count": len(summary.get("topics", [])),
                        "claims_count": len(summary.get("claims", [])),
                        "quality_score": summary.get("quality", {}).get("score", 0),
                        "session_type": "session_summary",  # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ —Å–∞–º–º–∞—Ä–∏ —Å–µ—Å—Å–∏–∏
                    },
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –≥—Ä–∞—Ñ
                self.ingestor.ingest([record])
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –≤ –≥—Ä–∞—Ñ –∏ Qdrant
                if embedding:
                    try:
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –≥—Ä–∞—Ñ
                        self.graph.update_node(
                            session_id,
                            embedding=embedding,
                        )
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Qdrant –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (–∫–æ–ª–ª–µ–∫—Ü–∏—è memory-records)
                        # –í–ê–ñ–ù–û: –≠—Ç–æ –æ—Å–Ω–æ–≤–Ω–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞, –¥–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –≤—Å–µ –∑–∞–ø–∏—Å–∏, –≤–∫–ª—é—á–∞—è —Å–µ—Å—Å–∏–∏
                        if self.vector_store and self.vector_store.available():
                            try:
                                payload_data = {
                                    "record_id": session_id,
                                    "source": meta.get("chat_name", ""),
                                    "tags": tags,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–≥–∏ –≤ Qdrant
                                    "timestamp": start_time_utc.timestamp() if start_time_utc else 0,
                                    "timestamp_iso": start_time_utc.isoformat() if start_time_utc else "",
                                    "content_preview": summary.get("context", "")[:200],
                                    "session_type": "session_summary",
                                    "chat": meta.get("chat_name", ""),
                                }
                                chat_name = meta.get("chat_name")
                                if isinstance(chat_name, str):
                                    payload_data["chat"] = chat_name
                                
                                self.vector_store.upsert(session_id, embedding, payload_data)
                                logger.debug(f"–≠–º–±–µ–¥–¥–∏–Ω–≥ —Å–µ—Å—Å–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ Qdrant (memory-records) –¥–ª—è {session_id}")
                            except Exception as e:
                                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —Å–µ—Å—Å–∏–∏ {session_id} –≤ Qdrant (memory-records): {e}")
                    except Exception as e:
                        logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —Å–µ—Å—Å–∏–∏ {session_id}: {e}")
                
                # –°–æ–∑–¥–∞–µ–º —Å–≤—è–∑–∏ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–µ—Å—Å–∏—è–º–∏ —Ç–æ–≥–æ –∂–µ —á–∞—Ç–∞
                # –ü–æ–ª—É—á–∞–µ–º –∏–º—è —á–∞—Ç–∞ –∏–∑ meta, —Å fallback –Ω–∞ chat_id –∏–∑ summary
                chat = meta.get("chat_name") or summary.get("chat_id") or ""
                self._link_session_to_previous_sessions(session_id, chat, start_time_utc)
                
                logger.debug(f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å–µ—Å—Å–∏—è {session_id} —Å –≥—Ä–∞—Ñ–æ–º –ø–∞–º—è—Ç–∏")
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Å–µ—Å—Å–∏–∏ {session_id} —Å –≥—Ä–∞—Ñ–æ–º: {e}")

        logger.info(f"L1: –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∞ —Å–µ—Å—Å–∏—è {session_id}")

    def _format_group_text(
        self,
        messages: List[Dict[str, Any]],
        max_tokens: Optional[int] = None,
    ) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –≥—Ä—É–ø–ø—É —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –µ–¥–∏–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞.

        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –≥—Ä—É–ø–ø—ã
            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≥—Ä—É–ø–ø—ã
        """
        if not messages:
            return ""

        parts = []
        total_chars = 0
        max_chars = (max_tokens * 4) if max_tokens else None  # ~4 —Å–∏–º–≤–æ–ª–∞ –Ω–∞ —Ç–æ–∫–µ–Ω

        for i, msg in enumerate(messages, 1):
            msg_text = msg.get("text", "").strip()
            if not msg_text:
                continue

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–≤—Ç–æ—Ä–∞
            author = "Unknown"
            from_field = msg.get("from") or {}
            if isinstance(from_field, dict):
                author = from_field.get("display") or from_field.get("username") or from_field.get("id") or "Unknown"
            elif isinstance(from_field, str):
                author = from_field

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
            formatted_msg = f"[MSG_{i}] {author}: {msg_text}"

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤
            if max_chars and total_chars + len(formatted_msg) > max_chars:
                # –û–±—Ä–µ–∑–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                remaining = max_chars - total_chars - len(f"[MSG_{i}] {author}: ")
                if remaining > 20:  # –ú–∏–Ω–∏–º—É–º 20 —Å–∏–º–≤–æ–ª–æ–≤
                    formatted_msg = f"[MSG_{i}] {author}: {msg_text[:remaining]}..."
                else:
                    break

            parts.append(formatted_msg)
            total_chars += len(formatted_msg)

        return "\n".join(parts)

    async def _group_messages_for_embedding(
        self,
        messages: List[Dict[str, Any]],
        session_id: str,
        chat_name: str,
    ) -> List[Dict[str, Any]]:
        """
        –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ —Å–º—ã—Å–ª—É –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.

        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
            session_id: ID —Å–µ—Å—Å–∏–∏
            chat_name: –ù–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –≥—Ä—É–ø–ø —Å–æ–æ–±—â–µ–Ω–∏–π —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        if not self.enable_message_grouping:
            # –ï—Å–ª–∏ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—É—é –≥—Ä—É–ø–ø—É
            return [
                {
                    "group_id": f"{session_id}-M{i+1:04d}",
                    "messages": [msg],
                    "message_ids": [msg.get("id") or msg.get("message_id") or f"msg_{i}"],
                    "strategy": "none",
                }
                for i, msg in enumerate(messages)
            ]

        strategy = self.message_grouping_strategy
        groups = []

        if strategy == "session":
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è "session": –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—é —Å–µ—Å—Å–∏—é –∫–∞–∫ –æ–¥–Ω—É –≥—Ä—É–ø–ø—É (–µ—Å–ª–∏ —Ä–∞–∑–º–µ—Ä –ø–æ–¥—Ö–æ–¥–∏—Ç)
            if len(messages) >= self.min_group_size and len(messages) <= self.max_group_size:
                # –í—Å—è —Å–µ—Å—Å–∏—è –∫–∞–∫ –æ–¥–Ω–∞ –≥—Ä—É–ø–ø–∞
                message_ids = [
                    msg.get("id") or msg.get("message_id") or f"msg_{i}"
                    for i, msg in enumerate(messages)
                ]
                groups.append({
                    "group_id": f"{session_id}-G001",
                    "messages": messages,
                    "message_ids": message_ids,
                    "strategy": "session",
                })
            else:
                # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø–æ–¥–≥—Ä—É–ø–ø—ã –ø–æ max_group_size
                for i in range(0, len(messages), self.max_group_size):
                    group_messages = messages[i:i + self.max_group_size]
                    if len(group_messages) >= self.min_group_size:
                        message_ids = [
                            msg.get("id") or msg.get("message_id") or f"msg_{i+j}"
                            for j, msg in enumerate(group_messages)
                        ]
                        groups.append({
                            "group_id": f"{session_id}-G{i//self.max_group_size + 1:03d}",
                            "messages": group_messages,
                            "message_ids": message_ids,
                            "strategy": "session",
                        })

        elif strategy == "semantic" and self.semantic_regrouper:
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è "semantic": —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –ø–µ—Ä–µ–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —á–µ—Ä–µ–∑ LLM
            try:
                # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –ø–µ—Ä–µ–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
                temp_sessions = [{
                    "session_id": f"{session_id}-temp",
                    "messages": messages,
                    "chat": chat_name,
                }]
                
                regrouped_sessions = await self.semantic_regrouper.regroup_sessions(
                    temp_sessions, chat_name
                )
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø–µ—Ä–µ–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ –≤ –≥—Ä—É–ø–ø—ã
                for i, regrouped_session in enumerate(regrouped_sessions, 1):
                    group_messages = regrouped_session.get("messages", [])
                    if len(group_messages) >= self.min_group_size:
                        message_ids = [
                            msg.get("id") or msg.get("message_id") or f"msg_{j}"
                            for j, msg in enumerate(group_messages)
                        ]
                        groups.append({
                            "group_id": f"{session_id}-G{i:03d}",
                            "messages": group_messages,
                            "message_ids": message_ids,
                            "strategy": "semantic",
                            "theme": regrouped_session.get("theme"),
                            "rationale": regrouped_session.get("regroup_rationale"),
                        })
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –ø–µ—Ä–µ–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é session: {e}")
                # Fallback –Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é session
                if len(messages) >= self.min_group_size:
                    message_ids = [
                        msg.get("id") or msg.get("message_id") or f"msg_{i}"
                        for i, msg in enumerate(messages)
                    ]
                    groups.append({
                        "group_id": f"{session_id}-G001",
                        "messages": messages,
                        "message_ids": message_ids,
                        "strategy": "session",
                    })

        elif strategy == "adaptive" and self.adaptive_grouper:
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è "adaptive": –∞–¥–∞–ø—Ç–∏–≤–Ω–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Å —É—á–µ—Ç–æ–º —Ä–∞–∑–º–µ—Ä–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            try:
                message_groups = self.adaptive_grouper.group_messages_adaptively(
                    messages, chat_name
                )
                
                for i, group_messages in enumerate(message_groups, 1):
                    if len(group_messages) >= self.min_group_size:
                        message_ids = [
                            msg.get("id") or msg.get("message_id") or f"msg_{j}"
                            for j, msg in enumerate(group_messages)
                        ]
                        groups.append({
                            "group_id": f"{session_id}-G{i:03d}",
                            "messages": group_messages,
                            "message_ids": message_ids,
                            "strategy": "adaptive",
                        })
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é session: {e}")
                # Fallback –Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é session
                if len(messages) >= self.min_group_size:
                    message_ids = [
                        msg.get("id") or msg.get("message_id") or f"msg_{i}"
                        for i, msg in enumerate(messages)
                    ]
                    groups.append({
                        "group_id": f"{session_id}-G001",
                        "messages": messages,
                        "message_ids": message_ids,
                        "strategy": "session",
                    })

        else:
            # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–ª–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º session
            logger.warning(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è {strategy} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º session")
            if len(messages) >= self.min_group_size:
                message_ids = [
                    msg.get("id") or msg.get("message_id") or f"msg_{i}"
                    for i, msg in enumerate(messages)
                ]
                groups.append({
                    "group_id": f"{session_id}-G001",
                    "messages": messages,
                    "message_ids": message_ids,
                    "strategy": "session",
                })

        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä—É–ø–ø—ã, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω–æ
        if not groups:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä—É–ø–ø—ã –¥–ª—è —Å–µ—Å—Å–∏–∏ {session_id}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è")
            return [
                {
                    "group_id": f"{session_id}-M{i+1:04d}",
                    "messages": [msg],
                    "message_ids": [msg.get("id") or msg.get("message_id") or f"msg_{i}"],
                    "strategy": "none",
                }
                for i, msg in enumerate(messages)
            ]

        logger.info(
            f"–°–æ–∑–¥–∞–Ω–æ {len(groups)} –≥—Ä—É–ø–ø –∏–∑ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π "
            f"–¥–ª—è —Å–µ—Å—Å–∏–∏ {session_id} (—Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {strategy})"
        )
        return groups

    async def _index_messages_l2_grouped(
        self,
        session: Dict[str, Any],
        messages: List[Dict[str, Any]],
        session_id: str,
        chat: str,
        chat_mode: str,
    ) -> int:
        """
        –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –Ω–∞ —É—Ä–æ–≤–Ω–µ L2 —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π –ø–æ —Å–º—ã—Å–ª—É.

        Args:
            session: –°–µ—Å—Å–∏—è
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
            session_id: ID —Å–µ—Å—Å–∏–∏
            chat: –ù–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞
            chat_mode: –¢–∏–ø —á–∞—Ç–∞ (channel/group)

        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        """
        indexed_count = 0
        skipped_duplicates_count = 0

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
        groups = await self._group_messages_for_embedding(messages, session_id, chat)

        groups_to_index = []

        for group in groups:
            try:
                group_id = group["group_id"]
                group_messages = group["messages"]
                message_ids = group["message_ids"]
                strategy = group.get("strategy", "session")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –≥—Ä—É–ø–ø—ã
                skipped_duplicate = False

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —ç—Ç–∞ –≥—Ä—É–ø–ø–∞ –≤ –±–∞–∑–µ
                if not self.force and self.qdrant_manager and self.messages_collection:
                    try:
                        existing_group = self.qdrant_manager.get(
                            collection_name=self.messages_collection,
                            ids=[group_id]
                        )
                        if existing_group and existing_group.get("ids"):
                            logger.debug(f"–ì—Ä—É–ø–ø–∞ {group_id} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                            skipped_duplicate = True
                    except Exception as e:
                        logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –≥—Ä—É–ø–ø—ã: {e}")

                if skipped_duplicate:
                    skipped_duplicates_count += len(group_messages)
                    continue

                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –≥—Ä—É–ø–ø—ã
                group_text = self._format_group_text(
                    group_messages,
                    max_tokens=self.max_group_tokens
                )

                if not group_text or len(group_text.strip()) < 10:
                    logger.warning(f"–ì—Ä—É–ø–ø–∞ {group_id} –ø—É—Å—Ç–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    continue

                # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥
                group_text, replaced_urls = validate_embedding_text(group_text)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                groups_to_index.append({
                    "group_id": group_id,
                    "group_text": group_text,
                    "group_messages": group_messages,
                    "message_ids": message_ids,
                    "strategy": strategy,
                    "message_count": len(group_messages),
                    "metadata": {
                        "group_id": group_id,
                        "message_ids": message_ids,
                        "message_count": len(group_messages),
                        "group_strategy": strategy,
                        "is_group_embedding": True,
                        "session_id": session_id,
                        "chat": chat,
                        "chat_mode": chat_mode,
                        "replaced_urls": ",".join(replaced_urls) if replaced_urls else "",
                        "theme": group.get("theme"),
                        "rationale": group.get("rationale"),
                    }
                })

            except Exception as e:
                logger.error(
                    f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –≥—Ä—É–ø–ø—ã {group.get('group_id', 'unknown')} "
                    f"–≤ —Å–µ—Å—Å–∏–∏ {session_id} –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}"
                )
                continue

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –±–∞—Ç—á–∞–º–∏
        if groups_to_index:
            try:
                async with self.embedding_client:
                    # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç—ã –¥–ª—è –±–∞—Ç—á–∞
                    batch_texts = [group["group_text"] for group in groups_to_index]

                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –±–∞—Ç—á–µ–º
                    embeddings = await self.embedding_client.generate_embeddings(batch_texts, batch_size=32)

                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é –±–∞—Ç—á–µ–º
                    ids = [group["group_id"] for group in groups_to_index]
                    documents = [group["group_text"] for group in groups_to_index]
                    metadatas = [group["metadata"] for group in groups_to_index]

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Qdrant –∫–æ–ª–ª–µ–∫—Ü–∏—é chat_messages
                    if self.qdrant_manager and self.messages_collection:
                        try:
                            self.qdrant_manager.upsert(
                                collection_name=self.messages_collection,
                                ids=ids,
                                embeddings=embeddings,
                                metadatas=metadatas,
                                documents=documents,
                            )
                            logger.debug(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(ids)} –≥—Ä—É–ø–ø –≤ Qdrant –∫–æ–ª–ª–µ–∫—Ü–∏—é {self.messages_collection}")
                        except Exception as e:
                            error_msg = str(e)
                            if "dimension" in error_msg.lower():
                                logger.warning(
                                    f"–û—à–∏–±–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ chat_messages: {error_msg}. "
                                    "–ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º –∫–æ–ª–ª–µ–∫—Ü–∏—é..."
                                )
                                if self.qdrant_manager:
                                    self.qdrant_manager.delete_collection(self.messages_collection)
                                    self.messages_collection = self._check_and_recreate_collection(
                                        "chat_messages",
                                        "–°–æ–æ–±—â–µ–Ω–∏—è —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–ª—è —É—Ç–æ—á–Ω—è—é—â–µ–≥–æ –ø–æ–∏—Å–∫–∞ (L2)",
                                        force_recreate=True
                                    )
                                    if self.messages_collection:
                                        self.qdrant_manager.upsert(
                                            collection_name=self.messages_collection,
                                            ids=ids,
                                            embeddings=embeddings,
                                            metadatas=metadatas,
                                            documents=documents,
                                        )
                                        logger.info("–ö–æ–ª–ª–µ–∫—Ü–∏—è chat_messages –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞ –∏ –∑–∞–ø–∏—Å–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã")
                            else:
                                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –≥—Ä—É–ø–ø –≤ Qdrant: {e}")
                    else:
                        logger.warning("Qdrant –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –≥—Ä—É–ø–ø—ã –Ω–µ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ")

                    # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –≥—Ä–∞—Ñ–æ–º –ø–∞–º—è—Ç–∏
                    if self.ingestor and self.graph:
                        logger.info(f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –≥—Ä–∞—Ñ–æ–º: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(groups_to_index)} –≥—Ä—É–ø–ø")
                        from ..indexing import MemoryRecord, Attachment
                        from ..utils.datetime_utils import parse_datetime_utc

                        records_to_ingest = []
                        for idx, group_data in enumerate(groups_to_index):
                            try:
                                group_id = group_data["group_id"]
                                group_text = group_data["group_text"]
                                metadata = group_data["metadata"]
                                embedding = embeddings[idx] if idx < len(embeddings) else None

                                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ä–µ–º—è –ø–µ—Ä–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≥—Ä—É–ø–ø—ã
                                first_msg = group_data["group_messages"][0]
                                date_utc = first_msg.get("date_utc") or first_msg.get("date", "")
                                timestamp = parse_datetime_utc(date_utc, default=None) if date_utc else None
                                if not timestamp:
                                    from datetime import datetime, timezone
                                    timestamp = datetime.now(timezone.utc)

                                # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –¥–ª—è –≥—Ä—É–ø–ø—ã
                                record = MemoryRecord(
                                    record_id=group_id,
                                    source=chat,
                                    content=group_text,
                                    timestamp=timestamp,
                                    author=None,  # –ì—Ä—É–ø–ø–∞ –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç —Ä–∞–∑–Ω—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤
                                    tags=[],
                                    entities=[],
                                    attachments=[],
                                    metadata=metadata,
                                )

                                if embedding is not None and len(embedding) > 0:
                                    records_to_ingest.append((record, embedding))

                            except Exception as e:
                                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –∑–∞–ø–∏—Å–∏ –≥—Ä—É–ø–ø—ã {group_data.get('group_id', 'unknown')}: {e}")
                                continue

                        # –ò–Ω–∂–µ—Å—Ç–∏–º –∑–∞–ø–∏—Å–∏ –≤ –≥—Ä–∞—Ñ
                        if records_to_ingest:
                            try:
                                for record, embedding in records_to_ingest:
                                    try:
                                        if hasattr(embedding, 'tolist'):
                                            embedding = embedding.tolist()
                                        elif not isinstance(embedding, list):
                                            embedding = list(embedding)

                                        self.ingestor.ingest([record], embeddings=[embedding])

                                        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ vector_store –¥–ª—è –ø–æ–∏—Å–∫–∞
                                        if self.vector_store and self.vector_store.available():
                                            payload_data = {
                                                "record_id": record.record_id,
                                                "source": record.source,
                                                "content": record.content,
                                                "timestamp": record.timestamp.isoformat() if record.timestamp else None,
                                                "tags": record.tags,
                                                "entities": record.entities,
                                                "metadata": record.metadata,
                                            }
                                            self.vector_store.upsert(record.record_id, embedding, payload_data)

                                    except Exception as e:
                                        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≥—Ä—É–ø–ø—ã {record.record_id}: {e}")
                                        continue

                                logger.info(
                                    f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(records_to_ingest)} –≥—Ä—É–ø–ø —Å –≥—Ä–∞—Ñ–æ–º –ø–∞–º—è—Ç–∏"
                                )
                            except Exception as e:
                                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –≥—Ä—É–ø–ø —Å –≥—Ä–∞—Ñ–æ–º: {e}")

                    indexed_count = sum(group["message_count"] for group in groups_to_index)

            except Exception as e:
                logger.error(
                    f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≥—Ä—É–ø–ø –≤ —Å–µ—Å—Å–∏–∏ {session_id}: {e}"
                )

        logger.info(
            f"L2 (–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞): –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {indexed_count} —Å–æ–æ–±—â–µ–Ω–∏–π "
            f"–≤ {len(groups_to_index)} –≥—Ä—É–ø–ø–∞—Ö –∏–∑ —Å–µ—Å—Å–∏–∏ {session_id} "
            f"(–ø—Ä–æ–ø—É—â–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {skipped_duplicates_count})"
        )
        return indexed_count

    async def _index_messages_l2(self, session: Dict[str, Any]) -> int:
        """
        –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –Ω–∞ —É—Ä–æ–≤–Ω–µ L2 (—Å —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏–ª–∏ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π)

        Args:
            session: –°–µ—Å—Å–∏—è

        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        """
        messages = session["messages"]
        session_id = session["session_id"]
        chat = session["chat"]

        indexed_count = 0
        skipped_duplicates_count = 0
        processed_count = 0

        # –û–ø—Ä–µ–¥–µ–ª–∏–º —Ç–∏–ø —á–∞—Ç–∞ –¥–ª—è –ø–æ–¥—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        chat_mode = self._detect_chat_mode(messages)

        # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥—Ä—É–ø–ø–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        if self.enable_message_grouping:
            return await self._index_messages_l2_grouped(session, messages, session_id, chat, chat_mode)

        # –ò–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É (–æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º)
        messages_to_index = []
        queued_count = 0

        for i, msg in enumerate(messages):
            try:
                processed_count += 1
                msg_text = msg.get("text", "").strip()
                if not msg_text or len(msg_text) < 10:
                    continue

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ Telegram –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: id -> message_id -> fallback –Ω–∞ session-based ID
                telegram_msg_id = msg.get("id") or msg.get("message_id")
                if telegram_msg_id:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–æ—Ä–º–∞—Ç: chat:telegram_msg_id –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
                    msg_id = f"{chat}:{telegram_msg_id}"
                else:
                    # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º session-based ID, –Ω–æ —Å —Ö–µ—à–µ–º —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
                    import hashlib
                    text_hash = hashlib.md5(msg_text.encode("utf-8")).hexdigest()[:8]
                    msg_id = f"{session_id}-M{i+1:04d}-{text_hash}"
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –±–∞–∑–µ
                # –í–ê–ñ–ù–û: –¥–∞–∂–µ –ø—Ä–∏ force_full –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ telegram_id, —á—Ç–æ–±—ã –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å
                # –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ä–∞–∑–Ω—ã—Ö —Å–µ—Å—Å–∏—è—Ö
                skipped_duplicate = False
                
                # –í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ telegram_id (–¥–∞–∂–µ –ø—Ä–∏ force_full)
                if telegram_msg_id:
                    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ –≥—Ä–∞—Ñ–µ –ø–∞–º—è—Ç–∏ –ø–æ —Ç–æ—á–Ω–æ–º—É ID
                    if self.graph:
                        try:
                            cursor = self.graph.conn.cursor()
                            cursor.execute("SELECT id FROM nodes WHERE id = ? LIMIT 1", (msg_id,))
                            if cursor.fetchone():
                                logger.debug(f"–î—É–±–ª–∏–∫–∞—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞–π–¥–µ–Ω –≤ –≥—Ä–∞—Ñ–µ –ø–æ msg_id={msg_id}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                                skipped_duplicate = True
                        except Exception as e:
                            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –≥—Ä–∞—Ñ–µ: {e}")
                    
                    # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ –≥—Ä–∞—Ñ–µ –ø–æ telegram_id –≥–ª–æ–±–∞–ª—å–Ω–æ (–≤ –ª—é–±–æ–º —á–∞—Ç–µ)
                    if not skipped_duplicate and self.graph:
                        try:
                            cursor = self.graph.conn.cursor()
                            cursor.execute("""
                                SELECT id FROM nodes 
                                WHERE type = 'DocChunk' 
                                AND properties IS NOT NULL
                                AND json_extract(properties, '$.telegram_id') = ?
                                LIMIT 1
                            """, (str(telegram_msg_id),))
                            if cursor.fetchone():
                                logger.debug(f"–î—É–±–ª–∏–∫–∞—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞–π–¥–µ–Ω –≤ –≥—Ä–∞—Ñ–µ –ø–æ telegram_id={telegram_msg_id}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                                skipped_duplicate = True
                        except Exception as e:
                            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –≥—Ä–∞—Ñ–µ –ø–æ telegram_id: {e}")
                    
                    # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ telegram ID –≤ Qdrant (–∫–æ–ª–ª–µ–∫—Ü–∏—è chat_messages)
                    if not skipped_duplicate and self.qdrant_manager and self.messages_collection:
                        try:
                            existing_by_id = self.qdrant_manager.get(
                                collection_name=self.messages_collection,
                                where={"$or": [
                                    {"msg_id": {"$eq": f"{chat}:{telegram_msg_id}"}},
                                    {"telegram_id": {"$eq": str(telegram_msg_id)}},
                                ]},
                                limit=1
                            )
                            if existing_by_id and existing_by_id.get("ids"):
                                logger.debug(f"–î—É–±–ª–∏–∫–∞—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞–π–¥–µ–Ω –≤ chat_messages –ø–æ telegram_id={telegram_msg_id}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                                skipped_duplicate = True
                        except Exception as e:
                            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ chat_messages –ø–æ telegram_id: {e}")
                    
                    # 4. –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏ memory-records (–¥–ª—è –ø–æ–∏—Å–∫–∞)
                    if not skipped_duplicate and self.vector_store and self.vector_store.available():
                        try:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∑–∞–ø–∏—Å—å —Å —Ç–∞–∫–∏–º telegram_id –≤ payload
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–∏—Å–∫ –ø–æ —Ñ–∏–ª—å—Ç—Ä—É (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è) –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ get
                            # –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –ø–æ record_id (msg_id)
                            # TODO: –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –ø–æ telegram_id –≤ payload, –µ—Å–ª–∏ Qdrant –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é
                            pass  # –ü–æ–∫–∞ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º, —Ç–∞–∫ –∫–∞–∫ vector_store –Ω–µ –∏–º–µ–µ—Ç –º–µ—Ç–æ–¥–∞ get —Å —Ñ–∏–ª—å—Ç—Ä–æ–º
                        except Exception as e:
                            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ memory-records: {e}")
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ content_hash (–¥–∞–∂–µ –ø—Ä–∏ force_full)
                if not skipped_duplicate:
                    import hashlib
                    content_hash = hashlib.md5(msg_text.encode("utf-8")).hexdigest()[:16]
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ –≥—Ä–∞—Ñ–µ –ø–∞–º—è—Ç–∏ –ø–æ content_hash –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                    if self.graph:
                        try:
                            cursor = self.graph.conn.cursor()
                            cursor.execute("""
                                SELECT id FROM nodes 
                                WHERE type = 'DocChunk' 
                                AND properties IS NOT NULL
                                AND json_extract(properties, '$.content_hash') = ?
                                AND (
                                    json_extract(properties, '$.chat') = ?
                                    OR json_extract(properties, '$.source') = ?
                                )
                                LIMIT 1
                            """, (content_hash, chat, chat))
                            if cursor.fetchone():
                                logger.debug(f"–î—É–±–ª–∏–∫–∞—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞–π–¥–µ–Ω –≤ –≥—Ä–∞—Ñ–µ –ø–æ content_hash={content_hash} –≤ —á–∞—Ç–µ {chat}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                                skipped_duplicate = True
                        except Exception as e:
                            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –≥—Ä–∞—Ñ–µ –ø–æ content_hash: {e}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ Qdrant
                    if not skipped_duplicate and self.qdrant_manager and self.messages_collection:
                        try:
                            existing_by_hash = self.qdrant_manager.get(
                                collection_name=self.messages_collection,
                                where={"content_hash": {"$eq": content_hash}},
                                limit=1
                            )
                            if existing_by_hash and existing_by_hash.get("ids"):
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Ç–æ –∂–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (–∏–∑ —Ç–æ–≥–æ –∂–µ —á–∞—Ç–∞)
                                existing_metadata = existing_by_hash.get("metadatas", [])
                                if existing_metadata and len(existing_metadata) > 0:
                                    existing_chat = existing_metadata[0].get("chat", "")
                                    if existing_chat == chat:
                                        logger.debug(f"–î—É–±–ª–∏–∫–∞—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞–π–¥–µ–Ω –ø–æ content_hash={content_hash} –≤ —á–∞—Ç–µ {chat}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                                        skipped_duplicate = True
                        except Exception as e:
                            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ content_hash: {e}")
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Ç–æ—á–Ω–æ–º—É ID (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ force_full)
                # –í–ê–ñ–ù–û: –¥–∞–∂–µ –ø—Ä–∏ force_full –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ telegram_id –∏ content_hash
                # —á—Ç–æ–±—ã –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ä–∞–∑–Ω—ã—Ö —Å–µ—Å—Å–∏—è—Ö
                if not self.force and not skipped_duplicate and self.qdrant_manager and self.messages_collection:
                    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ —Ç–æ—á–Ω–æ–º—É ID
                    existing_msg = self.qdrant_manager.get(
                        collection_name=self.messages_collection,
                        ids=[msg_id]
                    )
                    if existing_msg and existing_msg.get("ids"):
                        # –°–æ–æ–±—â–µ–Ω–∏–µ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                        logger.debug(f"–°–æ–æ–±—â–µ–Ω–∏–µ {msg_id} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                        skipped_duplicate = True
                
                # –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ telegram_id –∏ content_hash (–≤—Å–µ–≥–¥–∞, –¥–∞–∂–µ –ø—Ä–∏ force_full)
                # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ, –∫–æ–≥–¥–∞ –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ø–∞–¥–∞–µ—Ç –≤ —Ä–∞–∑–Ω—ã–µ —Å–µ—Å—Å–∏–∏
                if not skipped_duplicate:
                    import hashlib
                    content_hash = hashlib.md5(msg_text.encode("utf-8")).hexdigest()[:16]
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ –≥—Ä–∞—Ñ–µ –ø–æ content_hash –≥–ª–æ–±–∞–ª—å–Ω–æ (–≤ –ª—é–±–æ–º —á–∞—Ç–µ)
                    if self.graph:
                        try:
                            cursor = self.graph.conn.cursor()
                            cursor.execute("""
                                SELECT id FROM nodes 
                                WHERE type = 'DocChunk' 
                                AND properties IS NOT NULL
                                AND json_extract(properties, '$.content_hash') = ?
                                LIMIT 1
                            """, (content_hash,))
                            if cursor.fetchone():
                                logger.debug(f"–î—É–±–ª–∏–∫–∞—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞–π–¥–µ–Ω –≤ –≥—Ä–∞—Ñ–µ –ø–æ content_hash={content_hash}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                                skipped_duplicate = True
                        except Exception as e:
                            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –≥—Ä–∞—Ñ–µ –ø–æ content_hash: {e}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ Qdrant –∫–æ–ª–ª–µ–∫—Ü–∏–∏ chat_messages (–≥–ª–æ–±–∞–ª—å–Ω–æ –ø–æ —á–∞—Ç—É)
                    if not skipped_duplicate and self.qdrant_manager and self.messages_collection:
                        try:
                            if telegram_msg_id:
                                where_conditions = {
                                    "$and": [
                                        {"chat": {"$eq": chat}},
                                        {"$or": [
                                            {"telegram_id": {"$eq": str(telegram_msg_id)}},
                                            {"content_hash": {"$eq": content_hash}}
                                        ]}
                                    ]
                                }
                            else:
                                where_conditions = {
                                    "$and": [
                                        {"chat": {"$eq": chat}},
                                        {"content_hash": {"$eq": content_hash}}
                                    ]
                                }
                            
                            existing_by_id = self.qdrant_manager.get(
                                collection_name=self.messages_collection,
                                where=where_conditions,
                                limit=1
                            )
                            if existing_by_id and existing_by_id.get("ids"):
                                logger.debug(f"–î—É–±–ª–∏–∫–∞—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞–π–¥–µ–Ω –≤ chat_messages –ø–æ telegram_id={telegram_msg_id} –∏–ª–∏ content_hash={content_hash} –≤ —á–∞—Ç–µ {chat}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                                skipped_duplicate = True
                        except Exception as e:
                            # –ï—Å–ª–∏ –ø–æ–∏—Å–∫ –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
                            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ chat_messages: {e}")
                
                if skipped_duplicate:
                    skipped_duplicates_count += 1
                    continue

                # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–¥–æ 10 —Å–æ–æ–±—â–µ–Ω–∏–π, ‚â§ 1500 —Å–∏–º–≤–æ–ª–æ–≤)
                # –í –∫–∞–Ω–∞–ª–∞—Ö —Å–æ—Å–µ–¥–Ω–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç –º–µ–Ω–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω ‚Äî —É–º–µ–Ω—å—à–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                context_text = self._build_symmetric_context(
                    messages,
                    i,
                    max_messages=(3 if chat_mode == "channel" else 10),
                    max_chars=(500 if chat_mode == "channel" else 1500),
                )

                # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç + –∫–æ–Ω—Ç–µ–∫—Å—Ç
                embedding_text = f"{context_text}\n[CURRENT]: {msg_text}"

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –æ–±—Ä–µ–∑–∞–µ–º —Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –æ–Ω –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤
                # –û—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤: –ø—Ä–∏–º–µ—Ä–Ω–æ 4 —Å–∏–º–≤–æ–ª–∞ = 1 —Ç–æ–∫–µ–Ω
                estimated_tokens = len(embedding_text) // 4
                max_tokens = 131072  # –î–ª—è gpt-oss-20b (–º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ª–∏–º–∏—Ç)

                if estimated_tokens > max_tokens:
                    # –°–Ω–∞—á–∞–ª–∞ –æ–±—Ä–µ–∑–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –æ–Ω —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π
                    max_context_chars = (
                        2000  # –£–º–µ–Ω—å—à–∞–µ–º –¥–æ 2000 —Å–∏–º–≤–æ–ª–æ–≤ (~500 —Ç–æ–∫–µ–Ω–æ–≤) –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ª–∏–º–∏—Ç—É 8192
                    )
                    if len(context_text) > max_context_chars:
                        context_text = context_text[:max_context_chars] + "..."

                    # –ó–∞—Ç–µ–º –æ–±—Ä–µ–∑–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                    # –£—á–∏—Ç—ã–≤–∞–µ–º –¥–ª–∏–Ω—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ + "[CURRENT]: " (~3 —Ç–æ–∫–µ–Ω–∞)
                    remaining_chars = (max_tokens - len(context_text) // 4 - 3) * 4
                    if remaining_chars > 0:
                        msg_text = msg_text[:remaining_chars] + "..."
                        embedding_text = f"{context_text}\n[CURRENT]: {msg_text}"
                    else:
                        # –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç —É–∂–µ –∑–∞–Ω–∏–º–∞–µ—Ç –ø–æ—á—Ç–∏ –≤–µ—Å—å –ª–∏–º–∏—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–µ
                        msg_text = msg_text[: max_tokens * 4 - 10] + "..."
                        embedding_text = f"[CURRENT]: {msg_text}"

                    final_tokens = len(embedding_text) // 4
                    original_tokens = estimated_tokens
                    logger.warning(
                        f"–¢–µ–∫—Å—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –æ–±—Ä–µ–∑–∞–Ω –¥–æ ~{final_tokens} —Ç–æ–∫–µ–Ω–æ–≤ "
                        f"(–∏—Å—Ö–æ–¥–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: ~{original_tokens} —Ç–æ–∫–µ–Ω–æ–≤)"
                    )

                # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥
                embedding_text, replaced_urls = validate_embedding_text(embedding_text)

                # –õ–æ–≥–∏—Ä—É–µ–º –∑–∞–º–µ–Ω–µ–Ω–Ω—ã–µ URL –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
                if replaced_urls:
                    logger.warning(
                        f"–í —Å–æ–æ–±—â–µ–Ω–∏–∏ {i+1} —Å–µ—Å—Å–∏–∏ {session_id} –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ URL: {replaced_urls}"
                    )

                # –í—ã—á–∏—Å–ª—è–µ–º content_hash –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
                import hashlib
                content_hash = hashlib.md5(msg_text.encode("utf-8")).hexdigest()[:16]
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                queued_count += 1
                messages_to_index.append({
                    "msg_id": msg_id,
                    "msg_text": msg_text,
                    "embedding_text": embedding_text,
                    "msg_index": i,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞–≤—Ç–æ—Ä–∞
                    "msg": msg,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞–≤—Ç–æ—Ä–∞
                    "telegram_id": str(telegram_msg_id) if telegram_msg_id else None,
                    "content_hash": content_hash,
                    "metadata": {
                        "msg_id": msg_id,
                        "session_id": session_id,
                        "chat": chat,
                        "date_utc": msg.get("date_utc") or msg.get("date", ""),
                        "has_context": len(context_text) > 0,
                        "context_length": len(context_text),
                        "chat_mode": chat_mode,
                        "replaced_urls": ",".join(replaced_urls)
                        if replaced_urls
                        else "",  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–º–µ–Ω–µ–Ω–Ω—ã–µ URL –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
                        "telegram_id": str(telegram_msg_id) if telegram_msg_id else None,
                        "content_hash": content_hash,
                    }
                })

            except Exception as e:
                logger.error(
                    f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è {i} –≤ —Å–µ—Å—Å–∏–∏ {session_id} –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}"
                )
                # –õ–æ–≥–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                if "Invalid IPv6 URL" in str(e):
                    logger.error(
                        f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –æ—à–∏–±–∫–∞ IPv6 URL –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ {i} —Å–µ—Å—Å–∏–∏ {session_id}. "
                        f"–¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è: {msg.get('text', '')[:100]}..."
                    )
                continue

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –±–∞—Ç—á–∞–º–∏
        if messages_to_index:
            try:
                async with self.embedding_client:
                    # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç—ã –¥–ª—è –±–∞—Ç—á–∞
                    batch_texts = [msg["embedding_text"] for msg in messages_to_index]
                    
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –±–∞—Ç—á–µ–º
                    embeddings = await self.embedding_client.generate_embeddings(batch_texts, batch_size=32)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é –±–∞—Ç—á–µ–º
                    ids = [msg["msg_id"] for msg in messages_to_index]
                    documents = [msg["msg_text"] for msg in messages_to_index]
                    metadatas = [msg["metadata"] for msg in messages_to_index]
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Qdrant –∫–æ–ª–ª–µ–∫—Ü–∏—é chat_messages (–¥–ª—è –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∏ –¥—Ä—É–≥–∏—Ö —Ü–µ–ª–µ–π)
                    # –í–ê–ñ–ù–û: –û—Å–Ω–æ–≤–Ω–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ - memory-records, –æ–Ω–∞ –∑–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ vector_store.upsert
                    if self.qdrant_manager and self.messages_collection:
                        try:
                            self.qdrant_manager.upsert(
                                collection_name=self.messages_collection,
                                ids=ids,
                                embeddings=embeddings,
                                metadatas=metadatas,
                                documents=documents,
                            )
                            logger.debug(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(ids)} —Å–æ–æ–±—â–µ–Ω–∏–π –≤ Qdrant –∫–æ–ª–ª–µ–∫—Ü–∏—é {self.messages_collection}")
                        except Exception as e:
                            error_msg = str(e)
                            if "dimension" in error_msg.lower():
                                logger.warning(
                                    f"–û—à–∏–±–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ chat_messages: {error_msg}. "
                                    "–ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º –∫–æ–ª–ª–µ–∫—Ü–∏—é..."
                                )
                                # –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
                                if self.qdrant_manager:
                                    self.qdrant_manager.delete_collection(self.messages_collection)
                                    self.messages_collection = self._check_and_recreate_collection(
                                        "chat_messages",
                                        "–°–æ–æ–±—â–µ–Ω–∏—è —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–ª—è —É—Ç–æ—á–Ω—è—é—â–µ–≥–æ –ø–æ–∏—Å–∫–∞ (L2)",
                                        force_recreate=True
                                    )
                                    if self.messages_collection:
                                        self.qdrant_manager.upsert(
                                            collection_name=self.messages_collection,
                                            ids=ids,
                                            embeddings=embeddings,
                                            metadatas=metadatas,
                                            documents=documents,
                                        )
                                        logger.info("–ö–æ–ª–ª–µ–∫—Ü–∏—è chat_messages –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞ –∏ –∑–∞–ø–∏—Å–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã")
                            else:
                                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ Qdrant: {e}")
                    else:
                        logger.warning("Qdrant –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–µ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ")
                    
                    # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –≥—Ä–∞—Ñ–æ–º –ø–∞–º—è—Ç–∏
                    logger.debug(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Å –≥—Ä–∞—Ñ–æ–º: ingestor={self.ingestor is not None}, graph={self.graph is not None}")
                    if self.ingestor and self.graph:
                        logger.info(f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –≥—Ä–∞—Ñ–æ–º: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(messages_to_index)} —Å–æ–æ–±—â–µ–Ω–∏–π")
                        from ..indexing import MemoryRecord, Attachment
                        from ..utils.datetime_utils import parse_datetime_utc
                        
                        records_to_ingest = []
                        for idx, msg_data in enumerate(messages_to_index):
                            try:
                                msg_id = msg_data["msg_id"]
                                msg_text = msg_data["msg_text"]
                                metadata = msg_data["metadata"]
                                embedding = embeddings[idx] if idx < len(embeddings) else None
                                
                                # –ü–∞—Ä—Å–∏–º timestamp
                                date_utc = metadata.get("date_utc", "")
                                timestamp = parse_datetime_utc(date_utc, default=None) if date_utc else None
                                if not timestamp:
                                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –∫–∞–∫ fallback
                                    from datetime import datetime, timezone
                                    timestamp = datetime.now(timezone.utc)
                                
                                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–≤—Ç–æ—Ä–∞ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
                                author = None
                                msg_obj = msg_data.get("msg")
                                if msg_obj:
                                    from_data = msg_obj.get("from") or {}
                                    author = from_data.get("username") or from_data.get("display") or from_data.get("id")
                                
                                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–≥–∏
                                tags = []
                                chat_name = metadata.get("chat", "")
                                if chat_name:
                                    tags.append(chat_name.lower().replace(" ", "_"))
                                msg_tags = msg_obj.get("tags", []) if msg_obj else []
                                if not msg_tags:
                                    msg_tags = metadata.get("tags", [])
                                if isinstance(msg_tags, list):
                                    tags.extend([str(t).lower() for t in msg_tags if t])
                                tags = list(dict.fromkeys(tags))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
                                
                                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—É—â–Ω–æ—Å—Ç–∏
                                entities = []
                                if self.entity_extractor:
                                    try:
                                        extracted = self.entity_extractor.extract_entities(msg_text)
                                        if extracted:
                                            entities.extend([
                                                e.get("text") or e.get("value") 
                                                for e in extracted 
                                                if e.get("text") or e.get("value")
                                            ])
                                    except Exception as e:
                                        logger.debug(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è {msg_id}: {e}")
                                metadata_entities = metadata.get("entities", [])
                                if isinstance(metadata_entities, list):
                                    entities.extend(metadata_entities)
                                entities = list(dict.fromkeys([str(e) for e in entities if e]))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                                
                                # –°–æ–∑–¥–∞—ë–º MemoryRecord
                                record = MemoryRecord(
                                    record_id=msg_id,
                                    source=metadata.get("chat", "unknown"),
                                    content=msg_text,
                                    timestamp=timestamp,
                                    author=author,
                                    tags=tags,
                                    entities=entities,
                                    attachments=[],
                                    metadata={
                                        "chat": metadata.get("chat", ""),
                                        "session_id": metadata.get("session_id", ""),
                                        "has_context": metadata.get("has_context", False),
                                        "context_length": metadata.get("context_length", 0),
                                        "chat_mode": metadata.get("chat_mode", "group"),
                                        "date_utc": date_utc,
                                        "content_hash": metadata.get("content_hash", ""),  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
                                        "telegram_id": metadata.get("telegram_id"),  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
                                    },
                                )
                                records_to_ingest.append((record, embedding))
                            except Exception as e:
                                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –∑–∞–ø–∏—Å–∏ {msg_data.get('msg_id', 'unknown')} –¥–ª—è –≥—Ä–∞—Ñ–∞: {e}")
                                continue
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø–∏—Å–∏ –≤ –≥—Ä–∞—Ñ –±–∞—Ç—á–µ–º
                        logger.debug(f"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(records_to_ingest)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –≥—Ä–∞—Ñ")
                        if records_to_ingest:
                            try:
                                records_only = [r for r, _ in records_to_ingest]
                                logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ {len(records_only)} –∑–∞–ø–∏—Å–µ–π –≤ –≥—Ä–∞—Ñ —á–µ—Ä–µ–∑ ingestor.ingest()")
                                ingest_result = self.ingestor.ingest(records_only)
                                logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç ingest: records_ingested={ingest_result.records_ingested}, attachments_ingested={ingest_result.attachments_ingested}")
                                
                                if ingest_result.records_ingested == 0:
                                    logger.warning(
                                        f"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: 0 –∑–∞–ø–∏—Å–µ–π –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –≥—Ä–∞—Ñ –¥–ª—è —Å–µ—Å—Å–∏–∏ {session_id}. "
                                        f"–í–æ–∑–º–æ–∂–Ω–æ, –≤—Å–µ –∑–∞–ø–∏—Å–∏ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –∏–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞."
                                    )
                                
                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –≤ –≥—Ä–∞—Ñ
                                embeddings_saved = 0
                                embeddings_failed = 0
                                for record, embedding in records_to_ingest:
                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç–º–±–µ–¥–¥–∏–Ω–≥ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –Ω–µ –ø—É—Å—Ç–æ–π
                                    if embedding is not None and len(embedding) > 0:
                                        try:
                                            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º numpy –º–∞—Å—Å–∏–≤ –≤ —Å–ø–∏—Å–æ–∫, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                                            if hasattr(embedding, 'tolist'):
                                                embedding = embedding.tolist()
                                            elif not isinstance(embedding, list):
                                                embedding = list(embedding)
                                            
                                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —É–∑–µ–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –≥—Ä–∞—Ñ–µ
                                            if record.record_id not in self.graph.graph:
                                                logger.warning(
                                                    f"–£–∑–µ–ª {record.record_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –≥—Ä–∞—Ñ–µ, "
                                                    f"–Ω–µ–ª—å–∑—è –æ–±–Ω–æ–≤–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥"
                                                )
                                                embeddings_failed += 1
                                                continue
                                            
                                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –≤ –≥—Ä–∞—Ñ
                                            success = self.graph.update_node(
                                                record.record_id,
                                                embedding=embedding,
                                            )
                                            if success:
                                                embeddings_saved += 1
                                                logger.debug(
                                                    f"–≠–º–±–µ–¥–¥–∏–Ω–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –≥—Ä–∞—Ñ –¥–ª—è {record.record_id}: "
                                                    f"—Ä–∞–∑–º–µ—Ä={len(embedding)}"
                                                )
                                                
                                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –≤ Qdrant –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (–∫–æ–ª–ª–µ–∫—Ü–∏—è memory-records)
                                                # –í–ê–ñ–ù–û: –≠—Ç–æ –æ—Å–Ω–æ–≤–Ω–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞, –¥–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –≤—Å–µ –∑–∞–ø–∏—Å–∏
                                                if self.vector_store and self.vector_store.available():
                                                    try:
                                                        payload_data = {
                                                            "record_id": record.record_id,
                                                            "source": record.source,
                                                            "tags": record.tags,
                                                            "timestamp": record.timestamp.timestamp(),
                                                            "timestamp_iso": record.timestamp.isoformat(),
                                                            "content_preview": record.content[:200],
                                                            "chat": record.metadata.get("chat", ""),
                                                            "session_id": record.metadata.get("session_id", ""),
                                                            "telegram_id": record.metadata.get("telegram_id"),
                                                            "content_hash": record.metadata.get("content_hash", ""),
                                                        }
                                                        chat_name = record.metadata.get("chat")
                                                        if isinstance(chat_name, str):
                                                            payload_data["chat"] = chat_name
                                                        
                                                        self.vector_store.upsert(record.record_id, embedding, payload_data)
                                                        logger.debug(f"–≠–º–±–µ–¥–¥–∏–Ω–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ Qdrant (memory-records) –¥–ª—è {record.record_id}")
                                                    except Exception as e:
                                                        logger.warning(
                                                            f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –≤ Qdrant (memory-records) –¥–ª—è {record.record_id}: {e}"
                                                        )
                                            else:
                                                embeddings_failed += 1
                                                logger.warning(
                                                    f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –≤ –≥—Ä–∞—Ñ –¥–ª—è {record.record_id}"
                                                )
                                        except Exception as e:
                                            embeddings_failed += 1
                                            logger.warning(
                                                f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è {record.record_id}: {e}",
                                                exc_info=True
                                            )
                                    else:
                                        logger.debug(f"–≠–º–±–µ–¥–¥–∏–Ω–≥ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø—É—Å—Ç–æ–π –¥–ª—è {record.record_id}")
                                
                                logger.info(
                                    f"–≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {embeddings_saved}, "
                                    f"–æ—à–∏–±–æ–∫: {embeddings_failed} –∏–∑ {len(records_to_ingest)} –∑–∞–ø–∏—Å–µ–π"
                                )
                                
                                logger.debug(f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(records_to_ingest)} –∑–∞–ø–∏—Å–µ–π —Å –≥—Ä–∞—Ñ–æ–º –ø–∞–º—è—Ç–∏")
                            except Exception as e:
                                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∑–∞–ø–∏—Å–µ–π —Å –≥—Ä–∞—Ñ–æ–º: {e}")
                    
                    indexed_count += len(messages_to_index)
            except Exception as e:
                logger.error(
                    f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Å–µ—Å—Å–∏–∏ {session_id}: {e}"
                )

        logger.info(
            f"L2: –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {indexed_count} —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ —Å–µ—Å—Å–∏–∏ {session_id} "
            f"(–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count}, –ø—Ä–æ–ø—É—â–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {skipped_duplicates_count}, "
            f"–¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –æ—á–µ—Ä–µ–¥—å: {queued_count})"
        )
        return indexed_count

    def _detect_chat_mode(self, messages: List[Dict[str, Any]]) -> str:
        """–õ–æ–∫–∞–ª—å–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ —á–∞—Ç–∞: 'channel' –∏–ª–∏ 'group'."""
        authors = []
        for m in messages:
            fr = m.get("from") or {}
            name = fr.get("username") or fr.get("display") or fr.get("id") or "unknown"
            authors.append(str(name))
        total = len([a for a in authors if a != "unknown"])
        if total == 0:
            return "group"
        cnt = Counter(a for a in authors if a != "unknown")
        top, top_count = cnt.most_common(1)[0]
        top_share = top_count / total
        unique = len(cnt)
        if (top_share >= 0.85 and unique <= 3 and total >= 5) or unique == 1:
            return "channel"
        return "group"

    def _build_symmetric_context(
        self,
        messages: List[Dict[str, Any]],
        current_idx: int,
        max_messages: int = 10,
        max_chars: int = 1500,
    ) -> str:
        """
        –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è

        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
            current_idx: –ò–Ω–¥–µ–∫—Å —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
            max_messages: –ú–∞–∫—Å–∏–º—É–º —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10)
            max_chars: –ú–∞–∫—Å–∏–º—É–º —Å–∏–º–≤–æ–ª–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1500)

        Returns:
            –¢–µ–∫—Å—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        """
        context_parts = []
        total_chars = 0

        # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–∏: -1, +1, -2, +2, ...
        distance = 1
        while len(context_parts) < max_messages and distance <= max_messages // 2:
            # –ü—Ä–µ–¥—ã–¥—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            prev_idx = current_idx - distance
            if prev_idx >= 0:
                prev_text = messages[prev_idx].get("text", "").strip()
                if prev_text and total_chars + len(prev_text) <= max_chars:
                    context_parts.insert(0, prev_text)
                    total_chars += len(prev_text)

            # –°–ª–µ–¥—É—é—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            next_idx = current_idx + distance
            if next_idx < len(messages):
                next_text = messages[next_idx].get("text", "").strip()
                if next_text and total_chars + len(next_text) <= max_chars:
                    context_parts.append(next_text)
                    total_chars += len(next_text)

            distance += 1

        return " | ".join(context_parts)

    async def _index_tasks(self, summary: Dict[str, Any]) -> int:
        """
        –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è Action Items –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é tasks

        Args:
            summary: –°–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏

        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
        """
        actions = summary.get("actions", [])
        session_id = summary["session_id"]
        chat = summary.get("meta", {}).get("chat_name", "")

        indexed_count = 0

        for i, action in enumerate(actions):
            confidence = action.get("confidence", 0.8)
            if confidence < 0.6:
                continue

            try:
                # –¢–µ–∫—Å—Ç –∑–∞–¥–∞—á–∏
                task_text = action.get("text", "")
                if not task_text:
                    continue

                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
                async with self.embedding_client:
                    embeddings = await self.embedding_client.generate_embeddings(
                        [task_text]
                    )
                    embedding = embeddings[0]

                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                task_id = f"{session_id}-T{i+1:02d}"
                metadata = {
                    "task_id": task_id,
                    "session_id": session_id,
                    "chat": chat,
                    "owner": action.get("owner", ""),
                    "due": action.get("due", ""),
                    "priority": action.get("priority", "normal"),
                    "confidence": confidence,
                    "msg_id": action.get("msg_id", ""),
                    "topic_title": action.get("topic_title", ""),
                }

                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é
                if self.qdrant_manager and self.tasks_collection:
                    self.qdrant_manager.upsert(
                        collection_name=self.tasks_collection,
                        ids=[task_id],
                        documents=[task_text],
                        embeddings=[embedding],
                        metadatas=[metadata],
                    )

                indexed_count += 1

            except Exception as e:
                logger.error(
                    f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∑–∞–¥–∞—á–∏ {i} –≤ —Å–µ—Å—Å–∏–∏ {session_id}: {e}"
                )
                continue

        logger.info(
            f"Tasks: –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {indexed_count} –∑–∞–¥–∞—á –∏–∑ —Å–µ—Å—Å–∏–∏ {session_id}"
        )
        return indexed_count

    def _parse_message_time(self, msg: Dict[str, Any]) -> datetime:
        """–ü–∞—Ä—Å–∏–Ω–≥ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–æ–±—â–µ–Ω–∏—è (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—â—É—é —É—Ç–∏–ª–∏—Ç—É)."""
        from ..utils.datetime_utils import parse_message_time

        return parse_message_time(msg, use_zoneinfo=True)

    async def _cluster_chat_sessions(
        self, chat_name: str, summaries: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–π —á–∞—Ç–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Args:
            chat_name: –ù–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞
            summaries: –°–ø–∏—Å–æ–∫ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–π —Å–µ—Å—Å–∏–π

        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
        """
        if not self.session_clusterer or not self.cluster_summarizer:
            return {"clusters_count": 0, "sessions_clustered": 0}

        # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ Qdrant –¥–ª—è —Å–µ—Å—Å–∏–π
        session_ids = [s["session_id"] for s in summaries]

        try:
            result = None
            if self.qdrant_manager and self.sessions_collection:
                result = self.qdrant_manager.get(
                    collection_name=self.sessions_collection,
                    ids=session_ids
                )
            else:
                logger.warning("Qdrant –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞")
                return {"clusters_count": 0, "sessions_clustered": 0}

            if not result["ids"]:
                logger.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–µ—Å—Å–∏–π —á–∞—Ç–∞ {chat_name}")
                return {"clusters_count": 0, "sessions_clustered": 0}

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
            sessions_data = []
            embeddings_list = []

            for i, session_id in enumerate(result["ids"]):
                sessions_data.append(
                    {
                        "session_id": session_id,
                        "metadata": result["metadatas"][i],
                        "document": result["documents"][i],
                    }
                )
                embeddings_list.append(result["embeddings"][i])

            # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é
            logger.info(f"–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è {len(sessions_data)} —Å–µ—Å—Å–∏–π —á–∞—Ç–∞ {chat_name}")
            clustering_result = self.session_clusterer.cluster_sessions(
                sessions_data, embeddings_list
            )

            clusters = clustering_result.get("clusters", [])
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(clusters)} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–ª–∞—Å—Ç–µ—Ä—ã –≤ Qdrant –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–π
            clusters_saved = 0
            sessions_clustered = 0

            for cluster in clusters:
                cluster_id = f"{slugify(chat_name)}-cluster-{cluster['cluster_id']}"

                # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–π, –¥–æ–±–∞–≤–ª—è—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–ª–∞—Å—Ç–µ—Ä–µ
                for session_id in cluster["session_ids"]:
                    try:
                        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏
                        session_data = None
                        if self.qdrant_manager and self.sessions_collection:
                            session_data = self.qdrant_manager.get(
                                collection_name=self.sessions_collection,
                                ids=[session_id]
                            )

                        if session_data and session_data.get("ids"):
                            metadata = session_data["metadatas"][0].copy()
                            metadata["cluster_id"] = cluster_id
                            metadata["cluster_label"] = cluster.get("label", "")

                            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ upsert (Qdrant –Ω–µ –∏–º–µ–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ update)
                            if self.qdrant_manager and self.sessions_collection:
                                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
                                current_data = self.qdrant_manager.get(
                                    collection_name=self.sessions_collection,
                                    ids=[session_id]
                                )
                                if current_data and current_data.get("ids"):
                                    # –û–±–Ω–æ–≤–ª—è–µ–º —á–µ—Ä–µ–∑ upsert —Å –Ω–æ–≤—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
                                    self.qdrant_manager.upsert(
                                        collection_name=self.sessions_collection,
                                        ids=[session_id],
                                        embeddings=current_data.get("embeddings", [[]])[:1] or [[]],
                                        metadatas=[metadata],
                                        documents=current_data.get("documents", [""])[:1] or [""],
                                    )
                                    sessions_clustered += 1
                    except Exception as e:
                        logger.error(
                            f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–∏ {session_id}: {e}"
                        )

                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∞ (—Å—Ä–µ–¥–Ω–µ–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å–µ—Å—Å–∏–π)
                cluster_embedding = [0.0] * len(embeddings_list[0])
                for session_id in cluster["session_ids"]:
                    try:
                        idx = session_ids.index(session_id)
                        session_emb = embeddings_list[idx]
                        for i, val in enumerate(session_emb):
                            cluster_embedding[i] += val
                    except ValueError:
                        continue

                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
                n = len(cluster["session_ids"])
                if n > 0:
                    cluster_embedding = [val / n for val in cluster_embedding]

                # –°–æ–∑–¥–∞—ë–º –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∞
                cluster_doc = (
                    f"–ö–ª–∞—Å—Ç–µ—Ä: {cluster.get('label', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}\n"
                    f"–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(cluster.get('keywords', []))}\n"
                    f"–¢–æ–ø–∏–∫–∏: {', '.join(cluster.get('topics', []))}\n"
                    f"–°—É—â–Ω–æ—Å—Ç–∏: {', '.join(cluster.get('entities', []))}"
                )

                # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Ç–µ—Ä–∞
                cluster_metadata = {
                    "cluster_id": cluster_id,
                    "chat": chat_name,
                    "label": cluster.get("label", ""),
                    "size": cluster.get("size", 0),
                    "coherence": cluster.get("coherence", 0.0),
                    "session_ids": ",".join(cluster["session_ids"][:10]),  # –ü–µ—Ä–≤—ã–µ 10
                }

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–ª–∞—Å—Ç–µ—Ä
                try:
                    if self.qdrant_manager and self.clusters_collection:
                        self.qdrant_manager.upsert(
                            collection_name=self.clusters_collection,
                            ids=[cluster_id],
                            documents=[cluster_doc],
                            embeddings=[cluster_embedding],
                            metadatas=[cluster_metadata],
                        )
                    clusters_saved += 1
                    logger.info(
                        f"–°–æ—Ö—Ä–∞–Ω—ë–Ω –∫–ª–∞—Å—Ç–µ—Ä {cluster_id}: {cluster.get('label', '')}"
                    )
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞ {cluster_id}: {e}")

            return {
                "clusters_count": clusters_saved,
                "sessions_clustered": sessions_clustered,
                "total_sessions": len(sessions_data),
                "noise_sessions": clustering_result.get("noise_count", 0),
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ —á–∞—Ç–∞ {chat_name}: {e}")
            return {"clusters_count": 0, "sessions_clustered": 0}

    def get_clusters(
        self, chat: Optional[str] = None, limit: int = 20
    ) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤

        Args:
            chat: –§–∏–ª—å—Ç—Ä –ø–æ —á–∞—Ç—É (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        """
        if not self.qdrant_manager or not self.clusters_collection:
            return []

        try:
            where_filter = {"chat": chat} if chat else None

            result = self.qdrant_manager.get(
                collection_name=self.clusters_collection,
                where=where_filter,
                limit=limit
            )

            clusters = []
            for i, cluster_id in enumerate(result["ids"]):
                clusters.append(
                    {
                        "cluster_id": cluster_id,
                        "metadata": result["metadatas"][i],
                        "document": result["documents"][i],
                    }
                )

            return clusters
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {e}")
            return []

    def get_cluster_sessions(self, cluster_id: str) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–µ—Å—Å–∏–∏, –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—â–∏–µ –∫–ª–∞—Å—Ç–µ—Ä—É

        Args:
            cluster_id: ID –∫–ª–∞—Å—Ç–µ—Ä–∞

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–µ—Å—Å–∏–π
        """
        if not self.qdrant_manager or not self.sessions_collection:
            return []

        try:
            result = self.qdrant_manager.get(
                collection_name=self.sessions_collection,
                where={"cluster_id": cluster_id}
            )

            sessions = []
            for i, session_id in enumerate(result["ids"]):
                sessions.append(
                    {
                        "session_id": session_id,
                        "metadata": result["metadatas"][i],
                        "document": result["documents"][i],
                    }
                )

            return sessions
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–µ—Å—Å–∏–π –∫–ª–∞—Å—Ç–µ—Ä–∞ {cluster_id}: {e}")
            return []

    def _count_indexed_messages_in_chat(self, chat_name: str) -> int:
        """
        –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —á–∞—Ç–µ

        Returns:
            int: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ chat_messages –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —á–∞—Ç–∞
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Qdrant –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
            existing_messages = None
            if self.qdrant_manager and self.messages_collection:
                existing_messages = self.qdrant_manager.get(
                    collection_name=self.messages_collection,
                    where={"chat": chat_name}
                )

            if existing_messages and existing_messages.get("ids") is not None:
                message_count = len(existing_messages["ids"])
                logger.info(
                    f"–ù–∞–π–¥–µ–Ω–æ {message_count} —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —á–∞—Ç–µ {chat_name}"
                )
                return message_count
            else:
                logger.info(f"–í —á–∞—Ç–µ {chat_name} –Ω–µ—Ç –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π")
                return 0

        except Exception as e:
            logger.warning(
                f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥—Å—á–µ—Ç–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —á–∞—Ç–∞ {chat_name}: {e}"
            )
            return 0

    def _group_messages_by_smart_strategy(
        self, messages: List[Dict[str, Any]], chat_name: str
    ) -> List[Dict[str, Any]]:
        """
        –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π —Å —É–º–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π –æ–∫–æ–Ω

        NOW (0-1 –¥–µ–Ω—å): –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–Ω—è–º –∏–ª–∏ —Å–µ—Å—Å–∏—è–º
        FRESH (1-14 –¥–Ω–µ–π): –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–Ω—è–º —Å –º–∏–Ω–∏–º—É–º–æ–º —Å–æ–æ–±—â–µ–Ω–∏–π
        RECENT (14-30 –¥–Ω–µ–π): –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –Ω–µ–¥–µ–ª—è–º
        OLD (30+ –¥–Ω–µ–π): –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –º–µ—Å—è—Ü–∞–º

        –ü–µ—Ä–µ—Ö–æ–¥ –º–µ–∂–¥—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏:
        - –ï—Å–ª–∏ —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ >1000 —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —á–∞—Ç–µ, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        - fresh -> recent -> old
        """
        from datetime import datetime

        if not messages:
            return []

        current_date = datetime.now(datetime.now().astimezone().tzinfo)

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —á–∞—Ç–µ
        indexed_messages_count = self._count_indexed_messages_in_chat(chat_name)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        if indexed_messages_count >= self.strategy_threshold:
            logger.info(
                f"üîÑ –ü–µ—Ä–µ—Ö–æ–¥ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è —á–∞—Ç–∞ {chat_name}: "
                f"—É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {indexed_messages_count} —Å–æ–æ–±—â–µ–Ω–∏–π "
                f"(–ø–æ—Ä–æ–≥: {self.strategy_threshold})"
            )

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–µ—Å—Å–∏–π
            current_strategy = self._determine_current_strategy(chat_name)
            logger.info(f"üìä –¢–µ–∫—É—â–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è —á–∞—Ç–∞ {chat_name}: {current_strategy}")

            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            next_strategy = self._get_next_strategy(current_strategy)
            logger.info(f"‚û°Ô∏è  –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: {next_strategy}")

            # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é
            return self._apply_strategy_transition(
                messages, chat_name, next_strategy, current_date
            )

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä —Å–µ—Å—Å–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–µ—Å—Å–∏–π
        existing_session_ids = set()
        try:
            existing_sessions = None
            if self.qdrant_manager and self.sessions_collection:
                existing_sessions = self.qdrant_manager.get(
                    collection_name=self.sessions_collection,
                    where={"chat": chat_name}
                )
            if existing_sessions and existing_sessions.get("ids"):
                existing_session_ids = set(existing_sessions["ids"])
                logger.info(
                    f"–ù–∞–π–¥–µ–Ω–æ {len(existing_session_ids)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–µ—Å—Å–∏–π –¥–ª—è —á–∞—Ç–∞ {chat_name}"
                )
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–µ—Å—Å–∏–π: {e}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä —Å–µ—Å—Å–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–∫–Ω–∞
        window_max_numbers = {}
        for session_id in existing_session_ids:
            if f"{slugify(chat_name)}-" in session_id:
                parts = session_id.split("-")
                if len(parts) >= 3:
                    window_name = parts[1]
                    try:
                        session_num = int(parts[2][1:])  # –£–±–∏—Ä–∞–µ–º 'S' –∏ –±–µ—Ä–µ–º —á–∏—Å–ª–æ
                        if window_name not in window_max_numbers:
                            window_max_numbers[window_name] = 0
                        window_max_numbers[window_name] = max(
                            window_max_numbers[window_name], session_num
                        )
                    except (ValueError, IndexError):
                        continue

        logger.info(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –Ω–æ–º–µ—Ä–∞ —Å–µ—Å—Å–∏–π –ø–æ –æ–∫–Ω–∞–º: {window_max_numbers}")

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é fresh –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –Ω–æ–≤—ã—Ö —á–∞—Ç–æ–≤
        return self._apply_strategy_transition(
            messages, chat_name, "fresh", current_date
        )

    def _determine_current_strategy(self, chat_name: str) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–µ—Å—Å–∏–π

        Returns:
            str: —Ç–µ–∫—É—â–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è (fresh, recent, old)
        """
        try:
            existing_sessions = None
            if self.qdrant_manager and self.sessions_collection:
                existing_sessions = self.qdrant_manager.get(
                    collection_name=self.sessions_collection,
                    where={"chat": chat_name}
                )

            if not existing_sessions or not existing_sessions.get("ids"):
                return "fresh"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–∞—á–∏–Ω–∞–µ–º —Å fresh

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–µ—Å—Å–∏–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            strategies_found = set()
            for session_id in existing_sessions["ids"]:
                if f"{slugify(chat_name)}-" in session_id:
                    parts = session_id.split("-")
                    if len(parts) >= 3:
                        window_name = parts[1]
                        if window_name in ["fresh", "recent", "old"]:
                            strategies_found.add(window_name)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω
            if "old" in strategies_found:
                return "old"
            elif "recent" in strategies_found:
                return "recent"
            elif "fresh" in strategies_found:
                return "fresh"
            else:
                return "fresh"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é

        except Exception as e:
            logger.warning(
                f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è —á–∞—Ç–∞ {chat_name}: {e}"
            )
            return "fresh"

    def _get_next_strategy(self, current_strategy: str) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

        Args:
            current_strategy: —Ç–µ–∫—É—â–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è

        Returns:
            str: —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
        """
        strategy_sequence = ["fresh", "recent", "old"]

        try:
            current_index = strategy_sequence.index(current_strategy)
            if current_index < len(strategy_sequence) - 1:
                return strategy_sequence[current_index + 1]
            else:
                return "old"  # –û—Å—Ç–∞–µ–º—Å—è –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        except ValueError:
            logger.warning(
                f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {current_strategy}, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º fresh"
            )
            return "fresh"

    def _apply_strategy_transition(
        self,
        messages: List[Dict[str, Any]],
        chat_name: str,
        strategy: str,
        current_date,
    ) -> List[Dict[str, Any]]:
        """
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø–µ—Ä–µ—Ö–æ–¥ –∫ –Ω–æ–≤–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏

        Args:
            messages: —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
            chat_name: –Ω–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞
            strategy: –Ω–æ–≤–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è (fresh, recent, old)
            current_date: —Ç–µ–∫—É—â–∞—è –¥–∞—Ç–∞

        Returns:
            List[Dict[str, Any]]: —Å–ø–∏—Å–æ–∫ —Å–µ—Å—Å–∏–π
        """
        logger.info(f"üéØ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ '{strategy}' –¥–ª—è —á–∞—Ç–∞ {chat_name}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–æ–∑—Ä–∞—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –æ–∫–Ω–∞–º
        now_messages = []
        fresh_messages = []
        recent_messages = []
        old_messages = []

        for msg in messages:
            if "date_utc" not in msg:
                continue

            try:
                from ..utils.datetime_utils import parse_datetime_utc

                msg_date = parse_datetime_utc(msg["date_utc"], use_zoneinfo=True)
                age_days = (current_date - msg_date).days

                if age_days <= 1:
                    now_messages.append(msg)
                elif age_days <= 14:
                    fresh_messages.append(msg)
                elif age_days <= 30:
                    recent_messages.append(msg)
                else:
                    old_messages.append(msg)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç—ã —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
                continue

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–π
        sessions = []

        if strategy == "fresh":
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ NOW –∏ FRESH –æ–∫–Ω–∞
            # –ï—Å–ª–∏ –≤ —ç—Ç–∏—Ö –æ–∫–Ω–∞—Ö –Ω–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π, –Ω–æ –µ—Å—Ç—å –≤ OLD, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ OLD
            if not now_messages and not fresh_messages and old_messages:
                logger.info(
                    f"‚ö†Ô∏è  –í –æ–∫–Ω–∞—Ö NOW –∏ FRESH –Ω–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π, –Ω–æ –µ—Å—Ç—å {len(old_messages)} –≤ OLD. "
                    "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é OLD."
                )
                strategy = "old"
                window_strategies = [
                    ("now", now_messages, "session"),
                    ("fresh", fresh_messages, "day"),
                    ("recent", recent_messages, "week"),
                    ("old", old_messages, "month"),
                ]
            else:
                window_strategies = [
                    ("now", now_messages, "session"),
                    ("fresh", fresh_messages, "day"),
                ]
        elif strategy == "recent":
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º NOW, FRESH –∏ RECENT –æ–∫–Ω–∞
            window_strategies = [
                ("now", now_messages, "session"),
                ("fresh", fresh_messages, "day"),
                ("recent", recent_messages, "week"),
            ]
        else:  # strategy == "old"
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –æ–∫–Ω–∞
            window_strategies = [
                ("now", now_messages, "session"),
                ("fresh", fresh_messages, "day"),
                ("recent", recent_messages, "week"),
                ("old", old_messages, "month"),
            ]

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä —Å–µ—Å—Å–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–∫–Ω–∞
        existing_session_ids = set()
        try:
            existing_sessions = None
            if self.qdrant_manager and self.sessions_collection:
                existing_sessions = self.qdrant_manager.get(
                    collection_name=self.sessions_collection,
                    where={"chat": chat_name}
                )
            if existing_sessions and existing_sessions.get("ids"):
                existing_session_ids = set(existing_sessions["ids"])
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–µ—Å—Å–∏–π: {e}")

        window_max_numbers = {}
        for session_id in existing_session_ids:
            if f"{slugify(chat_name)}-" in session_id:
                parts = session_id.split("-")
                if len(parts) >= 3:
                    window_name = parts[1]
                    try:
                        session_num = int(parts[2][1:])  # –£–±–∏—Ä–∞–µ–º 'S' –∏ –±–µ—Ä–µ–º —á–∏—Å–ª–æ
                        if window_name not in window_max_numbers:
                            window_max_numbers[window_name] = 0
                        window_max_numbers[window_name] = max(
                            window_max_numbers[window_name], session_num
                        )
                    except (ValueError, IndexError):
                        continue

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–µ –æ–∫–Ω–æ –ø–æ —Å–≤–æ–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        for window_name, window_messages, window_strategy in window_strategies:
            if not window_messages:
                continue

            logger.info(
                f"–û–∫–Ω–æ '{window_name}': {len(window_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π, —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {window_strategy}"
            )

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
            window_sessions = (
                self.day_grouping_segmenter.group_messages_by_window_strategy(
                    window_messages, chat_name, window_strategy
                )
            )

            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–∫–Ω–µ –∫ —Å–µ—Å—Å–∏—è–º
            window_counter = window_max_numbers.get(window_name, 0) + 1
            for session in window_sessions:
                session["window"] = window_name
                session[
                    "session_id"
                ] = f"{slugify(chat_name)}-{window_name}-S{window_counter:04d}"
                window_counter += 1

            sessions.extend(window_sessions)

        logger.info(
            f"‚úÖ –°—Ç—Ä–∞—Ç–µ–≥–∏—è '{strategy}' –ø—Ä–∏–º–µ–Ω–µ–Ω–∞: —Å–æ–∑–¥–∞–Ω–æ {len(sessions)} —Å–µ—Å—Å–∏–π"
        )
        return sessions

    def _link_session_to_previous_sessions(
        self, session_id: str, chat: str, session_timestamp: datetime
    ) -> None:
        """–°–æ–∑–¥–∞–µ—Ç —Å–≤—è–∑–∏ –º–µ–∂–¥—É —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–µ–π –∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–µ—Å—Å–∏—è–º–∏ —Ç–æ–≥–æ –∂–µ —á–∞—Ç–∞."""
        if not self.graph:
            return
        
        try:
            from ..memory.graph_types import GraphEdge, EdgeType
            cursor = self.graph.conn.cursor()
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–º—è —á–∞—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ (—Å–µ—Å—Å–∏–∏ –º–æ–≥—É—Ç –∏–º–µ—Ç—å —Ñ–æ—Ä–º–∞—Ç "semya-old-S0001")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é slugify –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–º–µ–Ω–∏
            from ..utils.naming import slugify
            chat_slug = slugify(chat) if chat else ""
            
            # –ò—â–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–µ—Å—Å–∏–∏ —Ç–æ–≥–æ –∂–µ —á–∞—Ç–∞
            # –°–µ—Å—Å–∏–∏ –º–æ–≥—É—Ç –∏–º–µ—Ç—å —Ñ–æ—Ä–º–∞—Ç: "semya-old-S0001", "–°–µ–º—å—è-old-S0001", "semya-S0001" –∏ —Ç.–¥.
            # –ò—â–µ–º –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É, –∫–æ—Ç–æ—Ä—ã–π –≤–∫–ª—é—á–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∏–º—è —á–∞—Ç–∞ –∏–ª–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è
            query = """
                SELECT id, properties FROM nodes
                WHERE type = 'DocChunk' 
                AND id != ?
                AND properties IS NOT NULL
                AND json_extract(properties, '$.session_type') = 'session_summary'
                AND (
                    json_extract(properties, '$.chat') = ?
                    OR json_extract(properties, '$.source') = ?
                )
                AND (
                    id LIKE ? 
                    OR id LIKE ?
                    OR (id LIKE ? AND ? != '')
                )
                ORDER BY json_extract(properties, '$.timestamp') DESC
                LIMIT 5
            """
            
            # –ò—â–µ–º —Å–µ—Å—Å–∏–∏ —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ñ–æ—Ä–º–∞—Ç–∞–º–∏:
            # 1. –° –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º –∏–º–µ–Ω–µ–º: "semya-old-S%", "semya-S%"
            # 2. –° –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º: "–°–µ–º—å—è-old-S%", "–°–µ–º—å—è-S%"
            # 3. –° –ª—é–±—ã–º –ø—Ä–µ—Ñ–∏–∫—Å–æ–º, –µ—Å–ª–∏ chat_slug –ø—É—Å—Ç–æ–π
            pattern1 = f"{chat_slug}-%-S%" if chat_slug else "%"
            pattern2 = f"{chat}-%-S%" if chat else "%"
            pattern3 = f"{chat_slug}-S%" if chat_slug else "%"
            
            cursor.execute(query, (session_id, chat, chat, pattern1, pattern2, pattern3, chat_slug))
            existing_sessions = cursor.fetchall()
            
            for row in existing_sessions:
                try:
                    props = json.loads(row["properties"]) if isinstance(row["properties"], str) else row["properties"]
                    if not props:
                        continue
                    
                    # –ü–æ–ª—É—á–∞–µ–º timestamp –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Å–µ—Å—Å–∏–∏
                    prev_timestamp_str = props.get("timestamp") or props.get("start_time_utc")
                    if not prev_timestamp_str:
                        continue
                    
                    from ..utils.datetime_utils import parse_datetime_utc
                    prev_timestamp = parse_datetime_utc(prev_timestamp_str, default=None)
                    if not prev_timestamp:
                        continue
                    
                    # –°–æ–∑–¥–∞–µ–º —Å–≤—è–∑—å —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–µ—Å—Å–∏–∏ –±–ª–∏–∑–∫–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 7 –¥–Ω–µ–π)
                    time_diff = abs((session_timestamp - prev_timestamp).total_seconds())
                    if time_diff <= 7 * 24 * 3600:  # 7 –¥–Ω–µ–π
                        prev_session_id = row["id"]
                        
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–≤—è–∑–∏ (–æ—Ç –±–æ–ª–µ–µ —Å—Ç–∞—Ä–æ–π –∫ –±–æ–ª–µ–µ –Ω–æ–≤–æ–π)
                        if session_timestamp > prev_timestamp:
                            source_id = prev_session_id
                            target_id = session_id
                        else:
                            source_id = session_id
                            target_id = prev_session_id
                        
                        edge = GraphEdge(
                            id=f"{source_id}-next-session-{target_id}",
                            source_id=source_id,
                            target_id=target_id,
                            type=EdgeType.RELATES_TO,
                            weight=0.7,  # –í—ã—Å–æ–∫–∏–π –≤–µ—Å –¥–ª—è —Å–≤—è–∑–µ–π –º–µ–∂–¥—É —Å–µ—Å—Å–∏—è–º–∏
                            properties={
                                "time_diff_seconds": time_diff,
                                "relation_type": "session_sequence"
                            },
                        )
                        try:
                            self.graph.add_edge(edge)
                            logger.debug(f"–°–æ–∑–¥–∞–Ω–∞ —Å–≤—è–∑—å –º–µ–∂–¥—É —Å–µ—Å—Å–∏—è–º–∏ {source_id} -> {target_id}")
                        except Exception as e:
                            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏, –µ—Å–ª–∏ —Å–≤—è–∑—å —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Å–≤—è–∑—å –º–µ–∂–¥—É —Å–µ—Å—Å–∏—è–º–∏ {source_id} –∏ {target_id}: {e}")
                except Exception as e:
                    logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–≤—è–∑–∏ —Å —Å–µ—Å—Å–∏–µ–π {row['id']}: {e}")
                    continue
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–≤—è–∑—ã–≤–∞–Ω–∏–∏ —Å–µ—Å—Å–∏–∏ {session_id} —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏: {e}")

    async def _update_entity_nodes_with_descriptions(self) -> None:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ EntityNode –≤ –≥—Ä–∞—Ñ–µ —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏ –∏–∑ —Å–ª–æ–≤–∞—Ä—è —Å—É—â–Ω–æ—Å—Ç–µ–π"""
        if not self.graph or not self.entity_dictionary:
            return
        
        try:
            from ..memory.graph_types import NodeType
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ EntityNode –∏–∑ –≥—Ä–∞—Ñ–∞
            entity_nodes = self.graph.get_nodes_by_type(NodeType.ENTITY, limit=10000)
            
            updated_count = 0
            for node_data in entity_nodes:
                node_id = node_data.get("id")
                if not node_id:
                    continue
                
                # –ü–æ–ª—É—á–∞–µ–º —Ç–∏–ø –∏ –∏–º—è —Å—É—â–Ω–æ—Å—Ç–∏ –∏–∑ —É–∑–ª–∞
                entity_type = node_data.get("entity_type", "term")
                label = node_data.get("label", "")
                
                if not label:
                    continue
                
                # –ü–æ–ª—É—á–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ —Å–ª–æ–≤–∞—Ä—è
                description = self.entity_dictionary.get_entity_description(entity_type, label)
                
                if description:
                    # –û–±–Ω–æ–≤–ª—è–µ–º —É–∑–µ–ª —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –æ–±–Ω–æ–≤–ª—è—Ç—å (–µ—Å–ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)
                    current_description = node_data.get("description")
                    if current_description != description:
                        # –û–±–Ω–æ–≤–ª—è–µ–º —á–µ—Ä–µ–∑ update_node –∏–ª–∏ –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ SQL
                        try:
                            # –û–±–Ω–æ–≤–ª—è–µ–º —É–∑–µ–ª —á–µ—Ä–µ–∑ –º–µ—Ç–æ–¥ update_node –≥—Ä–∞—Ñ–∞
                            # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ —Å–≤–æ–π—Å—Ç–≤–∞
                            if node_id in self.graph.graph:
                                node_data = self.graph.graph.nodes[node_id]
                                current_properties = node_data.get("properties", {})
                                
                                # –û–±–Ω–æ–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –≤ —Å–≤–æ–π—Å—Ç–≤–∞—Ö
                                current_properties["description"] = description
                                
                                # –û–±–Ω–æ–≤–ª—è–µ–º —É–∑–µ–ª —á–µ—Ä–µ–∑ –º–µ—Ç–æ–¥ –≥—Ä–∞—Ñ–∞
                                self.graph.update_node(
                                    node_id,
                                    properties=current_properties,
                                )
                                
                                # –¢–∞–∫–∂–µ –æ–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª–µ description –Ω–∞–ø—Ä—è–º—É—é, –µ—Å–ª–∏ —É–∑–µ–ª —ç—Ç–æ EntityNode
                                node_data["description"] = description
                                
                                updated_count += 1
                                logger.debug(f"–û–±–Ω–æ–≤–ª–µ–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è EntityNode {node_id}: {description[:50]}...")
                        except Exception as e:
                            logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è EntityNode {node_id}: {e}")
            
            if updated_count > 0:
                logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–æ {updated_count} EntityNode —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏")
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ EntityNode —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏: {e}")

    async def _build_and_index_entities(self, chat_name: str) -> None:
        """
        –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø—Ä–æ—Ñ–∏–ª–µ–π —Å—É—â–Ω–æ—Å—Ç–µ–π –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
        
        Args:
            chat_name: –ù–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞ (–¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
        """
        if not self.entity_dictionary or not self.entity_vector_store or not self.graph:
            return
        
        try:
            from ..memory.graph_types import NodeType, EntityNode
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å—É—â–Ω–æ—Å—Ç–∏ –∏–∑ —Å–ª–æ–≤–∞—Ä—è
            all_entities = []
            for entity_type in self.entity_dictionary.learned_dictionaries:
                for normalized_value in self.entity_dictionary.learned_dictionaries[entity_type]:
                    # –ü–æ–ª—É—á–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (–∏–∑ entity_counts –∏–ª–∏ –∏–∑ –≥—Ä–∞—Ñ–∞)
                    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –≤ –≥—Ä–∞—Ñ–µ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
                    entity_id = f"entity-{normalized_value.replace(' ', '-')}"
                    original_value = normalized_value
                    
                    if entity_id in self.graph.graph:
                        node_data = self.graph.graph.nodes[entity_id]
                        original_value = node_data.get("label", normalized_value)
                    
                    all_entities.append((entity_type, normalized_value, original_value))
            
            if not all_entities:
                logger.debug(f"–ù–µ—Ç —Å—É—â–Ω–æ—Å—Ç–µ–π –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≤ —á–∞—Ç–µ {chat_name}")
                return
            
            logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª–µ–π –¥–ª—è {len(all_entities)} —Å—É—â–Ω–æ—Å—Ç–µ–π –∏–∑ —á–∞—Ç–∞ {chat_name}")
            
            indexed_count = 0
            failed_count = 0
            
            for entity_type, normalized_value, original_value in all_entities:
                try:
                    # –°—Ç—Ä–æ–∏–º –ø–æ–ª–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å —Å—É—â–Ω–æ—Å—Ç–∏
                    profile = self.entity_dictionary.build_entity_profile(entity_type, original_value)
                    
                    if not profile:
                        continue
                    
                    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∏–∑ –ø–æ–ª–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è
                    # –í–∫–ª—é—á–∞–µ–º: –æ–ø–∏—Å–∞–Ω–∏–µ, –∞–ª–∏–∞—Å—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏
                    embedding_text_parts = []
                    
                    if profile.get("description"):
                        embedding_text_parts.append(profile["description"])
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∞–ª–∏–∞—Å—ã
                    aliases = profile.get("aliases", [])
                    if aliases:
                        embedding_text_parts.append(f"–¢–∞–∫–∂–µ –∏–∑–≤–µ—Å—Ç–µ–Ω –∫–∞–∫: {', '.join(aliases[:5])}")
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç—è—Ö
                    related = profile.get("related_entities", [])
                    if related:
                        related_names = [r.get("label", "") for r in related[:3] if r.get("label")]
                        if related_names:
                            embedding_text_parts.append(f"–°–≤—è–∑–∞–Ω —Å: {', '.join(related_names)}")
                    
                    embedding_text = " ".join(embedding_text_parts)
                    
                    if not embedding_text:
                        # –ï—Å–ª–∏ –Ω–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è –∏ —Ç–∏–ø
                        embedding_text = f"{entity_type} {original_value}"
                    
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
                    async with self.embedding_client:
                        embedding = await self.embedding_client.embed(embedding_text)
                    
                    if not embedding or len(embedding) == 0:
                        logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è {entity_type}={normalized_value}")
                        failed_count += 1
                        continue
                    
                    # –§–æ—Ä–º–∏—Ä—É–µ–º payload –¥–ª—è Qdrant
                    entity_id = f"entity-{normalized_value.replace(' ', '-')}"
                    payload = {
                        "entity_type": entity_type,
                        "value": original_value,
                        "normalized_value": normalized_value,
                        "description": profile.get("description", ""),
                        "aliases": profile.get("aliases", []),
                        "importance": profile.get("importance", 0.5),
                        "mention_count": profile.get("mention_count", 0),
                        "chats": profile.get("chats", []),
                        "first_seen": profile.get("first_seen"),
                        "last_seen": profile.get("last_seen"),
                    }
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ EntityVectorStore
                    self.entity_vector_store.upsert_entity(entity_id, embedding, payload)
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º EntityNode –≤ –≥—Ä–∞—Ñ–µ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–º –∏ –ø–æ–ª–Ω—ã–º –æ–ø–∏—Å–∞–Ω–∏–µ–º
                    if entity_id in self.graph.graph:
                        node_data = self.graph.graph.nodes[entity_id]
                        current_properties = node_data.get("properties", {})
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∏ —ç–º–±–µ–¥–¥–∏–Ω–≥
                        current_properties["description"] = profile.get("description", "")
                        current_properties["entity_profile"] = {
                            "mention_count": profile.get("mention_count", 0),
                            "chats": profile.get("chats", []),
                            "importance": profile.get("importance", 0.5),
                        }
                        
                        self.graph.update_node(
                            entity_id,
                            properties=current_properties,
                            embedding=embedding,
                        )
                    else:
                        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π EntityNode, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç –≤ –≥—Ä–∞—Ñ–µ
                        entity_node = EntityNode(
                            id=entity_id,
                            label=original_value,
                            entity_type=entity_type,
                            aliases=profile.get("aliases", []),
                            description=profile.get("description"),
                            importance=profile.get("importance", 0.5),
                            properties={
                                "normalized_value": normalized_value,
                                "entity_profile": {
                                    "mention_count": profile.get("mention_count", 0),
                                    "chats": profile.get("chats", []),
                                    "importance": profile.get("importance", 0.5),
                                },
                            },
                            embedding=embedding,
                        )
                        self.graph.add_node(entity_node)
                    
                    indexed_count += 1
                    
                    if indexed_count % 10 == 0:
                        logger.debug(f"–ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {indexed_count} —Å—É—â–Ω–æ—Å—Ç–µ–π...")
                        
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Å—É—â–Ω–æ—Å—Ç–∏ {entity_type}={normalized_value}: {e}")
                    failed_count += 1
                    continue
            
            logger.info(
                f"–ó–∞–≤–µ—Ä—à–µ–Ω–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π –∏–∑ —á–∞—Ç–∞ {chat_name}: "
                f"{indexed_count} —É—Å–ø–µ—à–Ω–æ, {failed_count} –æ—à–∏–±–æ–∫"
            )
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –ø—Ä–æ—Ñ–∏–ª–µ–π —Å—É—â–Ω–æ—Å—Ç–µ–π: {e}")


if __name__ == "__main__":
    # –¢–µ—Å—Ç –º–æ–¥—É–ª—è
    async def test():
        indexer = TwoLevelIndexer()
        stats = await indexer.build_index(scope="all", recent_days=7)
        print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {stats}")

    asyncio.run(test())
