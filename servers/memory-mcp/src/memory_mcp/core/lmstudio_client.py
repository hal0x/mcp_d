#!/usr/bin/env python3
"""
–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å LM Studio Server API –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
"""

import asyncio
import logging
import random
from typing import Any, Dict, List, Optional

import aiohttp

from .constants import (
    DEFAULT_TIMEOUT_CONNECT,
    DEFAULT_TIMEOUT_MAX_RETRY,
    HTTP_CONNECTOR_LIMIT,
    HTTP_CONNECTOR_LIMIT_PER_HOST,
)

logger = logging.getLogger(__name__)


class LMStudioEmbeddingClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ LM Studio Server
    
    –í–ê–ñ–ù–û: 
    - model_name –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¢–û–õ–¨–ö–û –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (endpoint /v1/embeddings)
    - llm_model_name –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ (endpoint /v1/chat/completions)
    - –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞!
    """

    def __init__(
        self,
        model_name: str = "text-embedding-qwen3-embedding-0.6b",
        llm_model_name: Optional[str] = None,  # –ú–æ–¥–µ–ª—å –¥–ª—è LLM –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞
        base_url: str = "http://127.0.0.1:1234",
        max_text_length: int = 16384,  # 4096 —Ç–æ–∫–µ–Ω–æ–≤ * 4 —Å–∏–º–≤–æ–ª–∞/—Ç–æ–∫–µ–Ω –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞
    ):
        self.model_name = model_name  # –ú–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        self.llm_model_name = llm_model_name  # –ú–æ–¥–µ–ª—å –¥–ª—è LLM –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è model_name, —á—Ç–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ)
        self.base_url = base_url.rstrip("/")
        self.max_text_length = max_text_length
        self.session = None
        self._embedding_dimension: Optional[int] = None

    async def __aenter__(self):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä - –≤—Ö–æ–¥"""
        self.session = aiohttp.ClientSession()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä - –≤—ã—Ö–æ–¥"""
        if self.session:
            await self.session.close()

    async def check_model_availability(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ —Ä–µ–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å"""
        try:
            if not self.session:
                self.session = aiohttp.ClientSession()
            
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
            async with self.session.get(f"{self.base_url}/v1/models") as response:
                if response.status == 200:
                    data = await response.json()
                    models = [model.get("id", "") for model in data.get("data", [])]
                    if self.model_name not in models:
                        logger.warning(
                            f"–ú–æ–¥–µ–ª—å '{self.model_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Å–ø–∏—Å–∫–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. "
                            f"–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {', '.join(models[:5])}"
                        )
                        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —á–µ—Ä–µ–∑ —Ä–µ–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å, —Ç–∞–∫ –∫–∞–∫ –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ—Å—Ç—É–ø–Ω–∞
                        # –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ –≤ —Å–ø–∏—Å–∫–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –æ–Ω–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∫–∞–∫ embedding –º–æ–¥–µ–ª—å)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∞–ª—å–Ω—É—é –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ /v1/embeddings
            # –≠—Ç–æ –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π —Å–ø–æ—Å–æ–±, —Ç–∞–∫ –∫–∞–∫ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –º–æ–≥—É—Ç –Ω–µ –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å—Å—è
            # –≤ /v1/models, –Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å —á–µ—Ä–µ–∑ /v1/embeddings
            test_payload = {"model": self.model_name, "input": "test"}
            async with self.session.post(
                f"{self.base_url}/v1/embeddings",
                json=test_payload,
                timeout=aiohttp.ClientTimeout(total=10)
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    if "data" in data and len(data.get("data", [])) > 0:
                        embedding = data["data"][0].get("embedding")
                        if embedding and isinstance(embedding, list):
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏ –ø–µ—Ä–≤–æ–π —É—Å–ø–µ—à–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–µ
                            if self._embedding_dimension is None:
                                self._embedding_dimension = len(embedding)
                            return True
                
                # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –æ—à–∏–±–∫—É, –ª–æ–≥–∏—Ä—É–µ–º –µ—ë –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                if response.status != 200:
                    error_text = await response.text()
                    logger.warning(
                        f"–ú–æ–¥–µ–ª—å '{self.model_name}' –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤. "
                        f"HTTP {response.status}: {error_text[:200]}"
                    )
                return False
                
        except asyncio.TimeoutError:
            logger.warning(f"–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –º–æ–¥–µ–ª–∏ '{self.model_name}'")
            return False
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –º–æ–¥–µ–ª–∏ '{self.model_name}': {e}")
            return False

    async def get_embedding(self, text: str) -> List[float]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        embeddings = await self.generate_embeddings([text])
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
        if embeddings and self._embedding_dimension is None:
            self._embedding_dimension = len(embeddings[0])
        return embeddings[0] if embeddings else [0.0] * (self._embedding_dimension or 1024)

    async def generate_embeddings(self, texts: List[str], batch_size: int = 32) -> List[List[float]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤ —Å –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        if not texts:
            return []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LM Studio –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º —Ä–∞–±–æ—Ç—ã
        if not await self.check_model_availability():
            logger.error("LM Studio Server –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            default_dim = self._embedding_dimension or 1024
            return [[0.0] * default_dim] * len(texts)

        if len(texts) == 1:
            # –î–ª—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥
            text_preview = texts[0][:30] + "..." if len(texts[0]) > 30 else texts[0]
            logger.debug(f"üî§ –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {text_preview}")
            embedding = await self._process_single_text_async(texts[0], 0, 1)
            return [embedding] if embedding else [[0.0] * (self._embedding_dimension or 1024)]

        logger.info(f"üî§ –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤ –±–∞—Ç—á–∞–º–∏ –ø–æ {batch_size}...")

        # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç—ã –Ω–∞ –±–∞—Ç—á–∏
        batches = []
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            batches.append((i, batch))

        all_embeddings = []
        default_dim = self._embedding_dimension or 1024

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –±–∞—Ç—á
        for batch_idx, (start_idx, batch_texts) in enumerate(batches):
            try:
                logger.debug(f"üî§ –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ {batch_idx + 1}/{len(batches)} ({len(batch_texts)} —Ç–µ–∫—Å—Ç–æ–≤)")
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–∞—Ç—á –Ω–∞ —Å–µ—Ä–≤–µ—Ä
                batch_embeddings = await self._generate_batch_embeddings(batch_texts)
                
                if batch_embeddings:
                    all_embeddings.extend(batch_embeddings)
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏ –ø–µ—Ä–≤–æ–º —É—Å–ø–µ—à–Ω–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
                    if self._embedding_dimension is None and batch_embeddings[0]:
                        self._embedding_dimension = len(batch_embeddings[0])
                else:
                    # –ï—Å–ª–∏ –±–∞—Ç—á –Ω–µ —É–¥–∞–ª—Å—è, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
                    logger.warning(f"–ë–∞—Ç—á {batch_idx + 1} –Ω–µ —É–¥–∞–ª—Å—è, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏")
                    all_embeddings.extend([[0.0] * default_dim] * len(batch_texts))
                    
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–∞—Ç—á–∞ {batch_idx + 1}: {e}")
                # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —ç—Ç–æ–≥–æ –±–∞—Ç—á–∞
                all_embeddings.extend([[0.0] * default_dim] * len(batch_texts))

        return all_embeddings

    async def _generate_batch_embeddings(self, texts: List[str]) -> List[List[float]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –±–∞—Ç—á–∞ —Ç–µ–∫—Å—Ç–æ–≤ —á–µ—Ä–µ–∑ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É"""
        if not texts:
            return []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        tasks = []
        for i, text in enumerate(texts):
            task = self._process_single_text_async(text, i, len(texts))
            tasks.append(task)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        embeddings = await asyncio.gather(*tasks, return_exceptions=True)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
        result = []
        default_dim = self._embedding_dimension or 1024
        for i, emb in enumerate(embeddings):
            if isinstance(emb, Exception):
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ {i+1}: {emb}")
                result.append([0.0] * default_dim)
            elif emb:
                result.append(emb)
            else:
                result.append([0.0] * default_dim)
        
        return result

    async def _process_single_text_async(
        self, text: str, index: int, total: int
    ) -> List[float]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        try:
            # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –Ω–∞ —á–∞—Å—Ç–∏
            text_chunks = self._split_text_into_chunks(text)

            if len(text_chunks) == 1:
                # –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω–æ
                embedding = await self._generate_single_embedding(text)
                if embedding:
                    return embedding
                else:
                    logger.warning(
                        f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–µ–∫—Å—Ç–∞: {text[:50]}..."
                    )
                    default_dim = self._embedding_dimension or 1024
                    return [0.0] * default_dim
            else:
                # –î–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ —á–∞—Å—Ç—è–º –∏ —É—Å—Ä–µ–¥–Ω—è–µ–º
                chunk_embeddings = []
                for j, chunk in enumerate(text_chunks):
                    # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ (–±–æ–ª–µ–µ 3 —á–∞—Å—Ç–µ–π)
                    if len(text_chunks) > 3 and j == 0:
                        logger.debug(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –ø–æ —á–∞—Å—Ç—è–º ({len(text_chunks)} —á–∞—Å—Ç–µ–π)")
                    chunk_embedding = await self._generate_single_embedding(chunk)
                    if chunk_embedding:
                        chunk_embeddings.append(chunk_embedding)
                    else:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —á–∞—Å—Ç–∏ {j+1}")
                        default_dim = self._embedding_dimension or 1024
                        chunk_embeddings.append([0.0] * default_dim)

                # –£—Å—Ä–µ–¥–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –≤—Å–µ—Ö —á–∞—Å—Ç–µ–π
                if chunk_embeddings:
                    averaged_embedding = self._average_embeddings(chunk_embeddings)
                    # –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–ª–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –±–æ–ª—å—à–∏—Ö –≥—Ä—É–ø–ø)
                    if len(chunk_embeddings) > 3:
                        logger.debug(
                            f"–£—Å—Ä–µ–¥–Ω–µ–Ω —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏–∑ {len(chunk_embeddings)} —á–∞—Å—Ç–µ–π"
                        )
                    return averaged_embedding
                else:
                    default_dim = self._embedding_dimension or 1024
                    return [0.0] * default_dim

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            default_dim = self._embedding_dimension or 1024
            return [0.0] * default_dim

    def _split_text_into_chunks(self, text: str, max_length: int = None) -> List[str]:
        """–†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤"""
        if max_length is None:
            max_length = self.max_text_length

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ —Ç–æ–∫–µ–Ω–∞–º, –∞ –Ω–µ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
        # –î–ª—è Qwen3-Embedding –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ü–µ–Ω–∫—É: ~1.2 —Å–∏–º–≤–æ–ª–∞/—Ç–æ–∫–µ–Ω
        estimated_tokens = len(text) // 1.2
        max_tokens = max_length // 3.5

        if estimated_tokens <= max_tokens:
            return [text]

        chunks = []
        start = 0
        chunk_size_chars = max_tokens * 4  # –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –≤ —Å–∏–º–≤–æ–ª–∞—Ö

        while start < len(text):
            end = start + chunk_size_chars

            if end >= len(text):
                # –ü–æ—Å–ª–µ–¥–Ω–∏–π –∫—É—Å–æ–∫
                chunks.append(text[start:])
                break

            # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø—Ä–æ–±–µ–ª –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö chunk_size_chars
            last_space = text.rfind(" ", start, end)
            if (
                last_space > start + chunk_size_chars * 0.7
            ):  # –ï—Å–ª–∏ –ø—Ä–æ–±–µ–ª –Ω–µ —Å–ª–∏—à–∫–æ–º –¥–∞–ª–µ–∫–æ
                chunks.append(text[start:last_space])
                start = last_space + 1  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–±–µ–ª
            else:
                # –ï—Å–ª–∏ –ø—Ä–æ–±–µ–ª —Å–ª–∏—à–∫–æ–º –¥–∞–ª–µ–∫–æ, –æ–±—Ä–µ–∑–∞–µ–º –ø–æ —Å–∏–º–≤–æ–ª–∞–º
                chunks.append(text[start:end])
                start = end

        # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞–∑–º–µ—Ä–∞—Ö —á–∞–Ω–∫–æ–≤
        if len(chunks) > 1:
            chunk_tokens = [len(chunk) // 3.5 for chunk in chunks]
            logger.debug(
                f"–î–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(chunks)} —á–∞—Å—Ç–µ–π "
                f"(~{estimated_tokens} —Ç–æ–∫–µ–Ω–æ–≤ -> ~{sum(chunk_tokens)} —Ç–æ–∫–µ–Ω–æ–≤ –≤ —á–∞–Ω–∫–∞—Ö)"
            )

        return chunks

    def _average_embeddings(self, embeddings: List[List[float]]) -> List[float]:
        """–£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ –æ–¥–∏–Ω"""
        if not embeddings:
            default_dim = self._embedding_dimension or 1024
            return [0.0] * default_dim

        if len(embeddings) == 1:
            return embeddings[0]

        # –£—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ –∫–∞–∂–¥–æ–º—É –∏–∑–º–µ—Ä–µ–Ω–∏—é
        dimension = len(embeddings[0])
        averaged = []

        for i in range(dimension):
            sum_val = sum(emb[i] for emb in embeddings)
            averaged.append(sum_val / len(embeddings))

        return averaged

    def _truncate_text(self, text: str, max_length: int = None) -> str:
        """–û–±—Ä–µ–∑–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤"""
        if max_length is None:
            max_length = self.max_text_length

        if len(text) <= max_length:
            return text

        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø—Ä–æ–±–µ–ª–∞, —á—Ç–æ–±—ã –Ω–µ —Ä–∞–∑—Ä—ã–≤–∞—Ç—å —Å–ª–æ–≤–∞
        truncated = text[:max_length]
        last_space = truncated.rfind(" ")
        if last_space > max_length * 0.8:  # –ï—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø—Ä–æ–±–µ–ª –Ω–µ —Å–ª–∏—à–∫–æ–º –¥–∞–ª–µ–∫–æ
            result = truncated[:last_space]
        else:
            result = truncated

        logger.warning(
            f"–¢–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω —Å {len(text)} –¥–æ {len(result)} —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤"
        )
        return result

    async def _generate_single_embedding(self, text: str) -> Optional[List[float]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞
        if len(text) > self.max_text_length:
            logger.warning(
                f"–¢–µ–∫—Å—Ç –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç ({len(text)} > {self.max_text_length}), –æ–±—Ä–µ–∑–∞–µ–º"
            )
            text = text[: self.max_text_length]

        # LM Studio –∏—Å–ø–æ–ª—å–∑—É–µ—Ç OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç
        payload = {"model": self.model_name, "input": text}

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Å—Å–∏—é –æ–¥–∏–Ω —Ä–∞–∑ –ø–µ—Ä–µ–¥ —Ü–∏–∫–ª–æ–º retry, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if not self.session:
            connector = aiohttp.TCPConnector(
                limit=HTTP_CONNECTOR_LIMIT,
                limit_per_host=HTTP_CONNECTOR_LIMIT_PER_HOST,
                ttl_dns_cache=300,
                use_dns_cache=True,
                enable_cleanup_closed=True,
                force_close=True,
                ssl=False,
            )
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π —Ç–∞–π–º–∞—É—Ç –¥–ª—è —Å–µ—Å—Å–∏–∏, –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–∞–π–º–∞—É—Ç—ã –±—É–¥—É—Ç –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö
            timeout = aiohttp.ClientTimeout(
                total=DEFAULT_TIMEOUT_MAX_RETRY,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –¥–ª—è retry
                connect=DEFAULT_TIMEOUT_CONNECT,
                sock_read=DEFAULT_TIMEOUT_MAX_RETRY,
                sock_connect=DEFAULT_TIMEOUT_CONNECT,
            )
            self.session = aiohttp.ClientSession(
                connector=connector,
                timeout=timeout,
                headers={"Connection": "close"},
            )

        # –ü–æ–≤—Ç–æ—Ä–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏ —Å —Ä–∞–∑—É–º–Ω—ã–º–∏ —Ç–∞–π–º–∞—É—Ç–∞–º–∏ –∏ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π
        for attempt in range(3):
            try:
                # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–µ —Ç–∞–π–º–∞—É—Ç—ã: 60, 90, 120 —Å–µ–∫—É–Ω–¥
                timeout_seconds = 60 + (attempt * 30)

                # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–∫–∞—Ö
                if attempt > 0:
                    logger.debug(f"–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –∫ LM Studio ({attempt + 1}/3)")

                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∞–π–º–∞—É—Ç –¥–ª—è –≤—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
                async with asyncio.timeout(timeout_seconds):
                    async with self.session.post(
                        f"{self.base_url}/v1/embeddings", json=payload
                    ) as response:
                        if response.status == 200:
                            data = await response.json()
                            # LM Studio –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç:
                            # {"data": [{"embedding": [...], "index": 0, "object": "embedding"}]}
                            if "data" in data and len(data["data"]) > 0:
                                embedding = data["data"][0].get("embedding")
                                if embedding:
                                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏ –ø–µ—Ä–≤–æ–º —É—Å–ø–µ—à–Ω–æ–º –∑–∞–ø—Ä–æ—Å–µ
                                    if self._embedding_dimension is None:
                                        self._embedding_dimension = len(embedding)
                                    return embedding
                                else:
                                    logger.error("LM Studio –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π embedding")
                                    if attempt < 2:
                                        await asyncio.sleep(2 + attempt)
                                        continue
                                    return None
                            else:
                                logger.error("LM Studio –≤–µ—Ä–Ω—É–ª –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö")
                                if attempt < 2:
                                    await asyncio.sleep(2 + attempt)
                                    continue
                                return None
                        else:
                            error_text = await response.text()
                            logger.error(
                                f"–û—à–∏–±–∫–∞ API LM Studio: {response.status} - {error_text}"
                            )
                            if attempt < 2:  # –ù–µ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞
                                await asyncio.sleep(2 + attempt)  # 2, 3 —Å–µ–∫—É–Ω–¥—ã
                                continue
                            return None
            except asyncio.TimeoutError:
                logger.error(
                    f"–¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –∫ LM Studio (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/3)"
                )
                if attempt < 2:
                    # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ —Å jitter: 2^attempt + —Å–ª—É—á–∞–π–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (0-1)
                    delay = (2 ** attempt) + random.uniform(0, 1)
                    await asyncio.sleep(delay)
                    continue
                return None
            except aiohttp.ClientError as e:
                error_str = str(e)
                is_connection_reset = "Connection reset" in error_str or "Errno 54" in error_str
                
                if is_connection_reset:
                    logger.warning(
                        f"–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å LM Studio —Ä–∞–∑–æ—Ä–≤–∞–Ω–æ —Å–µ—Ä–≤–µ—Ä–æ–º (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/3). "
                        f"–í–æ–∑–º–æ–∂–Ω–æ, —Å–µ—Ä–≤–µ—Ä –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω –∏–ª–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è. "
                        f"–û—à–∏–±–∫–∞: {e}"
                    )
                    # –ü—Ä–∏ Connection reset –ø–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–∏
                    if attempt < 2:
                        try:
                            if self.session:
                                await self.session.close()
                        except Exception:
                            pass
                        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é
                        connector = aiohttp.TCPConnector(
                            limit=HTTP_CONNECTOR_LIMIT,
                            limit_per_host=HTTP_CONNECTOR_LIMIT_PER_HOST,
                            ttl_dns_cache=300,
                            use_dns_cache=True,
                            enable_cleanup_closed=True,
                            force_close=True,
                            ssl=False,
                        )
                        timeout = aiohttp.ClientTimeout(
                            total=DEFAULT_TIMEOUT_MAX_RETRY,
                            connect=DEFAULT_TIMEOUT_CONNECT,
                            sock_read=DEFAULT_TIMEOUT_MAX_RETRY,
                            sock_connect=DEFAULT_TIMEOUT_CONNECT,
                        )
                        self.session = aiohttp.ClientSession(
                            connector=connector,
                            timeout=timeout,
                            headers={"Connection": "close"},
                        )
                        # –ë–æ–ª–µ–µ –¥–ª–∏–Ω–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è Connection reset: —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è —Å jitter
                        # 5, 10, 20 —Å–µ–∫—É–Ω–¥ + —Å–ª—É—á–∞–π–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (0-2)
                        delay = (5 * (2 ** attempt)) + random.uniform(0, 2)
                        logger.debug(f"–û–∂–∏–¥–∞–Ω–∏–µ {delay:.2f} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π...")
                        await asyncio.sleep(delay)
                        continue
                else:
                    logger.error(
                        f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å LM Studio (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/3): {e}"
                    )
                    if attempt < 2:  # –ù–µ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞
                        # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ —Å jitter: 2^attempt * 2 + —Å–ª—É—á–∞–π–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (0-1)
                        delay = (2 ** attempt) * 2 + random.uniform(0, 1)
                        await asyncio.sleep(delay)
                        continue
                return None
            except aiohttp.InvalidURL as e:
                logger.error(
                    f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL –≤ –∑–∞–ø—Ä–æ—Å–µ –∫ LM Studio (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/3): {e}"
                )
                # –î–ª—è –æ—à–∏–±–æ–∫ URL –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–µ–º –ø–æ–ø—ã—Ç–∫–∏
                return None
            except aiohttp.ServerTimeoutError as e:
                logger.error(f"–¢–∞–π–º–∞—É—Ç —Å–µ—Ä–≤–µ—Ä–∞ LM Studio (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/3): {e}")
                if attempt < 2:  # –ù–µ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞
                    # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ —Å jitter
                    delay = (2 ** attempt) * 3 + random.uniform(0, 1)
                    await asyncio.sleep(delay)
                    continue
                return None
            except Exception as e:
                logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ LM Studio: {e}")
                if attempt < 2:  # –ù–µ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞
                    # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ —Å jitter
                    delay = (2 ** attempt) * 2 + random.uniform(0, 1)
                    await asyncio.sleep(delay)
                    continue
                return None

        return None

    async def test_connection(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LM Studio Server"""
        result = {
            "lmstudio_available": False,
            "model_available": False,
            "model_name": self.model_name,
            "base_url": self.base_url,
            "error": None,
        }

        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Å—Å–∏—é –µ—Å–ª–∏ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞
            if not self.session:
                self.session = aiohttp.ClientSession()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LM Studio Server
            try:
                async with self.session.get(
                    f"{self.base_url}/v1/models",
                    timeout=aiohttp.ClientTimeout(total=5)
                ) as response:
                    if response.status == 200:
                        result["lmstudio_available"] = True
                        data = await response.json()
                        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª—è—Ö
                        models = data.get("data", [])
                        result["available_models"] = [m.get("id", "") for m in models]
                    else:
                        result["error"] = f"HTTP {response.status}: {await response.text()}"
            except asyncio.TimeoutError:
                result["error"] = "–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –∫ LM Studio Server"
                return result
            except Exception as e:
                result["error"] = f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {str(e)}"
                return result

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ —Ä–µ–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            # –≠—Ç–æ –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ, —á–µ–º –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π
            if result["lmstudio_available"]:
                result["model_available"] = await self.check_model_availability()
                if not result["model_available"]:
                    # –î–æ–±–∞–≤–ª—è–µ–º –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ
                    if not result.get("error"):
                        result["error"] = (
                            f"–ú–æ–¥–µ–ª—å '{self.model_name}' –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤. "
                            f"–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –≤ LM Studio –∏ –¥–æ—Å—Ç—É–ø–Ω–∞ —á–µ—Ä–µ–∑ /v1/embeddings endpoint."
                        )

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
            result["error"] = str(e)

        return result

    def _estimate_tokens(self, text: str) -> int:
        """
        –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ
        –î–ª—è Qwen3-Embedding –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ü–µ–Ω–∫—É: ~1.2 —Å–∏–º–≤–æ–ª–∞ = 1 —Ç–æ–∫–µ–Ω
        """
        return len(text) // 1.2

    def _split_prompt(self, prompt: str, max_prompt_tokens: int = 31000) -> List[str]:
        """
        –†–∞–∑–±–∏–≤–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –Ω–∞ —á–∞—Å—Ç–∏, –µ—Å–ª–∏ –æ–Ω –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤

        Args:
            prompt: –ò—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            max_prompt_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –ø—Ä–æ–º–ø—Ç–µ

        Returns:
            –°–ø–∏—Å–æ–∫ —á–∞—Å—Ç–µ–π –ø—Ä–æ–º–ø—Ç–∞
        """
        estimated_tokens = self._estimate_tokens(prompt)

        if estimated_tokens <= max_prompt_tokens:
            return [prompt]

        # –†–∞–∑–±–∏–≤–∞–µ–º –ø—Ä–æ–º–ø—Ç –Ω–∞ —á–∞—Å—Ç–∏
        logger.warning(
            f"‚ö†Ô∏è  –ü—Ä–æ–º–ø—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π ({estimated_tokens} —Ç–æ–∫–µ–Ω–æ–≤), —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏ (–ª–∏–º–∏—Ç {max_prompt_tokens})"
        )

        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ –¥–ª—è –±–æ–ª–µ–µ —É–º–Ω–æ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è
        conversation_markers = [
            "–ò–°–•–û–î–ù–´–ô –†–ê–ó–ì–û–í–û–†:",
            "–†–∞–∑–≥–æ–≤–æ—Ä:",
            "–°–æ–æ–±—â–µ–Ω–∏—è:",
            "conversation_text:",
            "conversation:",
        ]

        system_part = ""
        conversation_part = ""

        for marker in conversation_markers:
            if marker in prompt:
                parts = prompt.split(marker, 1)
                if len(parts) == 2:
                    system_part = parts[0] + marker
                    conversation_part = parts[1]
                    break

        if not conversation_part:
            # –ï—Å–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–º–ø—Ç–∞ –¥—Ä—É–≥–∞—è, —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Å–∏–º–≤–æ–ª–∞–º
            max_chars = max_prompt_tokens * 1.2
            chunks = []
            for i in range(0, len(prompt), max_chars):
                chunks.append(prompt[i : i + max_chars])
            return chunks

        # –†–∞–∑–±–∏–≤–∞–µ–º —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞ —á–∞—Å—Ç–∏
        max_conversation_tokens = (
            max_prompt_tokens - self._estimate_tokens(system_part) - 100
        )  # –∑–∞–ø–∞—Å
        max_conversation_chars = max_conversation_tokens * 1.2

        conversation_chunks = []
        for i in range(0, len(conversation_part), max_conversation_chars):
            conversation_chunks.append(
                conversation_part[i : i + max_conversation_chars]
            )

        # –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–π —á–∞—Å—Ç–∏
        prompts = []
        for i, chunk in enumerate(conversation_chunks):
            if i == 0:
                chunk_prompt = system_part + chunk
            else:
                chunk_prompt = f"{system_part}\n(–ü–†–û–î–û–õ–ñ–ï–ù–ò–ï –†–ê–ó–ì–û–í–û–†–ê - —á–∞—Å—Ç—å {i+1}/{len(conversation_chunks)})\n{chunk}"
            prompts.append(chunk_prompt)

        logger.info(f"üìù –ü—Ä–æ–º–ø—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(prompts)} —á–∞—Å—Ç–µ–π")
        return prompts

    async def generate_summary(
        self,
        prompt: str,
        temperature: float = 0.3,
        max_tokens: int = 900,
        top_p: float = 0.93,
        presence_penalty: float = 0.05,
        max_prompt_tokens: int = 30000,
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ LLM —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Ä–∞–∑–±–∏–≤–∫–æ–π –¥–ª–∏–Ω–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤

        Args:
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
            top_p: Top-p –ø–∞—Ä–∞–º–µ—Ç—Ä
            presence_penalty: Presence penalty
            max_prompt_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –ø—Ä–æ–º–ø—Ç–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 30000, –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ª–∏–º–∏—Ç –¥–ª—è 32768 –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)

        Returns:
            –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –ø—Ä–æ–º–ø—Ç–∞ –∏ —Ä–∞–∑–±–∏–≤–∞–µ–º –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        prompt_parts = self._split_prompt(prompt, max_prompt_tokens)

        if len(prompt_parts) == 1:
            # –û–±—ã—á–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
            return await self._generate_single_summary(
                prompt_parts[0], temperature, max_tokens, top_p, presence_penalty
            )
        else:
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ —á–∞—Å—Ç—è–º –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            logger.info(
                f"üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –ø–æ —á–∞—Å—Ç—è–º ({len(prompt_parts)} —á–∞—Å—Ç–µ–π)"
            )
            summaries = []

            for i, part_prompt in enumerate(prompt_parts):
                logger.info(f"üìù –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞—Å—Ç–∏ {i+1}/{len(prompt_parts)}")
                part_summary = await self._generate_single_summary(
                    part_prompt, temperature, max_tokens, top_p, presence_penalty
                )
                summaries.append(part_summary)

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            combined = "\n\n".join(summaries)
            logger.info(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω—ã {len(summaries)} —á–∞—Å—Ç–µ–π —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏")
            return combined

    async def _generate_single_summary(
        self,
        prompt: str,
        temperature: float,
        max_tokens: int,
        top_p: float,
        presence_penalty: float,
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ —á–µ—Ä–µ–∑ LM Studio Server
        
        –í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç llm_model_name –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞, –∞ –Ω–µ model_name (–º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤).
        –ï—Å–ª–∏ llm_model_name –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –≤—ã–¥–∞–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—à–∏–±–∫—É.
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ LLM –º–æ–¥–µ–ª—å (–Ω–µ –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤)
        llm_model = self.llm_model_name
        if not llm_model:
            error_msg = (
                f"–û–®–ò–ë–ö–ê: –î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –Ω—É–∂–Ω–∞ LLM –º–æ–¥–µ–ª—å, –∞ –Ω–µ –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤. "
                f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: '{self.model_name}'. "
                f"–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ llm_model_name –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ LMStudioEmbeddingClient –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Ollama –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞."
            )
            logger.error(error_msg)
            return f"–û—à–∏–±–∫–∞: {error_msg}"
        
        # LM Studio –∏—Å–ø–æ–ª—å–∑—É–µ—Ç OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API –¥–ª—è chat completions
        payload = {
            "model": llm_model,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º LLM –º–æ–¥–µ–ª—å, –∞ –Ω–µ –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            "messages": [
                {
                    "role": "system",
                    "content": "You are a helpful AI assistant. Follow the user's instructions carefully and provide accurate responses.",
                },
                {"role": "user", "content": prompt},
            ],
            "temperature": temperature,
            "max_tokens": max_tokens,
            "top_p": top_p,
            "presence_penalty": presence_penalty,
            "stream": False,
        }

        # –ü–æ–≤—Ç–æ—Ä–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∞–º–º–∞—Ä–∏ (–¥–æ 2 –ø–æ–ø—ã—Ç–æ–∫)
        for attempt in range(2):
            try:
                if not self.session:
                    connector = aiohttp.TCPConnector(
                        limit=HTTP_CONNECTOR_LIMIT,
                        limit_per_host=HTTP_CONNECTOR_LIMIT_PER_HOST,
                        ttl_dns_cache=300,
                        use_dns_cache=True,
                        enable_cleanup_closed=True,
                        force_close=True,
                        ssl=False,
                    )
                    timeout = aiohttp.ClientTimeout(
                        total=300,  # 5 –º–∏–Ω—É—Ç –¥–ª—è LLM
                        connect=DEFAULT_TIMEOUT_CONNECT,
                    )
                    self.session = aiohttp.ClientSession(
                        connector=connector,
                        timeout=timeout,
                        headers={"Connection": "close"},
                    )
                
                async with self.session.post(
                    f"{self.base_url}/v1/chat/completions", json=payload
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        # LM Studio –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç:
                        # {"choices": [{"message": {"content": "..."}}]}
                        if "choices" in data and len(data["choices"]) > 0:
                            return data["choices"][0]["message"]["content"].strip()
                        else:
                            logger.error("LM Studio –≤–µ—Ä–Ω—É–ª –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö")
                            return "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞"
                    else:
                        error_text = await response.text()
                        logger.error(f"–û—à–∏–±–∫–∞ API LM Studio: {response.status} - {error_text}")
                        if attempt < 1:
                            await asyncio.sleep(3 + random.uniform(0, 1))
                            continue
                        return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: HTTP {response.status}"
            except aiohttp.ClientError as e:
                error_str = str(e)
                is_connection_reset = "Connection reset" in error_str or "Errno 54" in error_str
                
                if is_connection_reset:
                    logger.warning(
                        f"–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å LM Studio —Ä–∞–∑–æ—Ä–≤–∞–Ω–æ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∞–º–º–∞—Ä–∏ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/2). "
                        f"–û—à–∏–±–∫–∞: {e}"
                    )
                    # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é –ø—Ä–∏ Connection reset
                    if attempt < 1:
                        try:
                            if self.session:
                                await self.session.close()
                        except Exception:
                            pass
                        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é
                        connector = aiohttp.TCPConnector(
                            limit=HTTP_CONNECTOR_LIMIT,
                            limit_per_host=HTTP_CONNECTOR_LIMIT_PER_HOST,
                            ttl_dns_cache=300,
                            use_dns_cache=True,
                            enable_cleanup_closed=True,
                            force_close=True,
                            ssl=False,
                        )
                        timeout = aiohttp.ClientTimeout(
                            total=300,
                            connect=DEFAULT_TIMEOUT_CONNECT,
                        )
                        self.session = aiohttp.ClientSession(
                            connector=connector,
                            timeout=timeout,
                            headers={"Connection": "close"},
                        )
                        # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
                        delay = 5 + random.uniform(0, 2)
                        logger.debug(f"–û–∂–∏–¥–∞–Ω–∏–µ {delay:.2f} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏...")
                        await asyncio.sleep(delay)
                        continue
                else:
                    logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å LM Studio –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∞–º–º–∞—Ä–∏: {e}")
                    if attempt < 1:
                        delay = 3 + random.uniform(0, 1)
                        await asyncio.sleep(delay)
                        continue
                return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}"
            except aiohttp.InvalidURL as e:
                logger.error(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL –≤ –∑–∞–ø—Ä–æ—Å–µ –∫ LM Studio: {e}")
                return "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL"
            except asyncio.TimeoutError:
                logger.error(f"–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∞–º–º–∞—Ä–∏ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/2)")
                if attempt < 1:
                    delay = 5 + random.uniform(0, 1)
                    await asyncio.sleep(delay)
                    continue
                return "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: —Ç–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞"
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {e}")
                if attempt < 1:
                    delay = 3 + random.uniform(0, 1)
                    await asyncio.sleep(delay)
                    continue
                return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}"
        
        return "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: –Ω–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫"

