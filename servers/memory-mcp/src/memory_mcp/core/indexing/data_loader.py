"""–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏."""

import logging
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from ...analysis.segmentation import DayGroupingSegmenter, SessionSegmenter
from ...analysis.utils import TimeProcessor
from ...utils.system.naming import slugify

logger = logging.getLogger(__name__)

MIN_SESSION_MESSAGES = 15


class DataLoader:
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ JSON, –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–Ω—è–º, –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –º–∞–ª–µ–Ω—å–∫–∏—Ö —Å–µ—Å—Å–∏–π."""

    def __init__(
        self,
        session_segmenter: SessionSegmenter,
        day_grouping_segmenter: DayGroupingSegmenter,
        time_processor: Optional[TimeProcessor] = None,
        enable_time_analysis: bool = False,
    ):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö.

        Args:
            session_segmenter: –°–µ–≥–º–µ–Ω—Ç–∞—Ç–æ—Ä —Å–µ—Å—Å–∏–π
            day_grouping_segmenter: –°–µ–≥–º–µ–Ω—Ç–∞—Ç–æ—Ä –¥–Ω–µ–≤–Ω—ã—Ö –≥—Ä—É–ø–ø
            time_processor: –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            enable_time_analysis: –í–∫–ª—é—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        """
        self.session_segmenter = session_segmenter
        self.day_grouping_segmenter = day_grouping_segmenter
        self.time_processor = time_processor
        self.enable_time_analysis = enable_time_analysis

    async def load_messages_from_chat(self, chat_dir: Path) -> List[Dict[str, Any]]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ JSON —Ñ–∞–π–ª–æ–≤ —á–∞—Ç–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—â—É—é —É—Ç–∏–ª–∏—Ç—É).

        Args:
            chat_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —á–∞—Ç–∞

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
        """
        from ...utils.data.json_loader import load_json_or_jsonl

        messages = []
        json_files = list(chat_dir.glob("*.json"))

        for json_file in json_files:
            try:
                file_messages, _ = load_json_or_jsonl(json_file)
                messages.extend(file_messages)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {json_file}: {e}")
                continue

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        messages.sort(key=lambda x: x.get("date_utc") or x.get("date", ""))

        return messages

    def expand_day_groups(
        self, day_groups: List[Dict[str, Any]], chat_name: Optional[str]
    ) -> List[Dict[str, Any]]:
        """–†–∞—Å—à–∏—Ä—è–µ—Ç –¥–Ω–µ–≤–Ω—ã–µ –≥—Ä—É–ø–ø—ã –≤ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ —Å —É—á—ë—Ç–æ–º —Ä–∞–∑—Ä—ã–≤–æ–≤."""
        if not day_groups:
            return []

        sessions: List[Dict[str, Any]] = []
        chat_slug = slugify(chat_name) if chat_name else ""

        for day_index, day_group in enumerate(day_groups):
            base_id = day_group.get("session_id")
            if not base_id:
                base_id = (
                    f"{chat_slug}-D{day_index + 1:04d}"
                    if chat_slug
                    else f"D{day_index + 1:04d}"
                )

            raw_messages = day_group.get("messages", [])
            splitted = self.session_segmenter.segment_messages(raw_messages, chat_name)
            merged_segments = (
                self.merge_small_sessions(
                    splitted,
                    chat_name=chat_name,
                    min_messages=MIN_SESSION_MESSAGES,
                )
                if splitted
                else []
            )

            segments_to_use = merged_segments or splitted

            if not segments_to_use:
                session = day_group.copy()
                session["session_id"] = base_id
                session["day_group_id"] = base_id
                session["parent_session_id"] = base_id
                session["group_type"] = day_group.get("group_type", "day_grouped")
                session["chat"] = chat_name
                if chat_slug:
                    session["chat_id"] = chat_slug
                session["messages"] = session.get("messages", raw_messages)
                session["message_count"] = len(session.get("messages", []))

                if self.time_processor and self.enable_time_analysis:
                    try:
                        activity_patterns = self.time_processor.analyze_activity_patterns(
                            session.get("messages", [])
                        )
                        session["activity_patterns"] = activity_patterns
                    except Exception as e:
                        logger.warning(
                            f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è —Å–µ—Å—Å–∏–∏ {base_id}: {e}"
                        )

                sessions.append(session)
                continue

            if len(segments_to_use) == 1:
                session_data = segments_to_use[0].copy()
                session_data["session_id"] = base_id
                session_data["day_group_id"] = base_id
                session_data["parent_session_id"] = base_id
                session_data["group_type"] = session_data.get("group_type") or (
                    "session_segmented"
                    if splitted
                    else day_group.get("group_type", "day_grouped")
                )
                session_data["chat"] = chat_name
                if chat_slug:
                    session_data["chat_id"] = chat_slug
                session_data["messages"] = session_data.get("messages", raw_messages)
                session_data["message_count"] = len(session_data["messages"])

                if self.time_processor and self.enable_time_analysis:
                    try:
                        activity_patterns = self.time_processor.analyze_activity_patterns(
                            session_data.get("messages", [])
                        )
                        session_data["activity_patterns"] = activity_patterns
                    except Exception as e:
                        logger.warning(
                            f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è —Å–µ—Å—Å–∏–∏ {base_id}: {e}"
                        )

                sessions.append(session_data)
                continue

            for split_index, split_session in enumerate(segments_to_use):
                session_copy = split_session.copy()
                session_copy["session_id"] = f"{base_id}-S{split_index + 1:02d}"
                session_copy["day_group_id"] = base_id
                session_copy["parent_session_id"] = base_id
                session_copy["group_type"] = session_copy.get(
                    "group_type", "session_segmented"
                )
                session_copy["chat"] = chat_name
                if chat_slug:
                    session_copy["chat_id"] = chat_slug
                session_copy["messages"] = split_session.get("messages", raw_messages)
                session_copy["message_count"] = len(session_copy["messages"])

                if self.time_processor and self.enable_time_analysis:
                    try:
                        activity_patterns = self.time_processor.analyze_activity_patterns(
                            session_copy.get("messages", [])
                        )
                        session_copy["activity_patterns"] = activity_patterns
                    except Exception as e:
                        logger.warning(
                            f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è —Å–µ—Å—Å–∏–∏ {session_copy['session_id']}: {e}"
                        )

                sessions.append(session_copy)

        return sessions

    def merge_small_sessions(
        self,
        segments: List[Dict[str, Any]],
        chat_name: Optional[str],
        min_messages: int,
    ) -> List[Dict[str, Any]]:
        """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –º–∞–ª–µ–Ω—å–∫–∏–µ —Å–µ—Å—Å–∏–∏ –≤ –±–æ–ª–µ–µ –∫—Ä—É–ø–Ω—ã–µ."""
        if not segments:
            return []

        grouped: List[List[Dict[str, Any]]] = []
        buffer: List[Dict[str, Any]] = []

        def segment_len(segment: Dict[str, Any]) -> int:
            return segment.get("message_count") or len(segment.get("messages", []))

        for segment in segments:
            count = segment_len(segment)
            if not buffer:
                buffer.append(segment)
                continue

            buffer_count = sum(segment_len(item) for item in buffer)

            # –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –º–∞–ª–µ–Ω—å–∫–∏—Ö —Å–µ—Å—Å–∏–π
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –µ—Å–ª–∏:
            # 1. –¢–µ–∫—É—â–∞—è —Å–µ—Å—Å–∏—è –º–µ–Ω—å—à–µ min_messages –ò–õ–ò
            # 2. –ë—É—Ñ–µ—Ä –º–µ–Ω—å—à–µ min_messages –ò–õ–ò
            # 3. –¢–µ–∫—É—â–∞—è —Å–µ—Å—Å–∏—è –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∞—è (‚â§3 —Å–æ–æ–±—â–µ–Ω–∏—è) –ò –±—É—Ñ–µ—Ä —Ç–æ–∂–µ –º–∞–ª–µ–Ω—å–∫–∏–π (‚â§10 —Å–æ–æ–±—â–µ–Ω–∏–π)
            should_merge = (
                count < min_messages
                or buffer_count < min_messages
                or (count <= 3 and buffer_count <= 10)
            )

            if should_merge:
                buffer.append(segment)
            else:
                grouped.append(buffer)
                buffer = [segment]

        if buffer:
            grouped.append(buffer)

        normalized: List[Dict[str, Any]] = []
        for group in grouped:
            total_messages = sum(segment_len(item) for item in group)

            if len(group) == 1 and total_messages >= min_messages:
                segment_copy = group[0].copy()
                segment_copy["group_type"] = segment_copy.get(
                    "group_type", "session_segmented"
                )
                normalized.append(segment_copy)
                continue

            if len(group) > 1:
                segment_sizes = [segment_len(item) for item in group]
                logger.info(
                    f"üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ {len(group)} –º–∞–ª–µ–Ω—å–∫–∏—Ö —Å–µ—Å—Å–∏–π "
                    f"(—Ä–∞–∑–º–µ—Ä—ã: {segment_sizes}) –≤ –æ–¥–Ω—É —Å–µ—Å—Å–∏—é —Å {total_messages} —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏"
                )

            combined_messages: List[Dict[str, Any]] = []
            for segment in group:
                combined_messages.extend(segment.get("messages", []))

            combined_messages.sort(
                key=lambda msg: self.session_segmenter._parse_message_time(msg)
            )

            raw_session = {
                "messages": combined_messages,
                "start_time": self.session_segmenter._parse_message_time(
                    combined_messages[0]
                ),
                "end_time": self.session_segmenter._parse_message_time(
                    combined_messages[-1]
                ),
                "chat": chat_name,
            }
            merged_session = self.session_segmenter._finalize_session(
                raw_session,
                len(normalized),
            )
            merged_session["group_type"] = "session_merged"
            normalized.append(merged_session)

        return normalized

    def parse_message_time(self, msg: Dict[str, Any]) -> datetime:
        """–ü–∞—Ä—Å–∏–Ω–≥ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–æ–±—â–µ–Ω–∏—è (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—â—É—é —É—Ç–∏–ª–∏—Ç—É)."""
        from ...utils.processing.datetime_utils import parse_message_time

        return parse_message_time(msg, use_zoneinfo=True)

    def parse_session_start_time(self, session: Dict[str, Any]) -> datetime:
        """
        –ü–∞—Ä—Å–∏—Ç –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ —Å–µ—Å—Å–∏–∏ –¥–ª—è —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—â—É—é —É—Ç–∏–ª–∏—Ç—É).

        Args:
            session: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ —Å–µ—Å—Å–∏–∏

        Returns:
            datetime: –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ —Å–µ—Å—Å–∏–∏ –∏–ª–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
        """
        from ...utils.processing.datetime_utils import parse_datetime_utc

        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞—á–∞–ª–∞
        start_time = session.get("start_time")
        if start_time:
            if isinstance(start_time, str):
                result = parse_datetime_utc(start_time, use_zoneinfo=True)
                if result:
                    return result
            elif isinstance(start_time, datetime):
                return start_time

        # –ï—Å–ª–∏ –Ω–µ—Ç start_time, –±–µ—Ä–µ–º –≤—Ä–µ–º—è –ø–µ—Ä–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        messages = session.get("messages", [])
        if messages:
            first_message = messages[0]
            msg_date = first_message.get("date_utc")
            if msg_date:
                result = parse_datetime_utc(msg_date, use_zoneinfo=True)
                if result:
                    return result

        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–∞—Ç—É
        return datetime.min.replace(tzinfo=None)

