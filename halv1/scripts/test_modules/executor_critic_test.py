#!/usr/bin/env python3
"""–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è executor –∏ critic —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º."""

import asyncio
import logging
import time
from typing import Dict, Any

from base_tester import BaseTester
from llm.prompts import make_executor_prompt, make_critic_prompt

logger = logging.getLogger(__name__)


class ExecutorCriticTester(BaseTester):
    """–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç–µ—Ä –¥–ª—è executor –∏ critic."""
    
    def __init__(self):
        super().__init__("executor_critic")
    
    async def run_test(self) -> Dict[str, Any]:
        """–î–µ—Ç–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç executor –∏ critic."""
        logger.info("üß™ –î–µ—Ç–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ executor –∏ critic...")
        
        results = {}
        
        # –¢–µ—Å—Ç executor
        logger.info("–¢–µ—Å—Ç–∏—Ä—É–µ–º executor...")
        executor_prompt = make_executor_prompt()
        
        start_time = time.perf_counter()
        try:
            if hasattr(self.client, 'generate') and hasattr(self.client.generate, '__code__'):
                response, _ = self.client.generate(executor_prompt)
            else:
                response = self.client.generate_simple(executor_prompt)
            
            end_time = time.perf_counter()
            execution_time = end_time - start_time
            
            # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–∞
            analysis = self._analyze_executor_response(response)
            
            results["executor"] = {
                "execution_time": execution_time,
                "response": response,
                "response_length": len(response),
                "prompt_length": len(executor_prompt),
                "analysis": analysis,
                "success": True
            }
            
            logger.info(f"‚úÖ Executor: {execution_time:.2f}—Å, –∞–Ω–∞–ª–∏–∑: {analysis['score']:.2f}")
            
        except Exception as e:
            logger.error(f"‚ùå Executor: –û—à–∏–±–∫–∞ - {e}")
            results["executor"] = {
                "execution_time": 0,
                "response": "",
                "response_length": 0,
                "prompt_length": len(executor_prompt),
                "analysis": {"score": 0, "issues": [f"–û—à–∏–±–∫–∞: {e}"]},
                "success": False,
                "error": str(e)
            }
        
        # –¢–µ—Å—Ç critic
        logger.info("–¢–µ—Å—Ç–∏—Ä—É–µ–º critic...")
        critic_prompt = make_critic_prompt()
        
        start_time = time.perf_counter()
        try:
            if hasattr(self.client, 'generate') and hasattr(self.client.generate, '__code__'):
                response, _ = self.client.generate(critic_prompt)
            else:
                response = self.client.generate_simple(critic_prompt)
            
            end_time = time.perf_counter()
            execution_time = end_time - start_time
            
            # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–∞
            analysis = self._analyze_critic_response(response)
            
            results["critic"] = {
                "execution_time": execution_time,
                "response": response,
                "response_length": len(response),
                "prompt_length": len(critic_prompt),
                "analysis": analysis,
                "success": True
            }
            
            logger.info(f"‚úÖ Critic: {execution_time:.2f}—Å, –∞–Ω–∞–ª–∏–∑: {analysis['score']:.2f}")
            
        except Exception as e:
            logger.error(f"‚ùå Critic: –û—à–∏–±–∫–∞ - {e}")
            results["critic"] = {
                "execution_time": 0,
                "response": "",
                "response_length": 0,
                "prompt_length": len(critic_prompt),
                "analysis": {"score": 0, "issues": [f"–û—à–∏–±–∫–∞: {e}"]},
                "success": False,
                "error": str(e)
            }
        
        return {
            "individual_results": results,
            "summary": {
                "executor_score": results["executor"]["analysis"]["score"],
                "critic_score": results["critic"]["analysis"]["score"],
                "total_issues": len(results["executor"]["analysis"]["issues"]) + len(results["critic"]["analysis"]["issues"])
            },
            "success": True
        }
    
    def _analyze_executor_response(self, response: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–∞ executor."""
        response_lower = response.lower()
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è executor
        expected_keywords = [
            "–∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å", "hal", "–≤—ã–ø–æ–ª–Ω—è—é", "–∑–∞–¥–∞—á–∞", "—à–∞–≥", 
            "–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç", "json", "–æ—à–∏–±–∫–∞", "—É—Å–ø–µ—Ö", "–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ"
        ]
        
        found_keywords = [kw for kw in expected_keywords if kw in response_lower]
        score = len(found_keywords) / len(expected_keywords)
        
        issues = []
        if score < 0.5:
            issues.append("–ú–∞–ª–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è")
        if len(response) < 50:
            issues.append("–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç")
        if "json" not in response_lower:
            issues.append("–ù–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç JSON —Ñ–æ—Ä–º–∞—Ç")
        if "–æ—à–∏–±–∫–∞" not in response_lower and "—É—Å–ø–µ—Ö" not in response_lower:
            issues.append("–ù–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤")
        
        return {
            "score": score,
            "found_keywords": found_keywords,
            "missing_keywords": [kw for kw in expected_keywords if kw not in response_lower],
            "issues": issues
        }
    
    def _analyze_critic_response(self, response: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–∞ critic."""
        response_lower = response.lower()
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è critic
        expected_keywords = [
            "–∫—Ä–∏—Ç–∏–∫", "–ø–ª–∞–Ω", "–ø—Ä–æ–≤–µ—Ä–∫–∞", "json", "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å", 
            "–≤—ã–ø–æ–ª–Ω–∏–º–æ—Å—Ç—å", "–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å", "ok", "–ø—Ä–æ–±–ª–µ–º—ã"
        ]
        
        found_keywords = [kw for kw in expected_keywords if kw in response_lower]
        score = len(found_keywords) / len(expected_keywords)
        
        issues = []
        if score < 0.5:
            issues.append("–ú–∞–ª–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∫—Ä–∏—Ç–∏–∫–∞")
        if len(response) < 50:
            issues.append("–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç")
        if "json" not in response_lower:
            issues.append("–ù–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫—É JSON")
        if "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å" not in response_lower:
            issues.append("–ù–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å")
        if "ok" not in response_lower and "–ø—Ä–æ–±–ª–µ–º—ã" not in response_lower:
            issues.append("–ù–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤")
        
        return {
            "score": score,
            "found_keywords": found_keywords,
            "missing_keywords": [kw for kw in expected_keywords if kw not in response_lower],
            "issues": issues
        }


async def main():
    """–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞."""
    tester = ExecutorCriticTester()
    results = await tester.run()
    
    print(f"\n{'='*60}")
    print(tester.generate_summary(results))
    print(f"{'='*60}")


if __name__ == "__main__":
    asyncio.run(main())
