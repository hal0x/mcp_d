#!/usr/bin/env python3
"""–ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ embeddings –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""

import asyncio
import time
import logging
from pathlib import Path
import sys
from typing import List, Dict, Any
import random
import string

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.insert(0, str(Path(__file__).parent))

from llm.embeddings_client import AsyncEmbeddingsClient
from index.vector_index import VectorIndex
from utils.performance import profiler

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def generate_test_texts(count: int, min_length: int = 10, max_length: int = 1000) -> List[str]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã."""
    texts = []
    for i in range(count):
        length = random.randint(min_length, max_length)
        text = ''.join(random.choices(string.ascii_letters + string.digits + ' ', k=length))
        texts.append(text)
    return texts

async def test_embeddings_client_performance():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å AsyncEmbeddingsClient."""
    logger.info("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ AsyncEmbeddingsClient")
    
    client = AsyncEmbeddingsClient(
        model="text-embedding-qwen3-embedding-8b",
        host="127.0.0.1",
        port=1234,
        timeout_seconds=5
    )
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏
    test_scenarios = [
        {"name": "–ö–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ–∫—Å—Ç—ã", "count": 100, "min_length": 10, "max_length": 50},
        {"name": "–°—Ä–µ–¥–Ω–∏–µ —Ç–µ–∫—Å—Ç—ã", "count": 50, "min_length": 100, "max_length": 500},
        {"name": "–î–ª–∏–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã", "count": 20, "min_length": 500, "max_length": 2000},
        {"name": "–°–º–µ—à–∞–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã", "count": 200, "min_length": 10, "max_length": 1000},
    ]
    
    for scenario in test_scenarios:
        logger.info(f"üìä {scenario['name']}: {scenario['count']} —Ç–µ–∫—Å—Ç–æ–≤")
        
        texts = generate_test_texts(
            scenario["count"], 
            scenario["min_length"], 
            scenario["max_length"]
        )
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        start_time = time.perf_counter()
        for text in texts[:10]:  # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10
            await client.embed(text)
        single_time = time.perf_counter() - start_time
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º batch –∑–∞–ø—Ä–æ—Å—ã
        start_time = time.perf_counter()
        await client.embed_many(texts)
        batch_time = time.perf_counter() - start_time
        
        logger.info(f"  –û–¥–∏–Ω–æ—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã (10): {single_time:.2f}—Å")
        logger.info(f"  Batch –∑–∞–ø—Ä–æ—Å—ã ({len(texts)}): {batch_time:.2f}—Å")
        logger.info(f"  –°–∫–æ—Ä–æ—Å—Ç—å batch: {len(texts)/batch_time:.1f} —Ç–µ–∫—Å—Ç–æ–≤/—Å")

async def test_vector_index_performance():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å VectorIndex."""
    logger.info("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ VectorIndex")
    
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å
    vector_index = VectorIndex(
        path="load_test_index.json",
        model_name="text-embedding-qwen3-embedding-8b",
        host="127.0.0.1",
        port=1234
    )
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    test_docs = []
    for i in range(100):
        text = f"–¢–µ—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –Ω–æ–º–µ—Ä {i} —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"
        metadata = {"doc_id": str(i), "category": f"category_{i % 10}"}
        test_docs.append((f"doc_{i}", text, metadata))
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    logger.info("üìù –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    start_time = time.perf_counter()
    
    for doc_id, text, metadata in test_docs:
        await vector_index.add(doc_id, text, metadata)
    
    add_time = time.perf_counter() - start_time
    logger.info(f"  –î–æ–±–∞–≤–ª–µ–Ω–æ {len(test_docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∑–∞ {add_time:.2f}—Å")
    logger.info(f"  –°–∫–æ—Ä–æ—Å—Ç—å: {len(test_docs)/add_time:.1f} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤/—Å")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
    logger.info("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞")
    search_queries = [
        "—Ç–µ—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç",
        "–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏",
        "–∫–∞—Ç–µ–≥–æ—Ä–∏—è",
        "–Ω–æ–º–µ—Ä",
        "—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ"
    ]
    
    start_time = time.perf_counter()
    for query in search_queries:
        results = await vector_index.search(query, top_k=10)
    search_time = time.perf_counter() - start_time
    
    logger.info(f"  –í—ã–ø–æ–ª–Ω–µ–Ω–æ {len(search_queries)} –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∑–∞ {search_time:.2f}—Å")
    logger.info(f"  –°–∫–æ—Ä–æ—Å—Ç—å: {len(search_queries)/search_time:.1f} –∑–∞–ø—Ä–æ—Å–æ–≤/—Å")
    
    # –û—á–∏—Å—Ç–∫–∞
    Path("load_test_index.json").unlink(missing_ok=True)

async def monitor_metrics_during_test():
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç –º–µ—Ç—Ä–∏–∫–∏ –≤–æ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""
    logger.info("üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –º–µ—Ç—Ä–∏–∫ –≤–æ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    
    initial_metrics = profiler.get_all_metrics()
    logger.info("–ù–∞—á–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:")
    for metric, data in initial_metrics.items():
        if "avg_time_ms" in data:
            logger.info(f"  {metric}: {data['avg_time_ms']:.2f}–º—Å")
    
    # –ñ–¥–µ–º –Ω–µ–º–Ω–æ–≥–æ –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
    await asyncio.sleep(2)
    
    final_metrics = profiler.get_all_metrics()
    logger.info("–§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:")
    for metric, data in final_metrics.items():
        if "avg_time_ms" in data:
            initial_avg = initial_metrics.get(metric, {}).get("avg_time_ms", 0)
            current_avg = data["avg_time_ms"]
            change = current_avg - initial_avg
            logger.info(f"  {metric}: {current_avg:.2f}–º—Å (–∏–∑–º–µ–Ω–µ–Ω–∏–µ: {change:+.2f}–º—Å)")

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è embeddings")
    logger.info("=" * 60)
    
    try:
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–º –º–µ—Ç—Ä–∏–∫–∏ –¥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        await monitor_metrics_during_test()
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º AsyncEmbeddingsClient
        await test_embeddings_client_performance()
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º VectorIndex
        await test_vector_index_performance()
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å–ª–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        await monitor_metrics_during_test()
        
        logger.info("‚úÖ –ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        final_metrics = profiler.get_all_metrics()
        logger.info("üìä –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:")
        for metric, data in final_metrics.items():
            if "avg_time_ms" in data:
                avg_time = data["avg_time_ms"]
                status = "‚úÖ" if avg_time < 1000 else "‚ö†Ô∏è" if avg_time < 5000 else "‚ùå"
                logger.info(f"  {status} {metric}: {avg_time:.2f}–º—Å")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main())
