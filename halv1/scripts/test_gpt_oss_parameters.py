#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ gemma3n:e4b-it-q8_0 —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è.
–ò—â–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ temperature, top_p, –∏ –¥—Ä—É–≥–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
"""

import asyncio
import json
import logging
import sys
import time
from datetime import datetime
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from llm.factory import create_llm_client
from llm.prompts import (
    make_agent_summary_prompt,
    make_code_prompt,
    make_math_calculation_prompt,
    make_web_summary_prompt,
)
import yaml

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ParameterTester:
    """–¢–µ—Å—Ç–µ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è gemma3n:e4b-it-q8_0."""
    
    def __init__(self):
        self.base_config = None
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "model": "gemma3n:e4b-it-q8_0",
            "parameter_tests": {},
            "summary": {}
        }
    
    async def setup(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –±–∞–∑–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."""
        logger.info("üîß –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...")
        
        with open("config/settings.yaml", "r", encoding="utf-8") as f:
            config = yaml.safe_load(f)
        
        self.base_config = config.get("llm", {}).copy()
        self.base_config["model"] = "gemma3n:e4b-it-q8_0"
        
        logger.info("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    async def test_parameter_set(self, params: dict, test_name: str):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤."""
        logger.info(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {test_name}...")
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å —Ç–µ—Å—Ç–∏—Ä—É–µ–º—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        test_config = self.base_config.copy()
        test_config.update(params)
        
        # –°–æ–∑–¥–∞–µ–º LLM –∫–ª–∏–µ–Ω—Ç
        llm_client = create_llm_client(
            provider=test_config.get("provider", "ollama"),
            llm_cfg=test_config,
            ollama_cfg=test_config
        )
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –∫–µ–π—Å—ã
        test_cases = {
            "web_summary": {
                "prompt": make_web_summary_prompt("Python ‚Äî –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ–±—â–µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π —Ç–∏–ø–∏–∑–∞—Ü–∏–µ–π –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –ø–∞–º—è—Ç—å—é."),
                "expected_keywords": ["Python", "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ", "—è–∑—ã–∫"]
            },
            "agent_summary": {
                "prompt": make_agent_summary_prompt(
                    mode="summary",
                    user_name="@hal0x",
                    theme="–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞",
                    timezone="Asia/Bangkok",
                    window_start="2024-01-01T00:00:00",
                    window_end="2024-01-01T23:59:59",
                    now_iso="2024-01-01T12:00:00",
                    messages_block="1|chat|user|2024-01-01T10:00:00|–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞ —Å –ø—Ä–æ–µ–∫—Ç–æ–º?"
                ),
                "expected_keywords": ["HAL", "—Å–≤–æ–¥–∫–∞", "–≤–∞–∂–Ω—ã–µ"]
            },
            "code_generation": {
                "prompt": make_code_prompt("–°–æ–∑–¥–∞–π —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ñ–∞–∫—Ç–æ—Ä–∏–∞–ª–∞ —á–∏—Å–ª–∞"),
                "expected_keywords": ["def", "factorial", "return"]
            },
            "math_calculation": {
                "prompt": make_math_calculation_prompt("15 + 27"),
                "expected_keywords": ["42", "15", "27"]
            }
        }
        
        results = {}
        total_time = 0
        
        for test_name_case, test_case in test_cases.items():
            logger.info(f"  üìù {test_name_case}...")
            
            try:
                start_time = time.time()
                response = await self._generate_response(llm_client, test_case["prompt"])
                response_time = time.time() - start_time
                total_time += response_time
                
                quality_score = self._analyze_response_quality(
                    response, 
                    test_case["expected_keywords"],
                    test_name_case
                )
                
                results[test_name_case] = {
                    "prompt_length": len(test_case["prompt"]),
                    "response_length": len(response),
                    "response_time": response_time,
                    "quality_score": quality_score,
                    "response_preview": response[:150] + "..." if len(response) > 150 else response,
                    "status": "success"
                }
                
                logger.info(f"    ‚úÖ –∫–∞—á–µ—Å—Ç–≤–æ {quality_score:.2f}, –≤—Ä–µ–º—è {response_time:.2f}—Å")
                
            except Exception as e:
                logger.error(f"    ‚ùå –æ—à–∏–±–∫–∞ {str(e)}")
                results[test_name_case] = {
                    "error": str(e),
                    "status": "error"
                }
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
        successful_tests = [t for t in results.values() if t.get("status") == "success"]
        if successful_tests:
            avg_quality = sum(t.get("quality_score", 0) for t in successful_tests) / len(successful_tests)
            avg_time = sum(t.get("response_time", 0) for t in successful_tests) / len(successful_tests)
        else:
            avg_quality = 0.0
            avg_time = 0.0
        
        return {
            "parameters": params,
            "tests": results,
            "summary": {
                "total_tests": len(results),
                "successful_tests": len(successful_tests),
                "failed_tests": len(results) - len(successful_tests),
                "success_rate": len(successful_tests) / len(results) if results else 0,
                "average_quality": avg_quality,
                "average_response_time": avg_time,
                "total_time": total_time
            }
        }
    
    async def _generate_response(self, llm_client, prompt: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏."""
        try:
            response = llm_client.generate(prompt)
            return response.strip()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return f"–û—à–∏–±–∫–∞: {str(e)}"
    
    def _analyze_response_quality(self, response: str, expected_keywords: list, test_name: str) -> float:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–∞."""
        if not response or response.startswith("–û—à–∏–±–∫–∞:"):
            return 0.0
        
        score = 0.0
        total_keywords = len(expected_keywords)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        response_lower = response.lower()
        for keyword in expected_keywords:
            if keyword.lower() in response_lower:
                score += 1.0
        
        # –ë–∞–∑–æ–≤—ã–π —Å–∫–æ—Ä –∑–∞ –Ω–∞–ª–∏—á–∏–µ –æ—Ç–≤–µ—Ç–∞
        if response:
            score += 0.5
        
        # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –æ—Ç–≤–µ—Ç—ã
        if len(response) < 10:
            score *= 0.5
        
        # –ë–æ–Ω—É—Å –∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å
        if any(marker in response for marker in ["{", "}", "def ", "class ", "- ", "1.", "2."]):
            score += 0.2
        
        # –ë–æ–Ω—É—Å –∑–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ (–¥–ª—è —Ä—É—Å—Å–∫–∏—Ö –ø—Ä–æ–º–ø—Ç–æ–≤)
        if test_name in ["web_summary", "agent_summary", "math_calculation"]:
            russian_indicators = ["—ç—Ç–æ", "–¥–ª—è", "—á—Ç–æ", "–∫–∞–∫", "–≤", "–Ω–∞", "—Å", "–ø–æ", "–æ—Ç", "–¥–æ"]
            if any(indicator in response_lower for indicator in russian_indicators):
                score += 0.3
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–∫–æ—Ä
        max_possible = total_keywords + 1.0  # 0.5 –∑–∞ –æ—Ç–≤–µ—Ç + 0.2 –∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—É + 0.3 –∑–∞ —Ä—É—Å—Å–∫–∏–π
        return min(score / max_possible, 1.0)
    
    async def run_all_tests(self):
        """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤."""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ gemma3n:e4b-it-q8_0...")
        
        await self.setup()
        
        # –ù–∞–±–æ—Ä—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        parameter_sets = {
            "conservative": {
                "temperature": 0.1,
                "top_p": 0.8,
                "seed": 42
            },
            "balanced": {
                "temperature": 0.3,
                "top_p": 0.9,
                "seed": 42
            },
            "creative": {
                "temperature": 0.7,
                "top_p": 0.95,
                "seed": 42
            },
            "very_creative": {
                "temperature": 1.0,
                "top_p": 1.0,
                "seed": 42
            },
            "focused": {
                "temperature": 0.2,
                "top_p": 0.85,
                "seed": 42
            },
            "deterministic": {
                "temperature": 0.0,
                "top_p": 1.0,
                "seed": 42
            },
            "high_quality": {
                "temperature": 0.4,
                "top_p": 0.9,
                "seed": 42,
                "num_ctx": 32768,
                "num_keep": 1024
            },
            "fast": {
                "temperature": 0.2,
                "top_p": 0.8,
                "seed": 42,
                "num_ctx": 16384,
                "num_keep": 512
            }
        }
        
        for param_name, params in parameter_sets.items():
            try:
                logger.info(f"\nüîÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞–±–æ—Ä–∞: {param_name}")
                result = await self.test_parameter_set(params, param_name)
                self.results["parameter_tests"][param_name] = result
                
                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–µ—Å—Ç–∞–º–∏
                await asyncio.sleep(2)
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ {param_name}: {e}")
                continue
        
        self._generate_summary()
        self._save_results()
        
        logger.info("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    
    def _generate_summary(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
        tests = self.results["parameter_tests"]
        
        if not tests:
            self.results["summary"] = {"error": "–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"}
            return
        
        # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —Ä–∞–∑–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º
        best_quality = max(tests.items(), key=lambda x: x[1]["summary"]["average_quality"])
        best_speed = min(tests.items(), key=lambda x: x[1]["summary"]["average_response_time"])
        best_balanced = max(tests.items(), key=lambda x: x[1]["summary"]["average_quality"] / x[1]["summary"]["average_response_time"])
        
        self.results["summary"] = {
            "total_parameter_sets": len(tests),
            "best_quality": {
                "name": best_quality[0],
                "quality": best_quality[1]["summary"]["average_quality"],
                "time": best_quality[1]["summary"]["average_response_time"]
            },
            "best_speed": {
                "name": best_speed[0],
                "quality": best_speed[1]["summary"]["average_quality"],
                "time": best_speed[1]["summary"]["average_response_time"]
            },
            "best_balanced": {
                "name": best_balanced[0],
                "quality": best_balanced[1]["summary"]["average_quality"],
                "time": best_balanced[1]["summary"]["average_response_time"],
                "efficiency": best_balanced[1]["summary"]["average_quality"] / best_balanced[1]["summary"]["average_response_time"]
            }
        }
    
    def _save_results(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
        results_file = project_root / "scripts" / "gpt_oss_parameter_test_results.json"
        
        with open(results_file, "w", encoding="utf-8") as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {results_file}")
    
    def print_summary(self):
        """–í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
        summary = self.results["summary"]
        
        print(f"\n{'='*80}")
        print("üìä –°–í–û–î–ö–ê –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ü–ê–†–ê–ú–ï–¢–†–û–í GPT-OSS-20B:LATEST")
        print(f"{'='*80}")
        
        if "error" in summary:
            print(f"‚ùå {summary['error']}")
            return
        
        print(f"üìà –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ –Ω–∞–±–æ—Ä–æ–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {summary['total_parameter_sets']}")
        
        print(f"\nüèÜ –õ–£–ß–®–ï–ï –ö–ê–ß–ï–°–¢–í–û:")
        best_qual = summary["best_quality"]
        print(f"  –ù–∞–±–æ—Ä: {best_qual['name']}")
        print(f"  –ö–∞—á–µ—Å—Ç–≤–æ: {best_qual['quality']:.3f}")
        print(f"  –í—Ä–µ–º—è: {best_qual['time']:.2f}—Å")
        
        print(f"\n‚ö° –õ–£–ß–®–ê–Ø –°–ö–û–†–û–°–¢–¨:")
        best_speed = summary["best_speed"]
        print(f"  –ù–∞–±–æ—Ä: {best_speed['name']}")
        print(f"  –ö–∞—á–µ—Å—Ç–≤–æ: {best_speed['quality']:.3f}")
        print(f"  –í—Ä–µ–º—è: {best_speed['time']:.2f}—Å")
        
        print(f"\n‚öñÔ∏è –õ–£–ß–®–ò–ô –ë–ê–õ–ê–ù–°:")
        best_bal = summary["best_balanced"]
        print(f"  –ù–∞–±–æ—Ä: {best_bal['name']}")
        print(f"  –ö–∞—á–µ—Å—Ç–≤–æ: {best_bal['quality']:.3f}")
        print(f"  –í—Ä–µ–º—è: {best_bal['time']:.2f}—Å")
        print(f"  –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {best_bal['efficiency']:.4f}")
        
        print(f"\n{'='*80}")
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print(f"\nüìã –î–ï–¢–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        print(f"{'–ù–∞–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤':<20} {'–ö–∞—á–µ—Å—Ç–≤–æ':<10} {'–í—Ä–µ–º—è (—Å)':<12} {'–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å':<12}")
        print("-" * 80)
        
        for param_name, data in self.results["parameter_tests"].items():
            summary_data = data["summary"]
            efficiency = summary_data["average_quality"] / summary_data["average_response_time"] if summary_data["average_response_time"] > 0 else 0
            print(f"{param_name:<20} {summary_data['average_quality']:<10.3f} {summary_data['average_response_time']:<12.2f} {efficiency:<12.4f}")


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    tester = ParameterTester()
    
    try:
        await tester.run_all_tests()
        tester.print_summary()
    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    sys.exit(asyncio.run(main()))
